{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the difference between nucleus and TFS set of words. See if the words in this set are reasonable. They should be reasonable for when TFS is looser and should not be when TFS is tighter. Out of this set of words, take the highest, lowest prob ones and the middle one? Need at least 3 word gap between them. \n",
    "Rank each one in how reasonable it is. Control baseline is how reasonable words at different points in the body are. The first word, half way and at the closer of the tails. Can also get words outside of the last tail, just outside, halfway to the end, and at the very end. \n",
    "There are 9 different words in total. Should i rank all of them, scramble up a subset? Or have a ranking for each of the subsets differently? Probably scramble them all up. And then present 3 of them??\n",
    "Can then see overall how replaceable different parts of the distributions is, and for TFS and nucleus specifically. Have a control with the bad words. And should be able to hopefully show that the difference in replaceability between the TFS and nucleus words is small when TFS is looser and large when TFS is tighter. Can see how specific this is also. Eg could just look at the last TFS and nucleus words, see the diff in replaceability, or maybe need to look at the averages. Look most at this unique subset and these three points should hopefully categorize it. Want them because i dont know how good the signal is going to be. For the closest words for example. \n",
    "Can also get overall data on how replaceability corresponds to model probability. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pandas as pd    \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decodeLogits import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\\n'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#updated\n",
    "vals_dict = {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99],\n",
    "'n': [0.5, 0.63, 0.69, 0.81, 0.75, 0.9], 'k':[1,40,200]  }\n",
    "\n",
    "\n",
    "''' {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\n",
    "'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing analysis for the same logit going to use the ground truth as it is a Schelling point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=25\n",
    "num_batches=4\n",
    "prompt_length=100\n",
    "generated_length=150\n",
    "tot_len = prompt_length+generated_length\n",
    "\n",
    "import encoder\n",
    "model_name='774M' #345M\n",
    "models_dir='../gpt-2/models'\n",
    "enc = encoder.get_encoder(model_name, models_dir)\n",
    "\n",
    "prompts=pd.read_csv('test_dataframe_500primer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_out_path = 'gpt-2_output/'\n",
    "additional_path = '-model_774M-seed_27'#'' \n",
    "#all_perps = pickle.load( gzip.open(gpt_out_path+'all_perplexities_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb'))\n",
    "all_logits = pickle.load( gzip.open(gpt_out_path+'all_logits_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb')) # needed to get the probabilities\n",
    "text = pickle.load( gzip.open(gpt_out_path+'all_text_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n",
      "24\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_num = 0\n",
    "mapping_to_batch = dict()\n",
    "for i in range(num_batches):\n",
    "    num_in_batch = all_logits[i].shape[0]\n",
    "    for el, b_ind in zip(range(tot_num, tot_num+num_in_batch), range(0, num_in_batch)):\n",
    "        mapping_to_batch[el] = (i, b_ind) # actual batch and then the ind in that batch\n",
    "    print( num_in_batch)\n",
    "    tot_num+= num_in_batch\n",
    "tot_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 150, 50257)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Want to generate things that are at the different probability levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at max deviation and getting these points within the tails of each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to also focus on the maximum deviation portions at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random prompts and locations within the 150 generation locations\n",
    "\n",
    "num_prompts_and_timepoints_wanted = 50 # cant be larger than 100 right now!!!\n",
    "assert num_prompts_and_timepoints_wanted <=100\n",
    "leading_prompt = 15\n",
    "\n",
    "want_min_max = False\n",
    "\n",
    "if want_min_max==True:\n",
    "    minmax = pd.read_csv('Min_Max_Disagreement_Coords_TFS90.csv')\n",
    "    #shuffle it and take the number that is wanted. \n",
    "    minmax = minmax.sample(frac= num_prompts_and_timepoints_wanted/minmax.shape[0])\n",
    "    display(minmax.head())\n",
    "    \n",
    "else:\n",
    "    rand_prompts = np.random.randint(0,tot_num, num_prompts_and_timepoints_wanted)\n",
    "    # leadingprompt until 150. as the logits are 150 not 250. \n",
    "    # -1 because of the end token prediction\n",
    "    rand_times = np.random.randint(0,generated_length-1, num_prompts_and_timepoints_wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_logits[0][0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting random locations\n",
    "for the differnet gen strategies. find the tail locations. take the tokens at each position. \n",
    "move onto the next random location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(model_name, models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n",
      " we\n",
      "[732]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'we'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = text[batch_ind][ind_in_batch][text_timepoint]\n",
    "print(lol)\n",
    "gword = decoder_text([lol])\n",
    "print(gword)\n",
    "c = enc.encode(gword.strip())\n",
    "print(c)\n",
    "decoder_text(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ten sps values [9.7826791e-01 2.1306623e-03 7.7810284e-04 5.0903222e-04 4.9161154e-04\n",
      " 4.3409874e-04 3.7558551e-04 3.6901754e-04 3.4070396e-04 2.6838572e-04]\n",
      "prob slices: [0.97826791 0.78261433 0.58696074 0.39130716 0.19565358 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35195]\n",
      "['events' 'event' 'things' 'circumstances' 'bad' 'Population']\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.12378731 0.1110413  0.10720164 0.09488712 0.07680266 0.04294153\n",
      " 0.03562189 0.01786945 0.01625022 0.01591282]\n",
      "prob slices: [0.12378731 0.09902984 0.07427238 0.04951492 0.02475746 0.        ]\n",
      "words wanted rel positions [0, 3, 4, 5, 6, 35194]\n",
      "['were' 'had' 'would' 'could' 'are' 'iterator']\n",
      "ten sps values [0.27985963 0.1617055  0.08516163 0.06683456 0.03213869 0.03016647\n",
      " 0.02423738 0.00844133 0.00640868 0.00623327]\n",
      "prob slices: [0.27985963 0.22388771 0.16791578 0.11194385 0.05597193 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35196]\n",
      "['edge' 'counter' 'sink' 'side' 'table' 'Plot']\n",
      "ten sps values [0.41619945 0.17138307 0.11777301 0.05513218 0.04402787 0.01673699\n",
      " 0.01629868 0.01604169 0.0084719  0.00512973]\n",
      "prob slices: [0.41619945 0.33295956 0.24971967 0.16647978 0.08323989 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35194]\n",
      "['a' 'the' 'my' 'an' 'me' 'conservancy']\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.09772053 0.08673013 0.0442342  0.03243464 0.02368389 0.01398299\n",
      " 0.01168475 0.01133061 0.01012677 0.00927453]\n",
      "prob slices: [0.09772053 0.07817643 0.05863232 0.03908821 0.01954411 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35196]\n",
      "['and' 'of' 'oak' 'sand' 'sky' 'Eat']\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.22781697 0.07713857 0.04775241 0.04415162 0.0297315  0.02290292\n",
      " 0.01815408 0.0157106  0.01548197 0.01251665]\n",
      "prob slices: [0.22781697 0.18225358 0.13669018 0.09112679 0.04556339 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35195]\n",
      "['he' 'is' 'makes' 'she' 'the' 'prototype']\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.04251141 0.04043921 0.03173163 0.03017631 0.02360728 0.02247164\n",
      " 0.02095384 0.01484984 0.01151092 0.01143924]\n",
      "prob slices: [0.04251141 0.03400913 0.02550684 0.01700456 0.00850228 0.        ]\n",
      "words wanted rel positions [0, 2, 4, 7, 15, 35195]\n",
      "['simple' 'a' 'young' 'deliberate' 'simply' '7601']\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.25678304 0.12715816 0.05183318 0.0389463  0.03536024 0.02396843\n",
      " 0.02274912 0.01849176 0.01627074 0.01402227]\n",
      "prob slices: [0.25678304 0.20542643 0.15406982 0.10271322 0.05135661 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35196]\n",
      "['his' 'a' 'the' 'thought' 'an' 'cumbers']\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.3757138  0.36019436 0.05797093 0.05231691 0.01232337 0.01199899\n",
      " 0.01110467 0.00818582 0.00530018 0.00482234]\n",
      "prob slices: [0.3757138  0.30057104 0.22542828 0.15028552 0.07514276 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35196]\n",
      "['your' 'the' 'his' 'it' 'one' 'ODE']\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.01845132 0.01772166 0.01409782 0.01085417 0.01062797 0.01012612\n",
      " 0.00895747 0.00785161 0.0075899  0.00736638]\n",
      "prob slices: [0.01845132 0.01476105 0.01107079 0.00738053 0.00369026 0.        ]\n",
      "words wanted rel positions [0, 2, 3, 9, 31, 35195]\n",
      "['social' 'political' 'medical' 'research' 'design' 'winner']\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.2333325  0.13031088 0.05454249 0.0480359  0.01873391 0.01554786\n",
      " 0.01529359 0.01504613 0.01309819 0.01226895]\n",
      "prob slices: [0.2333325 0.186666  0.1399995 0.093333  0.0466665 0.       ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35195]\n",
      "['organized' 'at' 'in' 'people' 'organizers' 'rush']\n",
      "ten sps values [0.20355582 0.13363923 0.09389567 0.06085902 0.04151911 0.03775018\n",
      " 0.03496406 0.02466996 0.02128609 0.01839761]\n",
      "prob slices: [0.20355582 0.16284466 0.12213349 0.08142233 0.04071116 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35196]\n",
      "['the' 'weapons' 'these' 'their' 'weaponry' 'Sexual']\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.36536276 0.11716203 0.0867854  0.05399276 0.01965693 0.01751379\n",
      " 0.0113671  0.00910884 0.00801686 0.00684225]\n",
      "prob slices: [0.36536276 0.29229021 0.21921766 0.14614511 0.07307255 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35195]\n",
      "['same' 'story' 'truth' 'other' 'whole' 'cumbers']\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.06276622 0.05227108 0.04409203 0.03855397 0.03699395 0.03369571\n",
      " 0.01917561 0.01780903 0.01725752 0.01660915]\n",
      "prob slices: [0.06276622 0.05021298 0.03765973 0.02510649 0.01255324 0.        ]\n",
      "words wanted rel positions [0, 1, 4, 6, 12, 35196]\n",
      "['own' 'place' 'partner' 'value' 'chances' 'Reviewed']\n",
      "ten sps values [0.5349603  0.10094124 0.09639756 0.05381551 0.04533264 0.03729302\n",
      " 0.02017262 0.01200766 0.01112065 0.00988199]\n",
      "prob slices: [0.53496033 0.42796826 0.3209762  0.21398413 0.10699207 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35193]\n",
      "['his' 'himself' 'the' 'out' 'back' 'CAST']\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.72515    0.12334786 0.02939017 0.0284824  0.01833724 0.00611814\n",
      " 0.00563837 0.00413916 0.00399107 0.00353441]\n",
      "prob slices: [0.72514999 0.58011999 0.43508999 0.29006    0.14503    0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35195]\n",
      "['him' 'his' 'it' 'the' 'her' 'Export']\n",
      "one of the three tokens in front were not words so skipping\n",
      "one of the three tokens in front were not words so skipping\n",
      "ten sps values [0.15548737 0.11381613 0.07520269 0.0405112  0.02288244 0.01799409\n",
      " 0.01717026 0.01207147 0.01204886 0.01172266]\n",
      "prob slices: [0.15548737 0.1243899  0.09329242 0.06219495 0.03109747 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35195]\n",
      "['so' 'a' 'the' 'too' 'able' 'Tokens']\n",
      "ten sps values [0.10321759 0.03336173 0.02416081 0.01495864 0.01487671 0.01319072\n",
      " 0.01294508 0.01134373 0.00989361 0.0097677 ]\n",
      "prob slices: [0.10321759 0.08257408 0.06193056 0.04128704 0.02064352 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35195]\n",
      "['man' 'new' 'smile' 'pillow' 'lover' 'DEM']\n",
      "ten sps values [0.66799676 0.04252248 0.03396498 0.02823217 0.02178656 0.02174337\n",
      " 0.02160682 0.01850851 0.01837987 0.00937439]\n",
      "prob slices: [0.66799676 0.53439741 0.40079806 0.26719871 0.13359935 0.        ]\n",
      "words wanted rel positions [0, 1, 2, 3, 4, 35196]\n",
      "['that' 'money' 'the' 'I' 'we' 'Sax']\n"
     ]
    }
   ],
   "source": [
    "# applying all analyses to the logits. \n",
    "prompt_length = 100\n",
    "slices_from_each = 6 # as one will also be the ground truth word. \n",
    "to_df = []\n",
    "\n",
    "# randomly select generations and positions in those generations. from the original prompts. \n",
    "for r_ind in range(0, num_prompts_and_timepoints_wanted):\n",
    "    \n",
    "    if want_min_max ==True:\n",
    "        prompt = 999\n",
    "        batch_ind, ind_in_batch = minmax.iloc[r_ind, 1], minmax.iloc[r_ind, 2]\n",
    "        time_point = minmax.iloc[r_ind,3]\n",
    "        if time_point>=149:\n",
    "            continue # because of the stop token being predicted. \n",
    "        text_timepoint = time_point+prompt_length+1 # +1 because the perplexities keeps the end prediction token. \n",
    "    else:\n",
    "        prompt = rand_prompts[r_ind]\n",
    "        time_point = rand_times[r_ind]\n",
    "        text_timepoint = time_point+prompt_length+1 # +1 because the perplexities keeps the end prediction token. \n",
    "        batch_ind, ind_in_batch = mapping_to_batch[prompt]\n",
    "    \n",
    "    sps = softmax(-np.sort(-all_logits[batch_ind][ind_in_batch, time_point, :]))\n",
    "    prob_slices_wanted = np.linspace(sps[0],0,slices_from_each)\n",
    "    \n",
    "    indices = np.argsort(-all_logits[batch_ind][ind_in_batch, time_point, :])\n",
    "    ground_token = text[batch_ind][ind_in_batch][text_timepoint]\n",
    "    prev_token = text[batch_ind][ind_in_batch][text_timepoint-1]\n",
    "    prev_prev_token = text[batch_ind][ind_in_batch][text_timepoint-2]\n",
    "    prev_tokens = [ground_token, prev_token,prev_prev_token]\n",
    "    \n",
    "    stripped_prev_tokens = []\n",
    "    # need to strip the spaces and recode. \n",
    "    for t in prev_tokens:\n",
    "        \n",
    "        gword = decoder_text([t])\n",
    "        space_free = enc.encode(gword.strip())\n",
    "        stripped_prev_tokens.append(space_free)\n",
    "    \n",
    "    #print('prev tokens', prev_tokens)\n",
    "    real_prompt_words, _ = remove_non_words(stripped_prev_tokens, wantPrint=False)\n",
    "    #print(real_prompt_words)\n",
    "    if len(real_prompt_words)<len(stripped_prev_tokens):\n",
    "        print('one of the three tokens in front were not words so skipping')\n",
    "        continue\n",
    "    \n",
    "    ground_word = decoder_text([ground_token])\n",
    "    # what the ground token is\n",
    "    ground_word_prob = sps[ground_token]\n",
    "    \n",
    "    #get the 15 words in front. \n",
    "    lead_prompt_words = decoder_text(text[batch_ind][ind_in_batch][text_timepoint-leading_prompt:text_timepoint])\n",
    "    df_row = [prompt, time_point, batch_ind, ind_in_batch, lead_prompt_words, ground_word, ground_word_prob] # taking it from the last one. \n",
    "    \n",
    "    print('ten sps values', sps[0:10])\n",
    "    print('prob slices:', prob_slices_wanted)\n",
    "    \n",
    "    #remove any non word tokens from whole list. (could be done more efficiently)\n",
    "    real_word_tokens, abs_pos = remove_non_words(indices)\n",
    "    real_word_probs = sps[np.asarray(abs_pos)]\n",
    "    \n",
    "    rel_to_abs_index = {rel:absolute for rel, absolute in zip(range(len(abs_pos)), abs_pos )}\n",
    "    \n",
    "    # select the right positions and words: \n",
    "    #NEED TO IGNORE ANY OF THE SLICES THAT ARE TOO LARGE.  TAKE THE HIGHEST PROB WORD AND THEN DO THE SLICES.\n",
    "    rel_words_positions_wanted, sel_word_probs = get_specific_positions_from_probs(real_word_probs, prob_slices_wanted)\n",
    "    \n",
    "    print('words wanted rel positions', rel_words_positions_wanted)\n",
    "    \n",
    "    abs_words_positions_wanted = [ rel_to_abs_index[rel] for rel in rel_words_positions_wanted]\n",
    "    print(np.asarray(real_word_tokens)[np.asarray(rel_words_positions_wanted)])\n",
    "    df_row.append(np.asarray(real_word_tokens)[np.asarray(rel_words_positions_wanted)]) # adding the words themselves. \n",
    "    df_row.append(abs_words_positions_wanted)\n",
    "    df_row.append(sel_word_probs)\n",
    "        \n",
    "    to_df.append(df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = enchant.Dict(\"en_US\")\n",
    "d.check('rust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_ind</th>\n",
       "      <th>time_point</th>\n",
       "      <th>batch_ind</th>\n",
       "      <th>ind_in_batch</th>\n",
       "      <th>leading_words</th>\n",
       "      <th>ground_word</th>\n",
       "      <th>ground_word_prob</th>\n",
       "      <th>words</th>\n",
       "      <th>abs_inds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>change something, might be the one trigger th...</td>\n",
       "      <td>events</td>\n",
       "      <td>4.103564e-07</td>\n",
       "      <td>[events, event, things, circumstances, bad, Po...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50158]</td>\n",
       "      <td>[0.9782679, 0.0021306623, 0.00077810284, 0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>the world ’ s leading pharmaceutical companie...</td>\n",
       "      <td>would</td>\n",
       "      <td>5.513494e-05</td>\n",
       "      <td>[were, had, would, could, are, iterator]</td>\n",
       "      <td>[0, 3, 5, 6, 7, 50140]</td>\n",
       "      <td>[0.123787306, 0.09488712, 0.04294153, 0.035621...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>off guard. While your body lay half on the co...</td>\n",
       "      <td>edge</td>\n",
       "      <td>1.622044e-06</td>\n",
       "      <td>[edge, counter, sink, side, table, Plot]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50130]</td>\n",
       "      <td>[0.27985963, 0.1617055, 0.08516163, 0.06683456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>I'm getting rrREAdy''. My murmur had ended with</td>\n",
       "      <td>a</td>\n",
       "      <td>5.716932e-05</td>\n",
       "      <td>[a, the, my, an, me, conservancy]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50140]</td>\n",
       "      <td>[0.41619945, 0.17138307, 0.11777301, 0.0551321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>crunched underneath and the ground bubbled wi...</td>\n",
       "      <td>creek</td>\n",
       "      <td>2.153896e-08</td>\n",
       "      <td>[and, of, oak, sand, sky, Eat]</td>\n",
       "      <td>[4, 5, 6, 7, 8, 50156]</td>\n",
       "      <td>[0.023683885, 0.013982991, 0.011684752, 0.0113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>lady because the ugly mug of hers somehow brin...</td>\n",
       "      <td>is</td>\n",
       "      <td>2.049686e-04</td>\n",
       "      <td>[he, is, makes, she, the, prototype]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50158]</td>\n",
       "      <td>[0.22781697, 0.077138565, 0.047752414, 0.04415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>before it can even be started. \\n \\n Neverthe...</td>\n",
       "      <td>adept</td>\n",
       "      <td>1.260401e-08</td>\n",
       "      <td>[simple, a, young, deliberate, simply, 7601]</td>\n",
       "      <td>[0, 2, 4, 7, 15, 50152]</td>\n",
       "      <td>[0.042511407, 0.031731628, 0.023607282, 0.0148...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>voice. ``I wish I could actually be challenge...</td>\n",
       "      <td>shock</td>\n",
       "      <td>2.355514e-06</td>\n",
       "      <td>[his, a, the, thought, an, cumbers]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50158]</td>\n",
       "      <td>[0.25678304, 0.12715816, 0.051833175, 0.038946...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>you off guard. While your body lay half on th...</td>\n",
       "      <td>the</td>\n",
       "      <td>3.848319e-05</td>\n",
       "      <td>[your, the, his, it, one, ODE]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50133]</td>\n",
       "      <td>[0.3757138, 0.36019436, 0.05797093, 0.05231691...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>their data analysis, their legislation and li...</td>\n",
       "      <td>novel</td>\n",
       "      <td>1.560937e-05</td>\n",
       "      <td>[social, political, medical, research, design,...</td>\n",
       "      <td>[0, 2, 3, 9, 31, 50154]</td>\n",
       "      <td>[0.018451318, 0.014097815, 0.010854172, 0.0073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>, I fully use the power of organization and am...</td>\n",
       "      <td>secretaries</td>\n",
       "      <td>2.166052e-10</td>\n",
       "      <td>[organized, at, in, people, organizers, rush]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50161]</td>\n",
       "      <td>[0.2333325, 0.13031088, 0.054542486, 0.0480358...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>to use modern aged weapons. Everyone else was...</td>\n",
       "      <td>technology</td>\n",
       "      <td>3.796790e-06</td>\n",
       "      <td>[the, weapons, these, their, weaponry, Sexual]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50155]</td>\n",
       "      <td>[0.20355582, 0.13363923, 0.09389567, 0.0608590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>dude, that was hell you just came from. (I to...</td>\n",
       "      <td>Jews</td>\n",
       "      <td>2.580503e-06</td>\n",
       "      <td>[same, story, truth, other, whole, cumbers]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50160]</td>\n",
       "      <td>[0.36536276, 0.11716203, 0.0867854, 0.05399276...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>, despite both parties equally capable of feel...</td>\n",
       "      <td>trade</td>\n",
       "      <td>1.015331e-05</td>\n",
       "      <td>[own, place, partner, value, chances, Reviewed]</td>\n",
       "      <td>[0, 1, 4, 6, 12, 50161]</td>\n",
       "      <td>[0.062766224, 0.05227108, 0.03699395, 0.019175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>. Just count the stars, right? * \\n \\n He eased</td>\n",
       "      <td>his</td>\n",
       "      <td>5.129267e-06</td>\n",
       "      <td>[his, himself, the, out, back, CAST]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50122]</td>\n",
       "      <td>[0.5349603, 0.10094124, 0.09639756, 0.05381551...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>. Thoughts of her always danced in the back of...</td>\n",
       "      <td>his</td>\n",
       "      <td>9.561581e-06</td>\n",
       "      <td>[him, his, it, the, her, Export]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50156]</td>\n",
       "      <td>[0.72515, 0.12334786, 0.029390175, 0.028482404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>\\n He had forgotten so much of this day. He h...</td>\n",
       "      <td>told</td>\n",
       "      <td>2.744273e-05</td>\n",
       "      <td>[so, a, the, too, able, Tokens]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50140]</td>\n",
       "      <td>[0.15548737, 0.11381613, 0.07520269, 0.0405112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>. One of the most satisfying moments for him w...</td>\n",
       "      <td>smile</td>\n",
       "      <td>2.294331e-06</td>\n",
       "      <td>[man, new, smile, pillow, lover, DEM]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50160]</td>\n",
       "      <td>[0.103217594, 0.033361733, 0.02416081, 0.01495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>expecting it. ” \\n \\n“ So are you saying</td>\n",
       "      <td>we</td>\n",
       "      <td>2.269794e-05</td>\n",
       "      <td>[that, money, the, I, we, Sax]</td>\n",
       "      <td>[0, 1, 2, 4, 5, 50146]</td>\n",
       "      <td>[0.66799676, 0.042522475, 0.03396498, 0.021786...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prompt_ind  time_point  batch_ind  ind_in_batch  \\\n",
       "0           19          28          0            19   \n",
       "1           72         100          3             2   \n",
       "2           31          29          1             8   \n",
       "3           56          73          2            10   \n",
       "4           24          60          1             1   \n",
       "5           13          64          0            13   \n",
       "6           42         108          1            19   \n",
       "7           62          53          2            16   \n",
       "8           31          28          1             8   \n",
       "9           39          46          1            16   \n",
       "10          53         100          2             7   \n",
       "11          33         114          1            10   \n",
       "12          48          24          2             2   \n",
       "13          42          45          1            19   \n",
       "14          19           2          0            19   \n",
       "15          23          91          1             0   \n",
       "16          17         144          0            17   \n",
       "17          23          42          1             0   \n",
       "18           7         117          0             7   \n",
       "\n",
       "                                        leading_words   ground_word  \\\n",
       "0    change something, might be the one trigger th...        events   \n",
       "1    the world ’ s leading pharmaceutical companie...         would   \n",
       "2    off guard. While your body lay half on the co...          edge   \n",
       "3     I'm getting rrREAdy''. My murmur had ended with             a   \n",
       "4    crunched underneath and the ground bubbled wi...         creek   \n",
       "5   lady because the ugly mug of hers somehow brin...            is   \n",
       "6    before it can even be started. \\n \\n Neverthe...         adept   \n",
       "7    voice. ``I wish I could actually be challenge...         shock   \n",
       "8    you off guard. While your body lay half on th...           the   \n",
       "9    their data analysis, their legislation and li...         novel   \n",
       "10  , I fully use the power of organization and am...   secretaries   \n",
       "11   to use modern aged weapons. Everyone else was...    technology   \n",
       "12   dude, that was hell you just came from. (I to...          Jews   \n",
       "13  , despite both parties equally capable of feel...         trade   \n",
       "14    . Just count the stars, right? * \\n \\n He eased           his   \n",
       "15  . Thoughts of her always danced in the back of...           his   \n",
       "16   \\n He had forgotten so much of this day. He h...          told   \n",
       "17  . One of the most satisfying moments for him w...         smile   \n",
       "18           expecting it. ” \\n \\n“ So are you saying            we   \n",
       "\n",
       "    ground_word_prob                                              words  \\\n",
       "0       4.103564e-07  [events, event, things, circumstances, bad, Po...   \n",
       "1       5.513494e-05           [were, had, would, could, are, iterator]   \n",
       "2       1.622044e-06           [edge, counter, sink, side, table, Plot]   \n",
       "3       5.716932e-05                  [a, the, my, an, me, conservancy]   \n",
       "4       2.153896e-08                     [and, of, oak, sand, sky, Eat]   \n",
       "5       2.049686e-04               [he, is, makes, she, the, prototype]   \n",
       "6       1.260401e-08       [simple, a, young, deliberate, simply, 7601]   \n",
       "7       2.355514e-06                [his, a, the, thought, an, cumbers]   \n",
       "8       3.848319e-05                     [your, the, his, it, one, ODE]   \n",
       "9       1.560937e-05  [social, political, medical, research, design,...   \n",
       "10      2.166052e-10      [organized, at, in, people, organizers, rush]   \n",
       "11      3.796790e-06     [the, weapons, these, their, weaponry, Sexual]   \n",
       "12      2.580503e-06        [same, story, truth, other, whole, cumbers]   \n",
       "13      1.015331e-05    [own, place, partner, value, chances, Reviewed]   \n",
       "14      5.129267e-06               [his, himself, the, out, back, CAST]   \n",
       "15      9.561581e-06                   [him, his, it, the, her, Export]   \n",
       "16      2.744273e-05                    [so, a, the, too, able, Tokens]   \n",
       "17      2.294331e-06              [man, new, smile, pillow, lover, DEM]   \n",
       "18      2.269794e-05                     [that, money, the, I, we, Sax]   \n",
       "\n",
       "                   abs_inds                                              probs  \n",
       "0    [0, 1, 2, 3, 4, 50158]  [0.9782679, 0.0021306623, 0.00077810284, 0.000...  \n",
       "1    [0, 3, 5, 6, 7, 50140]  [0.123787306, 0.09488712, 0.04294153, 0.035621...  \n",
       "2    [0, 1, 2, 3, 4, 50130]  [0.27985963, 0.1617055, 0.08516163, 0.06683456...  \n",
       "3    [0, 1, 2, 3, 4, 50140]  [0.41619945, 0.17138307, 0.11777301, 0.0551321...  \n",
       "4    [4, 5, 6, 7, 8, 50156]  [0.023683885, 0.013982991, 0.011684752, 0.0113...  \n",
       "5    [0, 1, 2, 3, 4, 50158]  [0.22781697, 0.077138565, 0.047752414, 0.04415...  \n",
       "6   [0, 2, 4, 7, 15, 50152]  [0.042511407, 0.031731628, 0.023607282, 0.0148...  \n",
       "7    [0, 1, 2, 3, 4, 50158]  [0.25678304, 0.12715816, 0.051833175, 0.038946...  \n",
       "8    [0, 1, 2, 3, 4, 50133]  [0.3757138, 0.36019436, 0.05797093, 0.05231691...  \n",
       "9   [0, 2, 3, 9, 31, 50154]  [0.018451318, 0.014097815, 0.010854172, 0.0073...  \n",
       "10   [0, 1, 2, 3, 4, 50161]  [0.2333325, 0.13031088, 0.054542486, 0.0480358...  \n",
       "11   [0, 1, 2, 3, 4, 50155]  [0.20355582, 0.13363923, 0.09389567, 0.0608590...  \n",
       "12   [0, 1, 2, 3, 4, 50160]  [0.36536276, 0.11716203, 0.0867854, 0.05399276...  \n",
       "13  [0, 1, 4, 6, 12, 50161]  [0.062766224, 0.05227108, 0.03699395, 0.019175...  \n",
       "14   [0, 1, 2, 3, 4, 50122]  [0.5349603, 0.10094124, 0.09639756, 0.05381551...  \n",
       "15   [0, 1, 2, 3, 4, 50156]  [0.72515, 0.12334786, 0.029390175, 0.028482404...  \n",
       "16   [0, 1, 2, 3, 4, 50140]  [0.15548737, 0.11381613, 0.07520269, 0.0405112...  \n",
       "17   [0, 1, 2, 3, 4, 50160]  [0.103217594, 0.033361733, 0.02416081, 0.01495...  \n",
       "18   [0, 1, 2, 4, 5, 50146]  [0.66799676, 0.042522475, 0.03396498, 0.021786...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(to_df, columns = ['prompt_ind', 'time_point', \n",
    "                               'batch_ind', 'ind_in_batch', 'leading_words',\n",
    "                               'ground_word', 'ground_word_prob', 'words', 'abs_inds', 'probs'])\n",
    "                                         \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert results.drop_duplicates('leading_words').shape == results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_ind</th>\n",
       "      <th>time_point</th>\n",
       "      <th>batch_ind</th>\n",
       "      <th>ind_in_batch</th>\n",
       "      <th>leading_words</th>\n",
       "      <th>ground_word</th>\n",
       "      <th>ground_word_prob</th>\n",
       "      <th>words</th>\n",
       "      <th>abs_inds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>change something, might be the one trigger th...</td>\n",
       "      <td>events</td>\n",
       "      <td>4.103564e-07</td>\n",
       "      <td>[events, event, things, circumstances, bad, Po...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50158]</td>\n",
       "      <td>[0.9782679, 0.0021306623, 0.00077810284, 0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>the world ’ s leading pharmaceutical companie...</td>\n",
       "      <td>would</td>\n",
       "      <td>5.513494e-05</td>\n",
       "      <td>[were, had, would, could, are, iterator]</td>\n",
       "      <td>[0, 3, 5, 6, 7, 50140]</td>\n",
       "      <td>[0.123787306, 0.09488712, 0.04294153, 0.035621...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>off guard. While your body lay half on the co...</td>\n",
       "      <td>edge</td>\n",
       "      <td>1.622044e-06</td>\n",
       "      <td>[edge, counter, sink, side, table, Plot]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50130]</td>\n",
       "      <td>[0.27985963, 0.1617055, 0.08516163, 0.06683456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>I'm getting rrREAdy''. My murmur had ended with</td>\n",
       "      <td>a</td>\n",
       "      <td>5.716932e-05</td>\n",
       "      <td>[a, the, my, an, me, conservancy]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50140]</td>\n",
       "      <td>[0.41619945, 0.17138307, 0.11777301, 0.0551321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>crunched underneath and the ground bubbled wi...</td>\n",
       "      <td>creek</td>\n",
       "      <td>2.153896e-08</td>\n",
       "      <td>[and, of, oak, sand, sky, Eat]</td>\n",
       "      <td>[4, 5, 6, 7, 8, 50156]</td>\n",
       "      <td>[0.023683885, 0.013982991, 0.011684752, 0.0113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>lady because the ugly mug of hers somehow brin...</td>\n",
       "      <td>is</td>\n",
       "      <td>2.049686e-04</td>\n",
       "      <td>[he, is, makes, she, the, prototype]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 50158]</td>\n",
       "      <td>[0.22781697, 0.077138565, 0.047752414, 0.04415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>before it can even be started. \\n \\n Neverthe...</td>\n",
       "      <td>adept</td>\n",
       "      <td>1.260401e-08</td>\n",
       "      <td>[simple, a, young, deliberate, simply, 7601]</td>\n",
       "      <td>[0, 2, 4, 7, 15, 50152]</td>\n",
       "      <td>[0.042511407, 0.031731628, 0.023607282, 0.0148...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_ind  time_point  batch_ind  ind_in_batch  \\\n",
       "0          19          28          0            19   \n",
       "1          72         100          3             2   \n",
       "2          31          29          1             8   \n",
       "3          56          73          2            10   \n",
       "4          24          60          1             1   \n",
       "5          13          64          0            13   \n",
       "6          42         108          1            19   \n",
       "\n",
       "                                       leading_words ground_word  \\\n",
       "0   change something, might be the one trigger th...      events   \n",
       "1   the world ’ s leading pharmaceutical companie...       would   \n",
       "2   off guard. While your body lay half on the co...        edge   \n",
       "3    I'm getting rrREAdy''. My murmur had ended with           a   \n",
       "4   crunched underneath and the ground bubbled wi...       creek   \n",
       "5  lady because the ugly mug of hers somehow brin...          is   \n",
       "6   before it can even be started. \\n \\n Neverthe...       adept   \n",
       "\n",
       "   ground_word_prob                                              words  \\\n",
       "0      4.103564e-07  [events, event, things, circumstances, bad, Po...   \n",
       "1      5.513494e-05           [were, had, would, could, are, iterator]   \n",
       "2      1.622044e-06           [edge, counter, sink, side, table, Plot]   \n",
       "3      5.716932e-05                  [a, the, my, an, me, conservancy]   \n",
       "4      2.153896e-08                     [and, of, oak, sand, sky, Eat]   \n",
       "5      2.049686e-04               [he, is, makes, she, the, prototype]   \n",
       "6      1.260401e-08       [simple, a, young, deliberate, simply, 7601]   \n",
       "\n",
       "                  abs_inds                                              probs  \n",
       "0   [0, 1, 2, 3, 4, 50158]  [0.9782679, 0.0021306623, 0.00077810284, 0.000...  \n",
       "1   [0, 3, 5, 6, 7, 50140]  [0.123787306, 0.09488712, 0.04294153, 0.035621...  \n",
       "2   [0, 1, 2, 3, 4, 50130]  [0.27985963, 0.1617055, 0.08516163, 0.06683456...  \n",
       "3   [0, 1, 2, 3, 4, 50140]  [0.41619945, 0.17138307, 0.11777301, 0.0551321...  \n",
       "4   [4, 5, 6, 7, 8, 50156]  [0.023683885, 0.013982991, 0.011684752, 0.0113...  \n",
       "5   [0, 1, 2, 3, 4, 50158]  [0.22781697, 0.077138565, 0.047752414, 0.04415...  \n",
       "6  [0, 2, 4, 7, 15, 50152]  [0.042511407, 0.031731628, 0.023607282, 0.0148...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lady because the ugly mug of hers somehow brings a sense of familiarity that'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[5, 'leading_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('backup_of_different_prob_slices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_base = 'prob_slice_replaceable_comparisons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_orders = []\n",
    "with open(file_name_base + '_blind_output.txt', 'w') as file: \n",
    "    file.write('For each of the following assignments, rank on a scale of 1-5 how possible each word is, given the provided context. \\n')\n",
    "    file.write('Some words are stems, if the word could be completed then you can still rank it highly. And be generous with acronyms that could be plausible. ')\n",
    "    file.write('It helps to repeat the last few words of the prompt in your head while deciding how replaceable the current one is.')\n",
    "    file.write('5 means the word would work very well here, 1 means it doesnt make any sense, 3 means it could potentially work.')\n",
    "    file.write('===================================================== \\n \\n')\n",
    "    for ind in range(results.shape[0]):\n",
    "        file.write('Prompt '+str(ind)+'. \\n')\n",
    "        file.write('The '+str(leading_prompt)+' words in front: \\n \\n')\n",
    "        file.write(results.loc[ind, 'leading_words']+' _______')\n",
    "        #file.write(results.loc[ind, 'leading_words']+' : '+ results.loc[ind, 'ground_word'] )\n",
    "        file.write('\\n')\n",
    "        \n",
    "        words = [results.loc[ind, 'ground_word']]\n",
    "        words += list(results.loc[ind, 'words'])\n",
    "        words =np.asarray(words)\n",
    "        \n",
    "        order = ['ground_word']\n",
    "        order += [str(i) for i in range(len(words)-1)]\n",
    "        order = np.asarray(order)\n",
    "        \n",
    "        probs = [results.loc[ind, 'ground_word_prob']]\n",
    "        probs += results.loc[ind, 'probs']\n",
    "        probs = np.asarray(probs)\n",
    "                \n",
    "        #print(words, order)\n",
    "        shuffler = np.random.choice(range(len(words)), size =len(words), replace=False )\n",
    "        #print(len(words))\n",
    "        #print(shuffler)\n",
    "        \n",
    "        words = words[shuffler]\n",
    "        order = order[shuffler]\n",
    "        probs = probs[shuffler]\n",
    "        \n",
    "        question_answers = []\n",
    "        for w, p, o in zip(words,probs, order):\n",
    "            \n",
    "            if o=='ground_word':\n",
    "                w_p = (w,p,1)\n",
    "            else: \n",
    "                w_p = (w,p,0)\n",
    "        \n",
    "            question_answers.append(w_p)\n",
    "            \n",
    "        answer_orders.append(question_answers)\n",
    "        \n",
    "        #print('after', words, order)\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            file.write(str(i+1)+'. '+words[i]+' ')\n",
    "                \n",
    "        file.write('\\n \\n')\n",
    "        file.write('=====================================================')\n",
    "        file.write('\\n \\n')\n",
    "        \n",
    "with open(file_name_base + '_answers.txt', 'w') as file: \n",
    "    for ind, w_p in enumerate(answer_orders):\n",
    "        file.write('Prompt '+str(ind)+' : \\n')\n",
    "        for el_ind, el in enumerate(w_p): \n",
    "            file.write(str(el_ind+1) + '. '+str(el) +' ')\n",
    "        file.write('\\n')\n",
    "        file.write('=====================================================')\n",
    "        file.write('\\n')\n",
    "\n",
    "pickle.dump(answer_orders,open(file_name_base + '_answers_list.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(' events', 4.1035644926523673e-07, 1),\n",
       "  ('things', 0.0007781028398312628, 0),\n",
       "  ('events', 0.9782679080963135, 0),\n",
       "  ('bad', 0.0004916115431115031, 0),\n",
       "  ('Population', 7.025027803399253e-13, 0),\n",
       "  ('circumstances', 0.0005090322229079902, 0),\n",
       "  ('event', 0.0021306623239070177, 0)],\n",
       " [('would', 0.04294152930378914, 0),\n",
       "  (' would', 5.5134936701506376e-05, 1),\n",
       "  ('had', 0.09488712251186371, 0),\n",
       "  ('iterator', 1.5726539862037647e-11, 0),\n",
       "  ('are', 0.01786944642663002, 0),\n",
       "  ('were', 0.1237873062491417, 0),\n",
       "  ('could', 0.03562188893556595, 0)],\n",
       " [('side', 0.06683456152677536, 0),\n",
       "  ('counter', 0.16170549392700195, 0),\n",
       "  ('Plot', 1.6408815278756705e-11, 0),\n",
       "  (' edge', 1.6220442375924904e-06, 1),\n",
       "  ('sink', 0.08516162633895874, 0),\n",
       "  ('edge', 0.27985963225364685, 0),\n",
       "  ('table', 0.03213869407773018, 0)],\n",
       " [('an', 0.0551321804523468, 0),\n",
       "  ('me', 0.044027868658304214, 0),\n",
       "  ('the', 0.1713830679655075, 0),\n",
       "  ('my', 0.11777301132678986, 0),\n",
       "  ('conservancy', 2.3627343137544443e-11, 0),\n",
       "  (' a', 5.716932355426252e-05, 1),\n",
       "  ('a', 0.4161994457244873, 0)],\n",
       " [('oak', 0.011684752069413662, 0),\n",
       "  ('and', 0.023683885112404823, 0),\n",
       "  ('sky', 0.010126766748726368, 0),\n",
       "  ('Eat', 6.070240837763308e-11, 0),\n",
       "  ('sand', 0.011330608278512955, 0),\n",
       "  (' creek', 2.1538962613476542e-08, 1),\n",
       "  ('of', 0.013982990756630898, 0)],\n",
       " [(' is', 0.00020496858633123338, 1),\n",
       "  ('the', 0.029731499031186104, 0),\n",
       "  ('is', 0.07713856548070908, 0),\n",
       "  ('prototype', 4.2622644996770376e-11, 0),\n",
       "  ('makes', 0.047752413898706436, 0),\n",
       "  ('she', 0.04415161535143852, 0),\n",
       "  ('he', 0.22781696915626526, 0)],\n",
       " [(' adept', 1.2604008503558362e-08, 1),\n",
       "  ('simply', 0.008427090011537075, 0),\n",
       "  ('simple', 0.042511407285928726, 0),\n",
       "  ('young', 0.02360728196799755, 0),\n",
       "  ('deliberate', 0.014849836938083172, 0),\n",
       "  ('a', 0.03173162788152695, 0),\n",
       "  ('7601', 1.5810904668844827e-11, 0)],\n",
       " [('an', 0.03536023572087288, 0),\n",
       "  ('the', 0.051833175122737885, 0),\n",
       "  (' shock', 2.355513743168558e-06, 1),\n",
       "  ('a', 0.12715816497802734, 0),\n",
       "  ('cumbers', 2.3367134616147922e-11, 0),\n",
       "  ('his', 0.25678303837776184, 0),\n",
       "  ('thought', 0.03894629701972008, 0)],\n",
       " [('his', 0.05797092989087105, 0),\n",
       "  ('it', 0.05231691151857376, 0),\n",
       "  ('ODE', 1.615250251260636e-12, 0),\n",
       "  (' the', 3.8483194657601416e-05, 1),\n",
       "  ('one', 0.012323369272053242, 0),\n",
       "  ('the', 0.3601943552494049, 0),\n",
       "  ('your', 0.3757137954235077, 0)],\n",
       " [('social', 0.01845131814479828, 0),\n",
       "  ('medical', 0.010854171589016914, 0),\n",
       "  (' novel', 1.56093665282242e-05, 1),\n",
       "  ('research', 0.007366378325968981, 0),\n",
       "  ('design', 0.0036812543403357267, 0),\n",
       "  ('political', 0.014097815379500389, 0),\n",
       "  ('winner', 1.1857578807727975e-10, 0)],\n",
       " [('at', 0.13031087815761566, 0),\n",
       "  (' secretaries', 2.16605164360395e-10, 1),\n",
       "  ('rush', 7.324437063804812e-12, 0),\n",
       "  ('organized', 0.23333249986171722, 0),\n",
       "  ('people', 0.04803589731454849, 0),\n",
       "  ('organizers', 0.018733913078904152, 0),\n",
       "  ('in', 0.05454248562455177, 0)],\n",
       " [('their', 0.060859017074108124, 0),\n",
       "  ('Sexual', 1.827514528596197e-11, 0),\n",
       "  (' technology', 3.7967895423207665e-06, 1),\n",
       "  ('these', 0.09389566630125046, 0),\n",
       "  ('weapons', 0.13363923132419586, 0),\n",
       "  ('the', 0.20355582237243652, 0),\n",
       "  ('weaponry', 0.04151910915970802, 0)],\n",
       " [('whole', 0.019656933844089508, 0),\n",
       "  ('same', 0.3653627634048462, 0),\n",
       "  ('truth', 0.08678539842367172, 0),\n",
       "  ('other', 0.05399276316165924, 0),\n",
       "  ('story', 0.11716202646493912, 0),\n",
       "  ('cumbers', 1.6284040088576646e-11, 0),\n",
       "  (' Jews', 2.5805034056247678e-06, 1)],\n",
       " [(' trade', 1.0153305993299e-05, 1),\n",
       "  ('partner', 0.036993950605392456, 0),\n",
       "  ('Reviewed', 1.139088216112194e-11, 0),\n",
       "  ('place', 0.052271079272031784, 0),\n",
       "  ('chances', 0.011011623777449131, 0),\n",
       "  ('value', 0.019175605848431587, 0),\n",
       "  ('own', 0.06276622414588928, 0)],\n",
       " [('his', 0.5349603295326233, 0),\n",
       "  ('himself', 0.1009412407875061, 0),\n",
       "  (' his', 5.129267265147064e-06, 1),\n",
       "  ('the', 0.09639755636453629, 0),\n",
       "  ('CAST', 3.5308043381393484e-12, 0),\n",
       "  ('out', 0.05381551384925842, 0),\n",
       "  ('back', 0.045332636684179306, 0)],\n",
       " [(' his', 9.561581464367919e-06, 1),\n",
       "  ('Export', 1.5443222872377205e-12, 0),\n",
       "  ('her', 0.01833724044263363, 0),\n",
       "  ('him', 0.7251499891281128, 0),\n",
       "  ('his', 0.12334786355495453, 0),\n",
       "  ('the', 0.028482403606176376, 0),\n",
       "  ('it', 0.02939017489552498, 0)],\n",
       " [('able', 0.022882435470819473, 0),\n",
       "  ('Tokens', 5.895720543713789e-12, 0),\n",
       "  ('so', 0.15548737347126007, 0),\n",
       "  (' told', 2.7442727514426224e-05, 1),\n",
       "  ('the', 0.07520268857479095, 0),\n",
       "  ('too', 0.040511202067136765, 0),\n",
       "  ('a', 0.11381612718105316, 0)],\n",
       " [('DEM', 8.427578079839293e-12, 0),\n",
       "  ('smile', 0.024160809814929962, 0),\n",
       "  (' smile', 2.294330897711916e-06, 1),\n",
       "  ('new', 0.033361732959747314, 0),\n",
       "  ('man', 0.10321759432554245, 0),\n",
       "  ('pillow', 0.014958635903894901, 0),\n",
       "  ('lover', 0.01487671211361885, 0)],\n",
       " [(' we', 2.269794094900135e-05, 1),\n",
       "  ('money', 0.04252247512340546, 0),\n",
       "  ('I', 0.021786564961075783, 0),\n",
       "  ('we', 0.021743370220065117, 0),\n",
       "  ('that', 0.6679967641830444, 0),\n",
       "  ('the', 0.03396498039364815, 0),\n",
       "  ('Sax', 6.174503616729332e-12, 0)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('event', 0.0021306623239070177),\n",
       "  ('things', 0.0007781028398312628),\n",
       "  ('bad', 0.0004916115431115031),\n",
       "  (' events', 4.1035644926523673e-07),\n",
       "  ('circumstances', 0.0005090322229079902),\n",
       "  ('events', 0.9782679080963135),\n",
       "  ('Population', 7.025027803399253e-13)],\n",
       " [('iterator', 1.5726539862037647e-11),\n",
       "  (' would', 5.5134936701506376e-05),\n",
       "  ('would', 0.04294152930378914),\n",
       "  ('are', 0.01786944642663002),\n",
       "  ('could', 0.03562188893556595),\n",
       "  ('had', 0.09488712251186371),\n",
       "  ('were', 0.1237873062491417)],\n",
       " [('sink', 0.08516162633895874),\n",
       "  ('table', 0.03213869407773018),\n",
       "  ('Plot', 1.6408815278756705e-11),\n",
       "  ('counter', 0.16170549392700195),\n",
       "  ('edge', 0.27985963225364685),\n",
       "  ('side', 0.06683456152677536),\n",
       "  (' edge', 1.6220442375924904e-06)],\n",
       " [('a', 0.4161994457244873),\n",
       "  ('the', 0.1713830679655075),\n",
       "  ('me', 0.044027868658304214),\n",
       "  (' a', 5.716932355426252e-05),\n",
       "  ('conservancy', 2.3627343137544443e-11),\n",
       "  ('an', 0.0551321804523468),\n",
       "  ('my', 0.11777301132678986)],\n",
       " [('and', 0.023683885112404823),\n",
       "  ('sky', 0.010126766748726368),\n",
       "  ('of', 0.013982990756630898),\n",
       "  (' creek', 2.1538962613476542e-08),\n",
       "  ('oak', 0.011684752069413662),\n",
       "  ('Eat', 6.070240837763308e-11),\n",
       "  ('sand', 0.011330608278512955)],\n",
       " [('the', 0.029731499031186104),\n",
       "  ('is', 0.07713856548070908),\n",
       "  ('prototype', 4.2622644996770376e-11),\n",
       "  ('makes', 0.047752413898706436),\n",
       "  ('she', 0.04415161535143852),\n",
       "  (' is', 0.00020496858633123338),\n",
       "  ('he', 0.22781696915626526)],\n",
       " [('7601', 1.5810904668844827e-11),\n",
       "  (' adept', 1.2604008503558362e-08),\n",
       "  ('simple', 0.042511407285928726),\n",
       "  ('a', 0.03173162788152695),\n",
       "  ('deliberate', 0.014849836938083172),\n",
       "  ('young', 0.02360728196799755),\n",
       "  ('simply', 0.008427090011537075)],\n",
       " [('the', 0.051833175122737885),\n",
       "  ('cumbers', 2.3367134616147922e-11),\n",
       "  ('a', 0.12715816497802734),\n",
       "  ('an', 0.03536023572087288),\n",
       "  (' shock', 2.355513743168558e-06),\n",
       "  ('his', 0.25678303837776184),\n",
       "  ('thought', 0.03894629701972008)],\n",
       " [('it', 0.05231691151857376),\n",
       "  ('his', 0.05797092989087105),\n",
       "  ('the', 0.3601943552494049),\n",
       "  (' the', 3.8483194657601416e-05),\n",
       "  ('ODE', 1.615250251260636e-12),\n",
       "  ('your', 0.3757137954235077),\n",
       "  ('one', 0.012323369272053242)],\n",
       " [('medical', 0.010854171589016914),\n",
       "  (' novel', 1.56093665282242e-05),\n",
       "  ('political', 0.014097815379500389),\n",
       "  ('social', 0.01845131814479828),\n",
       "  ('winner', 1.1857578807727975e-10),\n",
       "  ('design', 0.0036812543403357267),\n",
       "  ('research', 0.007366378325968981)],\n",
       " [('in', 0.05454248562455177),\n",
       "  ('organizers', 0.018733913078904152),\n",
       "  ('rush', 7.324437063804812e-12),\n",
       "  ('at', 0.13031087815761566),\n",
       "  ('people', 0.04803589731454849),\n",
       "  ('organized', 0.23333249986171722),\n",
       "  (' secretaries', 2.16605164360395e-10)],\n",
       " [('the', 0.20355582237243652),\n",
       "  (' technology', 3.7967895423207665e-06),\n",
       "  ('their', 0.060859017074108124),\n",
       "  ('Sexual', 1.827514528596197e-11),\n",
       "  ('these', 0.09389566630125046),\n",
       "  ('weaponry', 0.04151910915970802),\n",
       "  ('weapons', 0.13363923132419586)],\n",
       " [('other', 0.05399276316165924),\n",
       "  ('story', 0.11716202646493912),\n",
       "  (' Jews', 2.5805034056247678e-06),\n",
       "  ('same', 0.3653627634048462),\n",
       "  ('whole', 0.019656933844089508),\n",
       "  ('cumbers', 1.6284040088576646e-11),\n",
       "  ('truth', 0.08678539842367172)],\n",
       " [(' trade', 1.0153305993299e-05),\n",
       "  ('partner', 0.036993950605392456),\n",
       "  ('value', 0.019175605848431587),\n",
       "  ('place', 0.052271079272031784),\n",
       "  ('own', 0.06276622414588928),\n",
       "  ('chances', 0.011011623777449131),\n",
       "  ('Reviewed', 1.139088216112194e-11)],\n",
       " [('CAST', 3.5308043381393484e-12),\n",
       "  ('his', 0.5349603295326233),\n",
       "  ('back', 0.045332636684179306),\n",
       "  (' his', 5.129267265147064e-06),\n",
       "  ('out', 0.05381551384925842),\n",
       "  ('the', 0.09639755636453629),\n",
       "  ('himself', 0.1009412407875061)],\n",
       " [('the', 0.028482403606176376),\n",
       "  ('it', 0.02939017489552498),\n",
       "  ('her', 0.01833724044263363),\n",
       "  (' his', 9.561581464367919e-06),\n",
       "  ('Export', 1.5443222872377205e-12),\n",
       "  ('his', 0.12334786355495453),\n",
       "  ('him', 0.7251499891281128)],\n",
       " [(' told', 2.7442727514426224e-05),\n",
       "  ('a', 0.11381612718105316),\n",
       "  ('Tokens', 5.895720543713789e-12),\n",
       "  ('too', 0.040511202067136765),\n",
       "  ('the', 0.07520268857479095),\n",
       "  ('able', 0.022882435470819473),\n",
       "  ('so', 0.15548737347126007)],\n",
       " [(' smile', 2.294330897711916e-06),\n",
       "  ('lover', 0.01487671211361885),\n",
       "  ('man', 0.10321759432554245),\n",
       "  ('smile', 0.024160809814929962),\n",
       "  ('pillow', 0.014958635903894901),\n",
       "  ('new', 0.033361732959747314),\n",
       "  ('DEM', 8.427578079839293e-12)],\n",
       " [('the', 0.03396498039364815),\n",
       "  ('that', 0.6679967641830444),\n",
       "  (' we', 2.269794094900135e-05),\n",
       "  ('we', 0.021743370220065117),\n",
       "  ('I', 0.021786564961075783),\n",
       "  ('money', 0.04252247512340546),\n",
       "  ('Sax', 6.174503616729332e-12)]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 3, 4, 3, 1, 4, 5, 4, 4, 2],\n",
       " [3, 2, 5, 1, 4, 5, 3, 5, 2, 4],\n",
       " [5, 4, 1, 5, 3, 5, 4, 5, 2, 2],\n",
       " [3, 5, 3, 5, 5, 3, 4, 5, 4],\n",
       " [3, 5, 2, 2, 3, 4, 4, 1, 5, 5],\n",
       " [5, 2, 1, 5, 2, 5, 4, 5, 1, 4],\n",
       " [1, 5, 5, 4, 5, 5, 5, 4, 3],\n",
       " [1, 1, 2, 1, 1, 5, 5, 5, 2, 4],\n",
       " [4, 1, 5, 5, 4, 3, 5, 3, 2, 2],\n",
       " [5, 2, 3, 4, 5, 5, 5, 5, 5, 4]]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[5, 3, 4, 3, 1, 4, 5, 4, 4, 2,], [3,2,5,1,4,5,3,5,2,4],[5,4,1,5, 3,5,4,5,2,2], [3,5,3,5,5,3,4,5,4], [3,5,2,2,3,4,4,1,5,5],[5, 2, 1,5,2,5,4,5,1,4], [1,5,5,4,5,5,5,4,3], [1,1,2,1,1,5,5,5,2,4], [4,1,5,5,4,3,5,3,2,2], [5,2,3,4,5,5,5,5,5,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for r in res: \n",
    "    print(len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = dict()\n",
    "for ind, (r, a) in enumerate(zip(res, answer_orders)):\n",
    "    for r_el, a_el in zip(r,a):\n",
    "        try:\n",
    "            prd[a_el[1]].append(r_el)\n",
    "        except:\n",
    "            prd[a_el[1]] = [r_el]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = pd.DataFrame(prd).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.438798e-02</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.133592e-01</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.043329e-02</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.023387e-06</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.646489e-11</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "1.438798e-02  5\n",
       "1.133592e-01  1\n",
       "1.043329e-02  5\n",
       "4.023387e-06  4\n",
       "4.646489e-11  5"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probs</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.438798e-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.133592e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.043329e-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.023387e-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.646489e-11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          probs  rep\n",
       "0  1.438798e-02    5\n",
       "1  1.133592e-01    1\n",
       "2  1.043329e-02    5\n",
       "3  4.023387e-06    4\n",
       "4  4.646489e-11    5"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.reset_index(inplace=True)\n",
    "#prd.drop('index', axis=1, inplace=True)\n",
    "prd.columns = ['probs', 'rep']\n",
    "prd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd['rep'] = prd['rep']*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x821a70fd0>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do a scatter plot of this. \n",
    "plt.scatter(prd['probs'], prd['rep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rep</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.083610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.023622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.054777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        probs\n",
       "rep          \n",
       "2    0.081718\n",
       "4    0.025102\n",
       "6    0.083610\n",
       "8    0.023622\n",
       "10   0.054777"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = prd.groupby('rep').mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x822685400>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(means['probs'], means.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_plot_columns(prd, 'TFS is tighter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAFACAYAAACcBJbJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAH4pJREFUeJzt3Xm4XFWZ7/HvjwDKPEgAGZIIKgqKqAH0yhWlHRAEvKAIDQgqxqFtZwG9dnew1cahW7tRW3FCVKS1FQcmBSVIRJAEAjJIKxiIjAEEAgoIvP3HWkV2KlWn6oSza9eq+n2e5zynau9d+11r7aq3Vq09KSIwM7NyrNZ0AczMbHKcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GNIUkh6co3rn5VjrN5l/gclfbnTspLOlHR4XWWzFUm6V9I2Ta2z7vfiqHLiBiQtlvSgpE3apl+a31izBlyeF0l6JH8Alkm6RtLrB1mGOkXExyLiyC7zXhERXweQdISk+asaR9JWkr4n6XZJd0u6QtIRq7q+Qcnvx9skrVOZdqSkeVMdKyLWjYjrJlG2D+b35b2S7pf0cOX5lauyzgliPabtP8qcuJf7A3Bw64mkZwJrN1ccboqIdYH1gXcDX5K0XYPlKdE3gCXATOAJwGHArVMZoNuviikwDXhnTeteZflLd9383nwL8KvW84jYoenyVdW4bRrnxL3cN4DXVZ4fDpxUXUDS4yR9StINkm6V9AVJa+V5G0k6TdJSSX/Kj7eqvHaepH+W9Mvci/5pew+/k0jOAO4Edqys72mSzpZ0Z+6RH1iZd2Iu29k51nmSZnZav6S98y+LeyQtkTS3bf5uki6QdFeef0Q/r8veIOkmSTdLel9lnXMlfbNLeebl3uXTgS8Az8+9ubsk7ZzbfVpl+f0lXdal+XYGToyI+yLioYi4NCLO7KNuG0g6KW/L6yV9SNJqed4ReRt+WtIdwNw8/Q2Srs7b/ifd2nsSPgm8T9KGHdpopaGoVrtVnr8pl2eZpKskPadTEFWGKiTtlZddJunG6jabjLZ1PkHSj/P75GJJH+nQi36JpN/l7fA5JStt/7y+iT6DL5L0R0lHS7oF+NqqlL8ETtzLXQisL+npOTEcBLQnl+OApwI7AU8GtgT+Mc9bjfRGmQnMAP4CfLbt9X8LvB7YFFgT6PnBkLSapH2BTYDf52nrAGcDJ+d1HQR8XtL2lZceAvxzft0i4FtdQtxH+sLaENgbeKukV+U4M4EzgeOB6bnei3q9ruLFwFOAlwFHS3pJr/q2RMTVrNij2zAiLgbuyOtrOYy2L9iKC4HPSTpI0ozqjB51Ox7YANgG2D3XszpUtStwHbAZ8FFJ+wEfBPbP6zof+Ha/de1iATCPPt4j7SS9hvSF8jrSL7Z9Se3Wy1eAN0fEesAzgJ9PNnYHnyO9VzYndYY67b94JelLdkfgQODlnbZ/XnaizyA5zsakz+GcKSj/cIqIsf8DFgMvAT4E/AuwJykxrg4EMAsQ6Q24beV1zwf+0GWdOwF/qjyfB3yo8vxtwFldXvsi4BHgLuAB4GHgXZX5rwXOb3vNF4F/yo9PBE6pzFs3r2Pr/DyAJ3eJ/Rng0/nxB4BT+2zD6utm5RhPq8z/BPCV/Hgu8M22ZVevtNOR+fERwPy2OEcD38qPNwb+DDyxS5k2In3Qr8z1XwTsPFHdSEMUDwLbV6a9GZhXKdMNba85E3hj5flquVwzH+P78RnA3aQvgyMrZVihzTq020+Ad/YZ69H3AnBDruv6fb52pe1TXWduy78C21XmfaT6mrzsbpXn3wGO6bR+enwGSZ+bB4HHr0q7l/TnHveKvkHqFR/Byr246aQx74X5J91dwFl5OpLWlvTF/NP6HuAXwIbVn/XALZXHfyYl1G5uitTLWB/4D2CPyryZwK6tcuSyHELqbbQsaT2IiHtJQy1btAeRtKukc/OwwN2kXk5rCGdr4NpOhevxupXKAFzfKf4q+CawT/7VcSDpC+zmTgtGxJ8i4phIY6+bkRL3DySJ7nXbBFgjl7da9i0rz5ewopnAv1e2xZ2kJLNl23Lkn/atnXkfnKiiEXEFcBpwzETLddB1u/VwALAXcL3S8NrzV2EdVdNJnZ9qe7W3HfT/uZjwM5gtjYj7V73IZXDiroiI60k7KfcCvt82+3bS8McOkX62bxgRG0TaSQPwXmA7YNeIWB94YZ6ux1imB0i9zGdWhiKWAOdVyrFhpJ+Tb628dOvWA0nrknqnN3UIcTLwI1JvfAPSuGKrzEuAbbsUbaLXrVQG0vBRp/gTWenSlRFxI/Ar0rDEYaQv294rirgd+BTpy2NjutftdlIvsTpGPQO4cYJyLSENMVS3x1oRcUGHcrwllu/M+1gfRf8n4E2s+CVwX/5f3Xne/qXdbbt1FREXR8R+pOG3H5B6v4/FUuAhYKvKtK27LNuxSG3Pe30GO71mJDlxr+yNwB4RcV91YkQ8AnwJ+LSkTQEkbSnp5XmR9UhvqrskbUz6wE2JiHgQ+FeWj+WdBjxV0mGS1sh/O+cdOi175Z1va5LGui+MiE69nfWAOyPifkm7kH5xtHyLtOPoQEmr5x1NO/XxupZ/yL9EdiCNEf/XJKt+K7BVrkPVScBRwDNZ+Qv2UZI+LukZuezrAW8Ffh8Rd3SrW0Q8TEpYH5W0Xh4Lfw8r7++o+gLwgVzP1s7N10yyrh1FxO9J7faOyrSlpC+SQyVNk/QGVkzUXybt2Hxu3tH3ZPXYWSppTUmHSNogIv4K3EMarnssZX+YtH3m5vfB01jxAIBeVtj+fXwGx4YTd5uIuDYiFnSZfTRpB+GFeTjkHFIvG9IY71qkXsGFpJ9wU+mrwAxJ+0TEMtIOuoNIvdhbgI8Dj6ssfzLpy+NO4LnAoV3W+zbgw5KWkb4YHu1lRcQNpF8f783rWQQ8q9frKs4jtdfPgE9FxE8nWeefk8anb5F0e2X6qaQe8akR8ecJXr92XvYu0s7EmaQddb3q9vekXu11wHxSW361W5CIOJXU/qfk98UVwCsmU9EePgys0zbtTcD7STsddwAe7d1HxHeBj+ZyLyP1njfuI85hwOJch7eQht8eq7eTdvTeQvp19G3Sfpt+dNr+E30Gx4byoL6NEEknAn+MiA81XZa6SLqWNDxxTtNlsf5J+jiweUT47NjHwD1uK46kA0hjmVNxuJrVSOl8gx3zkM0upKHIU5suV+lG9swiG01Kp31vDxyWxzxtuK1HGh7ZgjRm/a/ADxst0QjwUImZWWE8VGJmVhgnbjOzwtQyxr3JJpvErFmz6li1mdlIWrhw4e0RMb33kjUl7lmzZrFgQbdDoc3MrJ2k63svlXioxMysME7cZmaFceI2MyuME7eZWWGcuM3MCtPXUSWSFpOuMvYw8FBEzK6zUGZm1t1kDgd8cb4YvZmZNchDJWZmhem3xx3ATyUF8MWIOKF9AUlzyHdVnjFjRvtss45mHXN67TEWH7d37THMBqnfHvduEfEc0l09/k7SC9sXiIgTImJ2RMyePr2vszbNzGwV9JW48w1aiYjbSBdB36XOQpmZWXc9E7ekdfKNVpG0Duleh1fUXTAzM+usnzHuzYBTJbWWPzkipvpGuGZm1qeeiTsirmP53a/NzKxhPhzQzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwKU8s9Jx+LJk+B9unXZlYC97jNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwKM3RnTo4rn7VpVq9R+oy5x21mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlYYJ24zs8L4lHezMTNKp36PK/e4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysMH0nbknTJF0q6bQ6C2RmZhObTI/7ncDVdRXEzMz601filrQVsDfw5XqLY2ZmvfTb4/4McBTwSI1lMTOzPvRM3JJeCdwWEQt7LDdH0gJJC5YuXTplBTQzsxX10+N+AbCvpMXAKcAekr7ZvlBEnBARsyNi9vTp06e4mGZm1tIzcUfEByJiq4iYBRwE/DwiDq29ZGZm1pGP4zYzK8ykrg4YEfOAebWUxMzM+uIet5lZYZy4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWGcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrzKRupGBmU2PWMafXHmPxcXvXHsOa4R63mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYXzmpJkNjM8YnRrucZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWF6Jm5Jj5f0a0mXSbpS0rGDKJiZmXXWz+GADwB7RMS9ktYA5ks6MyIurLlsZmbWQc/EHREB3JufrpH/os5CmZlZd32NcUuaJmkRcBtwdkRcVG+xzMysm74Sd0Q8HBE7AVsBu0h6RvsykuZIWiBpwdKlS6e6nGZmlk3qqJKIuAs4F9izw7wTImJ2RMyePn36VJXPzMza9HNUyXRJG+bHawEvBX5bd8HMzKyzfo4qeSLwdUnTSIn+OxFxWr3FMjOzbvo5quRy4NkDKIuZmfXBZ06amRXGidvMrDBO3GZmhXHiNjMrjBO3mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWGcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrjBO3mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVpmfilrS1pHMlXSXpSknvHETBzMyss9X7WOYh4L0RcYmk9YCFks6OiKtqLpuZmXXQs8cdETdHxCX58TLgamDLugtmZmadTWqMW9Is4NnARXUUxszMeus7cUtaF/ge8K6IuKfD/DmSFkhasHTp0qkso5mZVfSVuCWtQUra34qI73daJiJOiIjZETF7+vTpU1lGMzOr6OeoEgFfAa6OiH+rv0hmZjaRfnrcLwAOA/aQtCj/7VVzuczMrIuehwNGxHxAAyiLmZn1wWdOmpkVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWGcuM3MCuPEbWZWmJ7X4zYbVbOOOb32GIuP27v2GDZ+3OM2MyuME7eZWWGcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrjBO3mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoXpmbglfVXSbZKuGESBzMxsYv30uE8E9qy5HGZm1qeeiTsifgHcOYCymJlZHzzGbWZWmCm7WbCkOcAcgBkzZkzVam0AfNNcs7JMWY87Ik6IiNkRMXv69OlTtVozM2vjoRIzs8L0czjgt4FfAdtJ+qOkN9ZfLDMz66bnGHdEHDyIgpiZWX88VGJmVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWGcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrjBO3mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlaYvhK3pD0lXSPp95KOqbtQZmbWXc/ELWka8DngFcD2wMGStq+7YGZm1lk/Pe5dgN9HxHUR8SBwCrBfvcUyM7Nu+kncWwJLKs//mKeZmVkDFBETLyC9GtgzIo7Mzw8Ddo2It7ctNweYk59uB1wz9cXtaBPg9gHFcuzxjt10fMce7dgzI2J6Pwuu3scyNwJbV55vlaetICJOAE7oq3hTSNKCiJg96LiOPX6xm47v2OMVeyL9DJVcDDxF0pMkrQkcBPyo3mKZmVk3PXvcEfGQpLcDPwGmAV+NiCtrL5mZmXXUz1AJEXEGcEbNZVlVAx+eceyxjd10fMcer9hd9dw5aWZmw8WnvJuZFcaJ28ysME7cZmaF6Wvn5DCRtDbwdiCA40mHJ+4P/Bb4cETcW2PsacCRpGPZz4qIX1bmfSgiPlJX7AnK9JSI+N0A4igiQtLqpGvWXB8Rd9cdt0eZToiIOb2XfMxxpkXEw23TNoqIP9UduxJv44i4c0Cx9p9ofkR8fxDlqJK0bp2f7dKU2OM+EdgMeBJwOjAb+CQg4D9rjv1FYHfgDuA/JP1bZd6Eb/Ya/azOlUvaV9ItwE2SXgnMJ31hXiVp7zpj5/gbd/l7ArBXzbF3l3QDcJukMyTNqMyurd0lvUDS1ZKulLSrpLOBiyUtkfT8uuJW7JP/3gh8BTgk/30ZeMMA4ndyVZ0rl/RMSRfmNj5B0kaVeb+uM/aqKK7HDTw1Ig6UJOBm4CW5JzgfuKzm2LtExI4Akj4LfF7S94GDSV8ctWj7glhhFrBBXXGzY4FnA2sDl5Iud3C1pCcB3yF9edZpKXA9K7Zv5Oeb1hz7U8Argd8ArwXOkXRIRFxMjdsb+DRwILAuqX1fFRHzJT2H9KX5ghpjExGvB5D0U2D7iLg5P38iqeNUC0nv6TaL1BZ1+k9gLnAh6Vf1fEn7RsS1wBo1x560EhM3ADlZnxH5eMb8vO5jG9esxH8ImCPpH4GfU+8baw5wFPBAh3l/rTEuAJUP7g0RcXWe9oc8dFS364C/iYgb2mdIWtJh+am0ZkRcnh+fIulK4L8lvY/05VGXNSLiNwCSlkbEfICIuETSWjXGbbd1a9tntwIzui08BT5G+vX8UId5dY8OrBcRZ+XHn5K0EDgrX5tp6I6ZLjFxL2iNd0XEoz/bJG0LLBtA7D0rG5iI+LCkm6h3mOZi4NKI+FX7DElza4ybQ2i1iHgEeFNl4mpUvshq9BlgI2ClxA18oubYD0naLCJuBYiI30h6KXAaMKvGuNUk9YG2eYNo85afSfoJ8O38/LXAOTXGuwT4QUQsbJ8h6cga47ZibNDabxMR50o6APgesHHdsSdrpE7Aae1Aa7ocU03SdODPEXFfA7GfByyKiPvbps8Cdo+Irw+6TIMi6eXArRGxqG36RsA7IuLYmuLuC5wTEX9um74tcEBE1P2FVY35/4AX5qe/iIhTa4y1HXBHRKx0Nb7qF2hNsf8WuC4iLmybPgP4h4h4U+dXNmMkEvegji4YptiSdqz8jB+b2Dl+k9u7kbpL2jwibhlgvGmkL48XDypml3IMtN7DEruXEo8q6aTJyy42FfvEhuI2HRua3d4nNhR3oNcKyoc/PiKp7p3fvTR5jaRhvT5TkWPcndw2hrHrPKphmGNDs9u7qbo3Efde4Df5cMRHh+ki4h0DLMM4v8+7GonEHRF7jmHsgZ/sMySxG93eNFf3LzUQ8/v5r0lN1HsYYk+ouDHufDTDEcABpDMYHwb+B/hCRMwbxdiSdpxofp1jrk3GzvGb3N6N1r2tLAM7c7It7prAU/PTayKi9sNP2+I3Uu+mY/dSYuL+GumEjHOAVwP3AOcDRwM/jIjjRy22pPMnmB0R8cIJ5hcbO8dvcns3Uvfq5RMkbQ/8gHQSiIDXRsRFdcTtUI4XAV8HFufYWwOHR8QvaorXWL2Hpc37FhFF/QGXtz2/MP9/HHD1qMYe179xbHPgksrj04FX5Me7ABcMsBwLge0qz58KLBzFeg9Lm/f7V+IY918lbRsR1+ZTgB8EiIgHBnDmZCOxJe0eEefl43tXEhG13QO0ydhZY9t7COoOsEVEnJnj/XrAZ06uERHXtJ5ExP9IGtTp303Wu8nYfSkxcb8fOFfSA6TyHwSPnqRy2ojGfilwHvCaDvOCem/e3GRsaHZ7N1X3bST9iPQzfStJa8fyk3EGed2MBZK+DHwzPz8EWFBjvCbrPSxt3pfixrghnSEJPCE6nGE1yrHH1bi1uaTd2yYtjIh7JW0GvDoiPjegcjwO+DtgtzzpfODzEdHpmjlTEa+xeg9Lm/eruMSdT0G9LSLuzx/oI4DnkC77+KVIF38audiVMrwc2AF4fGtaRHys7rhNxR6GNs/laKzdmyLpb0jju39puiy2ohLPnDyD5eU+DtgbuAjYmfrvyNxkbCR9HjgceA+wFnAo8OS64zYcu9E2h8HXXdJqkl4v6TRJl0m6RNIp+SiPQXodcJnSdao/KWkfVa5TPdWarPcQtXlfSuxxXxUR2+fHC4GdI125DkmXRcSzRjF2jnF5ROzYiiVpPeD0qPmQvCZjN93mOc5A697kIZBdyrNFLsf7SDvuatk3No6H+q6qEnvcSyTtkR8vJh1bitIdUUY5NkDrJ+v9kjYH7ge2GPHYTbc5DL7uz42IuRExPyLeBbwsIs4m/dp4W41xVyDpUElfBP4beAnwWeD/1hiyyXoPRZv3q8SjSo4ETlK6DvXdwCJJi4ANST9lRzU2wJmSNiTdmWUR6SzCQV1WtanYTbc5DL7uTR7yWvUZ4FrgC8C5EbG45nhjd6jvqipuqKRF0tNJJwSsDvwRuLj1E3rUYkt6Xqx8neC1gLWi5lNym4zdFnPg27upuudfGCeS7ni0OnBQRFyUD4F8f0QcVVfsDmXZgXQ97t2Ap5BOez+spliN1XuY2rwfxSbucSLpkoh4zrjFblrD7d74IZCS1ifd33J30hDJJqQzVw+vMaYP9e1DiWPcXUkayFEGwxZ7XI1ym0fS6U4wmw+wGPNJd3u/nHS9ju3qTNrQbL2HpM37MlI9bknPjQ73qys9tqS7gK4X9omIjqdklx67l7q39zDWXdLpEbH3oON2Iun4iPj7AcVqrN7D1OYtI5W4R5Wk35F20nUUEeeNYuymjXPd+zHOw2hNK+6oEqVbKX0AeBWwKemaEbcBPwSOi4i7RjD2sgaTRJOxG93eNFj3PN66C7BlnnQj8OsY8Z5Wk/Uuqc1LHOP+DvAn4EURsXFEPAF4cZ72nRGNvbjGdQ9zbGh2ey+uef0dSXoZ8DtgLrBX/jsW+F2eN5KarHdpbV7cUImkayJiu8nOKz12Jc7/AWZR+bUUESfVHbep2MPQ5jnWwOou6WrS9aAXt01/EnBGRDy9jriTJenSiHj2FK6vsXqX0uYtxQ2VANdLOgr4ekTcCqB0Ba8jgCUjHBtJ3wC2ZflJIJCGDmpP3A3GbrTNc7xB1711rHq7GxmuS4z++xSvr8l6l9LmQJmJ+7XAMcB5kjbN024lXRv5wBGODTAb2L6hMbemYjfd5jD4un8VuFjSKSz/ctqadC3yr9QdXNKPSV9MHbWOpomIE6c4dJP1brTNJ6u4oZJ+STo8IgZ1OvhAYkv6LvCOiLh5qtc9zLH7Uef2bqLu+UzR/VhxR9mPIuKqAcRuXZt6f2Bzlt9I4WDg1oh4d42xm6x3Y7Ena5QT98idbSjpXGAn4NekU3OBwRxP3GTsftS5vYe17pK+FxEH1Lj+BRExu9e0Qau73sMau6rEoZJ+aQRjz61pvcMeux91bu+5Na77sdim5vWvI2mbiLgOHt1Rt07NMftRd72HNfajRjlxN/lTopbYTR5PXcDJJrVt7yGue93v8XcD8yRdR/pinAm8ueaY/Ri5z/ZkjXLiHpket6RldH7DiHSJhfWnMt6wxJ6kKd/eBdW9FhFxlqSnAE/Lk34bNd1v0ian2MStdCPTA1j52NoP54e/HJXYEbHeVK6vlNhVTWzvYan7BAbROXkuy9v8WZIGdt7ABEamU7aqik3cpFOe7wYWUtlh1BIRbx/R2ONqrNtc6V6PW0fE5ZXJR9ccs7HzBiplGHi9hyF2L8UeVSLpioh4xrjFHlfj2OaS5gH7kjpYC0nXaPllRAzkzj/5bMKBH7vfZL2bbvN+lXitkpYLJD1zDGOPq3Fs8w0i4h7S8dQnRcSupHs/DsoVpOO4B63Jejfd5n0peahkN+AISX8g/XRu7TDaccRjj6txbPPVJT2RdIbo/28g/ibAVZIGffx6k/Vuus37UnLifsWYxh5X49jmxwI/AeZHxMWStiFdwW5Q5g4wVlWT9W66zftS7Bi32aiS9PGIOFrSayLiu02XZ1CarHdpbe7EbTZkJP0G2BFY2NRlG3I5qsexr0m6St59dR2/3mS9h6XN+1XyUInZqDqLdKOIdSXdU5k+0BN/qsex57vD7Ac8r8aQTdZ7KNq8X+5xmw0pST+NiJe1TftERBzVYJmm9OYJXWI0Vu9hbPNOSj4c0GzUbdJh2p6DCi5p/8rfqyUdB9w/gNBN1rvRNu+Xh0rMhoyktwJvA7aRVD1rbz3gggEWZZ/K44dI9+Dcr65gTdZ7iNq8Lx4qMRsySne23wj4F9Ldf1qWRcSdzZSqfk3Wu7Q2d+I2s44kbQUcD7wgTzofeGdEdLo3ow2Qx7jNrJuvke7tuUX++3GeZg1zj9vMOpK0KCJ26jXNBs89bjPr5g5Jh0qalv8OBe5oulDmHreZdSFpJmmM+/mkMygvIN3t/oZGC2Y+HNDMViZpGrB/03eyt848VGJmK4mIh4GDmy6HdeahEjPrSNKnSReW+i/gvtb0iLiksUIZ4MRtZl1IOjc/bCWJ1gWX9mioSJZ5jNvMujmNlLRbdzYP4B5JO0XEouaKZe5xm1lHkk4GZpNOwhHwSuByYBbw3Yj4RHOlG29O3GbWkaRfAHtFxL35+brA6aSr5S2MiO2bLN8481ElZtbNplRuEgz8FdgsIv7SNt0GzGPcZtbNt4CLJP0wP98HOFnSOsBVzRXLPFRiZl1Jms3yqwP+MiIWNFkeS5y4zcwK4zFuM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrzP8CNbSzl5FHT5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_plot_columns(nuc_tighter, 'Nuc is Tighter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want when Nuc is tighter for the difference between Nuc and TFS to be smaller than it is when TFS is tighter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: 1 = 0.3999999999999999\n",
      "position: 2 = 0.6000000000000001\n",
      "position: 3 = 0.7999999999999998\n"
     ]
    }
   ],
   "source": [
    "abs_diff_of_different_locations(tfs_tighter, tfs_label, n_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: 1 = 1.75\n",
      "position: 2 = 0.25\n",
      "position: 3 = 1.25\n"
     ]
    }
   ],
   "source": [
    "abs_diff_of_different_locations(nuc_tighter,tfs_label, n_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
