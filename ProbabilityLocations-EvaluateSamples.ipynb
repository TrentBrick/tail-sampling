{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the difference between nucleus and TFS set of words. See if the words in this set are reasonable. They should be reasonable for when TFS is looser and should not be when TFS is tighter. Out of this set of words, take the highest, lowest prob ones and the middle one? Need at least 3 word gap between them. \n",
    "Rank each one in how reasonable it is. Control baseline is how reasonable words at different points in the body are. The first word, half way and at the closer of the tails. Can also get words outside of the last tail, just outside, halfway to the end, and at the very end. \n",
    "There are 9 different words in total. Should i rank all of them, scramble up a subset? Or have a ranking for each of the subsets differently? Probably scramble them all up. And then present 3 of them??\n",
    "Can then see overall how replaceable different parts of the distributions is, and for TFS and nucleus specifically. Have a control with the bad words. And should be able to hopefully show that the difference in replaceability between the TFS and nucleus words is small when TFS is looser and large when TFS is tighter. Can see how specific this is also. Eg could just look at the last TFS and nucleus words, see the diff in replaceability, or maybe need to look at the averages. Look most at this unique subset and these three points should hopefully categorize it. Want them because i dont know how good the signal is going to be. For the closest words for example. \n",
    "Can also get overall data on how replaceability corresponds to model probability. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pandas as pd    \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decodeLogits import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\\n'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#updated\n",
    "vals_dict = {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99],\n",
    "'n': [0.5, 0.63, 0.69, 0.81, 0.75, 0.9], 'k':[1,40,200]  }\n",
    "\n",
    "\n",
    "''' {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\n",
    "'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing analysis for the same logit going to use the ground truth as it is a Schelling point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=25\n",
    "num_batches=4\n",
    "prompt_length=100\n",
    "generated_length=150\n",
    "tot_len = prompt_length+generated_length\n",
    "\n",
    "import encoder\n",
    "from decodeLogits import *\n",
    "model_name='774M' #345M\n",
    "models_dir='../gpt-2/models'\n",
    "enc = encoder.get_encoder(model_name, models_dir)\n",
    "\n",
    "prompts=pd.read_csv('test_dataframe_500primer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_out_path = 'gpt-2_output/'\n",
    "additional_path = '-model_774M-seed_27'#'' \n",
    "#all_perps = pickle.load( gzip.open(gpt_out_path+'all_perplexities_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb'))\n",
    "all_logits = pickle.load( gzip.open(gpt_out_path+'all_logits_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb')) # needed to get the probabilities\n",
    "text = pickle.load( gzip.open(gpt_out_path+'all_text_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n",
      "24\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_num = 0\n",
    "mapping_to_batch = dict()\n",
    "for i in range(num_batches):\n",
    "    num_in_batch = all_logits[i].shape[0]\n",
    "    for el, b_ind in zip(range(tot_num, tot_num+num_in_batch), range(0, num_in_batch)):\n",
    "        mapping_to_batch[el] = (i, b_ind) # actual batch and then the ind in that batch\n",
    "    print( num_in_batch)\n",
    "    tot_num+= num_in_batch\n",
    "tot_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 150, 50257)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Want to generate things that are at the different probability levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at max deviation and getting these points within the tails of each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to also focus on the maximum deviation portions at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(29) # 1 used 27, 2 used 28, 3 used 29. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random prompts and locations within the 150 generation locations\n",
    "\n",
    "num_prompts_and_timepoints_wanted = 50 # cant be larger than 100 right now!!!\n",
    "assert num_prompts_and_timepoints_wanted <=100\n",
    "leading_prompt = 15\n",
    "\n",
    "want_min_max = False\n",
    "\n",
    "if want_min_max==True:\n",
    "    minmax = pd.read_csv('Min_Max_Disagreement_Coords_TFS90.csv')\n",
    "    #shuffle it and take the number that is wanted. \n",
    "    minmax = minmax.sample(frac= num_prompts_and_timepoints_wanted/minmax.shape[0])\n",
    "    display(minmax.head())\n",
    "    \n",
    "else:\n",
    "    rand_prompts = np.random.randint(0,tot_num, num_prompts_and_timepoints_wanted)\n",
    "    # leadingprompt until 150. as the logits are 150 not 250. \n",
    "    # -1 because of the end token prediction\n",
    "    rand_times = np.random.randint(0,generated_length-1, num_prompts_and_timepoints_wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_logits[0][0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting random locations\n",
    "for the differnet gen strategies. find the tail locations. take the tokens at each position. \n",
    "move onto the next random location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(model_name, models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x8221b8400>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXwU9eH/8ddnc993QghHuK+A3JcHIB54cmgrKmg9ilZbKz39trb219rDam1VRMX7quKBR70Aq1JEBEM4EiDcZyAQICThSkjy+f2RhdJIICS7O7ub9/Px2Ec2s7PO28nmzWRmPjPGWouIiAQel9MBRESkaVTgIiIBSgUuIhKgVOAiIgFKBS4iEqBCfbmw1NRUm52d7ctFiogEvCVLluyx1qbVn+7TAs/OziY3N9eXixQRCXjGmC0nm65dKCIiAUoFLiISoFTgIiIBSgUuIhKgVOAiIgHqtAVujHnOGLPbGFNwwrRkY8xcY8w699ck78YUEZH6GrMF/gIwpt60e4B/W2u7AP92fy8iIj502gK31v4H2Fdv8ljgRffzF4FxHs71P+au2sXri7d6cxEiIgGnqfvAM6y1OwHcX9MbmtEYM8UYk2uMyS0pKWnSwt7M3cbv/rWSLXsPNi2tiEgQ8vpBTGvtDGvtQGvtwLS0b40EbZTfj80hzOXiV+/koxtQiIjUaWqB7zLGZAK4v+72XKRva5UQyS8v6c6C9Xt5O6/Im4sSEQkYTS3w94Eb3c9vBN7zTJyGXTe4HYOyk/jDB6soqaj09uJERPxeY04jfA1YCHQzxmw3xtwC/AW40BizDrjQ/b1XuVyGP0/ozeGqGn7/wSpvL05ExO+d9mqE1tprG3hptIeznFbn9DjuHNWZv3+6lvH9WnN+9wxfRxAR8RsBNxLzByM70TUjlnvfKeBAZbXTcUREHBNwBR4e6uLPE/qws/wID81e43QcERHHBFyBAwxon8QNQ9vz4sLN5G0tdTqOiIgjArLAAX4+pjut4iO55+0VVFXXOh1HRMTnArbAYyNCuX9cDmt3HeCpeRucjiMi4nMBW+AAo3tkcHmfTB77bD3rdx9wOo6IiE8FdIED3HdFL6LCQ/i/WSuordUwexFpOQK+wNPiIvj1ZT34ZnMpr32jKxaKSMsR8AUO8J0BbRjeKYW/fFRIcdkRp+OIiPhEUBS4MYY/je9NVU0t971fcPo3iIgEgaAocIDs1BimXtiV2St38UnBTqfjiIh4XdAUOMCt53SgZ2Y8v3lvJWWHjzodR0TEq4KqwENDXDxwVR/2HqjkLx8XOh1HRMSrgqrAAXq3SeCWczrw2uKtfL1xr9NxRES8JugKHGDqhV1pmxzFr2blc+RojdNxRES8IigLPDo8lD+N783GPQeZ9tl6p+OIiHhFUBY4wLld0pjQP4sn521g9c5yp+OIiHhc0BY4wG8u60lCVBj3zMqnRsPsRSTIBHWBJ8WE89srerJ8235e+Gqz03FERDwqqAsc4MqzWjOqWxoPzi5k3a4Kp+OIiHhM0Be4MYYHru5DTHgoP3ptqc5KEZGgEfQFDpAeF8mD3+lDYXGFBviISNBoEQUOcH73DL43PJsXvtrMZ4W7nI4jItJsLabAAe65pDvdW8Xx8zdXsLtcl50VkcDWogo8MiyEx67tx8Gqan765nLdwUdEAlqLKnCALhlx/Obynsxft4dnv9zkdBwRkSZrcQUOcN3gdlzUM4O/zi4kf3uZ03FERJqkRRa4MYYHrupDSkwEd72+lIOV1U5HEhE5Yy2ywKFulObfr+nL5r0H+X//Wul0HBGRM9ZiCxxgWKcU7hjZiTdyt/PBih1OxxEROSMtusAB7r6gK33bJvJ/s/LZXnrI6TgiIo3W4gs8LMTFoxP7YS3c/foyqmtqnY4kItIoLb7AAdqlRHP/uBxyt5TymG4AISIBQgXuNq5fFhP6ZfHYZ+v4ZvM+p+OIiJyWCvwEvx+XQ5ukaO5+fRllh446HUdE5JSaVeDGmKnGmJXGmAJjzGvGmEhPBXNCbEQoj17bj13lR/jVO/lYq6H2IuK/mlzgxpgs4C5goLU2BwgBJnoqmFP6tk3kJxd15cP8nbyZu93pOCIiDWruLpRQIMoYEwpEA0FxMvXt53VieKcU7nt/JRtKDjgdR0TkpJpc4NbaIuAhYCuwEyiz1s6pP58xZooxJtcYk1tSUtL0pD7kchke/m5fIsNc3PXaUiqrdRcfEfE/zdmFkgSMBToArYEYY8yk+vNZa2dYawdaawempaU1PamPtUqI5IGr+rByRzkPzV7jdBwRkW9pzi6UC4BN1toSa+1RYBYw3DOx/MNFvVoxeWh7np6/iXlrA+OvBxFpOZpT4FuBocaYaGOMAUYDqz0Ty3/8+rIedM2I5Sczl2movYj4lebsA18EvAXkAfnu/9YMD+XyG5FhITwxaQBV1bVMeWkJh6u0P1xE/EOzzkKx1t5nre1urc2x1k621lZ6Kpg/6ZQWy6PX9mN1cTk/f2u5zg8XEb+gkZiNNKp7Or+4uDsfrNjJ9C82OB1HREQFfiZuH9GRsX1b89CcNXy6apfTcUSkhVOBn4Fjt2Lr1Tqeu2cuY/3uCqcjiUgLpgI/Q5FhIcyYPJDIsBBufTFXF70SEceowJugdWIUT07qT9H+w/zwtTzdBEJEHKECb6KB2cn8YWwO89ft4YFPCp2OIyItUKjTAQLZxMHtWL2znKfnb6JHZjwT+rdxOpKItCDaAm+mey/vybCOKdwzK59l2/Y7HUdEWhAVeDOFhbh4/Pr+pMdFcNvLuewuP+J0JBFpIVTgHpAcE87TNwyk4kg1t72yhCNHNdxeRLxPBe4hPTLj+dt3zmLp1v3c+26BhtuLiNepwD3okt6Z3DW6C28t2c7zCzY7HUdEgpwK3MPuHt2Fi3tl8MePVvPluj1OxxGRIKYC9zCXy/C37/alc1osd/4zjy17DzodSUSClArcC2IjQnn6hoEYA99/KZcDldVORxKRIKQC95J2KdE8fl1/NpQcZOrMZdTW6qCmiHiWCtyLzu6cyr2X9WDuql38/dO1TscRkSCjofRe9r3h2RTurOCxz9aTER/JpKHtnY4kIkFCBe5lxhjuH5/DngOV/Oa9AhKjw7i8T2unY4lIENAuFB84Ntx+YPskps5cxvx1JU5HEpEgoAL3kciwEJ65cRCd0mK57eUluvCViDSbCtyHEqLCeOmWwaTGRnDT84t1SzYRaRYVuI+lx0Xy8i2DCXG5mPzsYor2H3Y6kogEKBW4A9qnxPDSzYM5UFnN5GcXse9gldORRCQAqcAd0rN1PM/eOIii0sPc9PxijdYUkTOmAnfQ4A7JTL++PwU7yrnt5Vwqq3UdcRFpPBW4w0b3yOCvV/Vhwfq9TJ25jBoNuReRRtJAHj9w1YA2lB6q4v4PV5MYXcAfx+VgjHE6loj4ORW4n7j13I7sO1jF9C82kBwdzs8u7uZ0JBHxcypwP/Lzi7tReqiKaZ+vJzkmnJvP6eB0JBHxYypwP2KM4f5xvSk9eJTff7CKpJgwxvdr43QsEfFTOojpZ0Jchn9M7MvwTin87M0VfFa4y+lIIuKnVOB+KDIshBk3DKRnZjx3vJpH7uZ9TkcSET+kAvdTsRGhvHDTIFonRHHzC99QWFzudCQR8TMqcD+WEhvBS7cMJjo8lEnPLGJNsS5+JSL/1awCN8YkGmPeMsYUGmNWG2OGeSqY1GmTFM2r3x9CiMswccZCCorKnI4kIn6iuVvgjwCfWGu7A2cBq5sfSerrlBbLG7cNIzo8lGuf/pq8raVORxIRP9DkAjfGxAPnAc8CWGurrLW6S4GXtE+J4Y3bh5EcE87kZxaxaONepyOJiMOaswXeESgBnjfGLDXGPGOMiak/kzFmijEm1xiTW1KiW4k1R1ZiFG/cNozMxChufH6xbs0m0sI1p8BDgf7AE9bafsBB4J76M1lrZ1hrB1prB6alpTVjcQKQER/J61OGkp0Swy0v5PLpKp0nLtJSNafAtwPbrbWL3N+/RV2hi5elxkbw+pShdM+M4/ZXlvBR/k6nI4mIA5pc4NbaYmCbMebYVZdGA6s8kkpOKzE6nFduHULfton88J95vLN0u9ORRMTHmnsWyo+AV40xK4C+wJ+aH0kaKz4yjBdvHsyQDin85I3lvL54q9ORRMSHmnUxK2vtMmCgh7JIE8REhPL8TYO47eUl3DMrn8rqWm4cnu10LBHxAY3EDAJ1104ZwIU9M7jv/ZU8NW+D05FExAdU4EEiIjSE6df35/I+mfz540L+8elarNXt2USCma4HHkTCQlw8MrEfkWEh/OPTdRw5Wssvx3TT7dlEgpQKPMiEuAx/vaoPEaEunpy3gSNHa7jvip4qcZEgpAIPQi6X4f5xOUSEhvDcgk1UVtfwx3G9cblU4iLBRAUepIwx/ObyHkSFu3j88w0crqrhr1efRXioDnuIBAsVeBAzxvDzi7sTHR7Kg7PXsLPsCE9NHkBidLjT0UTEA7Q51gLcOaoz/7imL0u37mfC9K/YvOeg05FExANU4C3EuH5ZvHLrEEoPVTFu+gIWb9J9NkUCnQq8BRncIZl37jib5OhwJj2zSNdPEQlwKvAWJjs1hll3DKd/+0SmzlzOw3M14EckUKnAW6DE6HBeunkIVw9ow6P/XsePX1/GkaM1TscSkTOks1BaqPBQFw9e3YcOqTE8OHsNO/Yf5qnJA0iJjXA6mog0krbAWzBjDHeO6szj1/Unv6iM8dO/Yv3uA07HEpFGUoELl/XJ5LUpQzlUVc2E6Qv4av0epyOJSCOowAWA/u2SeOeOs8mIj+SG5xbzxjfbnI4kIqehApfj2iZH89YPhjOsUwq/eHsFD3xSSG2tzlAR8VcqcPkfCVFhPPe9QVw7uB1PfLGBH76WpzNURPyUCly+JSzExZ/G5/DrS3vwcUEx18z4mpKKSqdjiUg9KnA5KWMM3z+vI09OGsDa4grGTvuSJVtKnY4lIidQgcspXdyrFW/ePgyXy3DNUwt5Zv5GjdwU8RMqcDmtnKwEPvzRuYzqns79H67mtpeXUHb4qNOxRFo8Fbg0SkJ0GDMmD+Dey3rwWeFuLn9sPvnby5yOJdKiqcCl0Ywx3HpuR2beNoyaGstVT3zFSws3a5eKiENU4HLGBrRP4sO7zuXszin89r2V/PC1pVQc0S4VEV9TgUuTJMWE8+yNg/jFmG58UlDMldMWsGpHudOxRFoUFbg0mctluGNkZ/556xAOVlYzfvoCXl+8VbtURHxEBS7NNqRjCh/9+FwGZSdzz6x8fvrGcg5VVTsdSyToqcDFI1JjI3jx5sFMvaAr7ywr4sppC1i3q8LpWCJBTQUuHhPiMvz4gi68cssQ9h+q4sppC3h7ie67KeItKnDxuLM7p/LRXefSp00CP31zOb98a4UuiCXiBSpw8Yr0+EhevXUId47qxMzcbYydtoCCIg38EfEkFbh4TWiIi59f3J0XbhpE6aEqxj2+gIfnrqWqutbpaCJBQQUuXjeyWzpzpp7HFWe15tF/r2Ps4zpnXMQTVODiE4nR4fz9mr7MmDyAkopKrpz2JY98uo6jNdoaF2mqZhe4MSbEGLPUGPOBJwJJcLuoVyvmTj2Py/pk8vdP1zLu8QUUFmtrXKQpPLEF/mNgtQf+O9JCJMWE88jEfjw5aQC7yo9wxWNfMu2zdVRra1zkjDSrwI0xbYDLgGc8E0dakjE5rZgzdQQX92rFQ3PWMn76V6wp1uAfkcZq7hb4P4BfAA1uOhljphhjco0xuSUlJc1cnASb5Jhwpl3Xn+nX96do/2GueOxLHv98vbbGRRqhyQVujLkc2G2tXXKq+ay1M6y1A621A9PS0pq6OAlyl/bOZM7U87igZzoPzl7DVU98paH4IqfRnC3ws4ErjTGbgdeB840xr3gklbRIqbERTL9+ANOu68fWfYe47LEveXLeBmpqdXVDkZNpcoFba//PWtvGWpsNTAQ+s9ZO8lgyabEu79OaOVNHMKpbGn/5uJCrnviK9bsPOB1LxO/oPHDxS2lxETw5aQCPTOzL5r0HufSR+Tw4u1CXqRU5gfHlxfcHDhxoc3NzfbY8CQ67K47wl48KmbW0iMyESO69rCeX9m6FMcbpaCI+YYxZYq0dWH+6tsDF76XHRfLwNX158/ZhJEaHc+c/87j+mUU6yCktngpcAsag7GQ++NE5/GFsL1buKOeSR+bzhw9WUa4bKksLpQKXgBLiMkwels3nPxvJdwa25bkFmzj/oXm8vWQ7tTpbRVoYFbgEpOSYcP48oTfv3Xk2bZKi+Omby/nOUwt1zXFpUVTgEtD6tElk1g+G89er+7B5z0GumPYl976bz/5DVU5HE/E6FbgEPJfL8N2BbfnsZyO5cVg2/1y0lVEPfcGri7ZoEJAENRW4BI2EqDB+d2UvPrzrXLpkxPHrdwoY+/iXLNlS6nQ0Ea9QgUvQ6ZEZz8wpQ3lkYl9KKiq56omv+Mkbyyjaf9jpaCIeFep0ABFvMMYwtm8Wo3tk8Nhn63j+y818sHwn1w9tx52jOpMaG+F0RJFm00hMaRGK9h/m0U/X8eaSbUSGhXDLOR34/nkdiY8MczqayGk1NBJTBS4tyoaSAzw8Zy0f5u8kISqMH4zsxI3DsokKD3E6mkiDVOAiJygoKuPB2WuYt7aE9LgI7hrdhWsGtSUsRIeFxP/oWigiJ8jJSuDFmwczc8pQ2iVHc++7BYz+2zzeXVqkUw8lYKjApUUb0jGFN28fxvPfG0RMRCh3z1zGpY/MZ+6qXfjyr1ORplCBS4tnjGFU93Q+/NE5PHZtP6pqavn+S7lMeOIrvtqwx+l4Ig1SgYu4uVyGK85qzZyp5/GXCb0pLjvCdU8vYvKzi1i+bb/T8US+RQcxRRpw5GgNr3y9helfbGDfwSrO6ZzK7SM6cXbnFN1MQnxKZ6GINNGBympe/XoLz365id0VlfTOSuC2ER25JCeTEJeKXLxPBS7STJXVNbyTV8SM/2xk456DZKdE8/3zOnJV/zZEhuk8cvEeFbiIh9TUWuauKuaJLzawfHsZqbER3HR2NpOGtichSiM7xfNU4CIeZq1l4ca9PDlvI/9ZW0JsRCjXD2nHzed0ICM+0ul4EkRU4CJeVFBUxlP/2ciHK3YQ6nIxvl8WU0Z0pFNarNPRJAiowEV8YOveQzw9fyNv5G6jqqaWi3pmcPuITvRrl+R0NAlgKnARH9pzoJIXFmzmpYWbKT9SzZAOydwwLJuLemXoeityxlTgIg44UFnN64u38vyCzRTtP0x6XAQTB7fj2sFtyUyIcjqeBAgVuIiDamot89bu5uWFW/hibQkuY7igRzqTh2YzvFMKLp1PLqfQUIHrjjwiPhDiMpzfPYPzu2ewbd8hXl20lTdytzF75S46pMZw/ZB2fGdAWxKidRqiNJ62wEUcUlldw8f5xbz89RaWbCklItTFlWe1ZvKw9vRpk+h0PPEj2oUi4sdW7SjnlUVbeHdpEYeqaujTJoFJQ9tzRZ/WuluQqMBFAkH5kaO8u7SIlxduYd3uAyREhXH1gDZcP6QdHXVOeYulAhcJINZaFm3ax8tfb2F2QTHVtZb+7RKZ0L8Nl/fJJDE63OmI4kMqcJEAtbviCLPyipiVt521uw4QHuLi/O7pTOifxchu6YSH6rzyYKcCFwlw1lpW7ihnVl4R7y8vYs+BKpKiw7jirNaM75dF37aJuk55kFKBiwSR6ppa5q/bw6ylRcxZWUxldS0dU2MY3y+Lcf2yaJsc7XRE8SAVuEiQKj9ylE/yi3k7bzuLNu0DYEiHZCb0z+KS3pnER+rc8kDn8QI3xrQFXgJaAbXADGvtI6d6jwpcxLu27TvEe8uKmJVXxMY9B4kIdXFhzwwm9M/i7M6pRITqlMRA5I0CzwQyrbV5xpg4YAkwzlq7qqH3qMBFfMNay7Jt+3lnaRHvL9/B/kNHiYsIZXSPdMbkZDKia5rOLw8gXt+FYox5D5hmrZ3b0DwqcBHfq6qu5cv1JXxSUMycVbvYf+goUWEhjOqexsW9WnF+93TitJvFr3m1wI0x2cB/gBxrbXm916YAUwDatWs3YMuWLc1enog0TXVNLYs27ePjgp3MXrmLkopKwkNcnNsllTE5rbiwZ4bOMfdDXitwY0wsMA/4o7V21qnm1Ra4iP+oqbXkbS3l4/xiZq8spmj/YUJdhmGdUri4Vysu6pVBepxuDecPvFLgxpgw4ANgtrX24dPNrwIX8U/WWlZsL+PjgmI+KdjJ5r2HMAYGtU9mTE4rLs5pRVairl/uFG8cxDTAi8A+a+3djXmPClzE/1lrWbOrgo/zi/mkoJg1uyoA6JYRx8juaYzsms7A7CTdWciHvFHg5wDzgXzqTiME+JW19qOG3qMCFwk8G0sOMHfVLr5YU8I3m/dRXWuJiwjl7M6pjOqexoiu6bRK0K4Wb9JAHhFptoojR1mwfi/z1u7m88ISisuPANAjM56R3dIY1S2d/u0SCdXWuUepwEXEo47tavm8sIQv1uwmd0spNbWWuMhQzuuSxohuaYzsmkZ6vLbOm0sFLiJeVX7kKAvW7eHzNbv5Yk0JuysqAejVOp4RXdMY3imVAe2TNICoCVTgIuIz1lpW7SznizUlzFtTwpKtdVvn4SEu+rZLZFjHFIZ1SqFfu0QN728EFbiIOKbiyFFyN5eycONeFm7Yy8odZdRaiAh1MaB90vFC79MmUdc3PwkVuIj4jbLDR1m8aR8LN+xl4ca9rN5ZN4A7KiyEgdlJDOuUwrCOKfTOStABUVTgIuLHSg9WsWjT3uOFvnbXAQBiI0IZ5C70Ae2TycmKb5G7XBoq8FAnwoiInCgpJpwxOZmMyckEYM+BSr7e+N9C/3xNCQDhIS5ysuLp3y6JAe3rHi35LBdtgYuI3yupqCRvayl5W0rJ21rK8u1lVFXXjR/MSow6Xub92yXRPTMu6EaJaheKiASNqupaVu4oI2/rfvK2lLJkS+nxQUVRYSGc1Tbh+FZ6v3ZJJMcE9hUWVeAiEtR27D/MEvcWet6WUlbuKKe6tq7fOqTG0Dsrgd5ZCeRkJdArKz6gbjWnfeAiEtRaJ0bROjGKK85qDcDhqhryi8pYsqWUpVtLyd28j/eX7zg+f4fUGHKyEuidFU+Ou9gDqdRBBS4iQSoqPITBHZIZ3CH5+LS9ByrJLyqjoKiM/KIy8raU8q8TSj07Jdpd6nWPXlkJJET5b6mrwEWkxUiJjWBkt3RGdks/Pm3vgUoKdpTXlfr2MpZu3c8HK3Yef719SjQ5rRPo3iqObq3i6JEZT1ZiFC6XceJ/4X+owEWkRUuJjWBE1zRGdE07Pm3fwar/bqlvL2P59v18mP/fUo8JD6Frqzi6t4o/XuzdW8X5/HZ0OogpItIIByqrWVNc4X6UU1hcQWFxBWWHjx6fp1V85PEy7+Z+dE6PbfbgIx3EFBFphtiI0OPnmx9jrWVXeSWFxeXHy311cQULN+ylqqbuPPUQl6FjagxPTBpA5/RYj2ZSgYuINJExhlYJkbRKiPyf/epHa2rZvOcghe5SLywuJy02wuPLV4GLiHhYWIiLLhlxdMmI44qzvLec4BpvKiLSgqjARUQClApcRCRAqcBFRAKUClxEJECpwEVEApQKXEQkQKnARUQClE+vhWKMKQG2NPHtqcAeD8bxNOVrHuVrHuVrHn/P195am1Z/ok8LvDmMMbknu5iLv1C+5lG+5lG+5vH3fA3RLhQRkQClAhcRCVCBVOAznA5wGsrXPMrXPMrXPP6e76QCZh+4iIj8r0DaAhcRkROowEVEApTfFbgxZowxZo0xZr0x5p6TvB5hjJnpfn2RMSbbh9naGmM+N8asNsasNMb8+CTzjDTGlBljlrkfv/VVPvfyNxtj8t3L/tYNSE2dR93rb4Uxpr8Ps3U7Yb0sM8aUG2PurjePT9efMeY5Y8xuY0zBCdOSjTFzjTHr3F+TGnjvje551hljbvRhvgeNMYXun987xpjEBt57ys+CF/P9zhhTdMLP8NIG3nvK33Uv5pt5QrbNxphlDbzX6+uv2ay1fvMAQoANQEcgHFgO9Kw3zx3Ak+7nE4GZPsyXCfR3P48D1p4k30jgAwfX4WYg9RSvXwp8DBhgKLDIwZ91MXUDFBxbf8B5QH+g4IRpfwXucT+/B3jgJO9LBja6vya5nyf5KN9FQKj7+QMny9eYz4IX8/0O+Fkjfv6n/F33Vr56r/8N+K1T66+5D3/bAh8MrLfWbrTWVgGvA2PrzTMWeNH9/C1gtDHG+CKctXantTbP/bwCWA1k+WLZHjQWeMnW+RpINMZkOpBjNLDBWtvUkbkeYa39D7Cv3uQTP2MvAuNO8taLgbnW2n3W2lJgLjDGF/mstXOstdXub78G2nh6uY3VwPprjMb8rjfbqfK5e+O7wGueXq6v+FuBZwHbTvh+O98uyOPzuD/EZUCKT9KdwL3rph+w6CQvDzPGLDfGfGyM6eXTYGCBOcaYJcaYKSd5vTHr2Bcm0vAvjpPrDyDDWrsT6v7RBtJPMo+/rMebqfuL6mRO91nwph+6d/E818AuKH9Yf+cCu6y16xp43cn11yj+VuAn25Kuf55jY+bxKmNMLPA2cLe1trzey3nU7RY4C3gMeNeX2YCzrbX9gUuAO40x59V73R/WXzhwJfDmSV52ev01lj+sx18D1cCrDcxyus+CtzwBdAL6Ajup201Rn+PrD7iWU299O7X+Gs3fCnw70PaE79sAOxqaxxgTCiTQtD/hmsQYE0Zdeb9qrZ1V/3Vrbbm19oD7+UdAmDEm1Vf5rLU73F93A+9Q96fqiRqzjr3tEiDPWrur/gtOrz+3Xcd2K7m/7j7JPI6uR/dB08uB6617h219jfgseIW1dpe1tsZaWws83cBynV5/ocAEYGZD8zi1/s6EvxX4N0AXY0wH91baROD9evO8Dxw74n818FlDH2BPc+8zexZYba19uIF5Wh3bJ2+MGUzdOt7ro3wxxpi4Y8+pO9hVUG+294Eb3GejDAXKju0u8KEGt3ycXH8nOPEzdiPw3knmmQ1cZIxJcu8iuMg9zeuMMWOAXwJXWmsPNTBPYz4L3sp34sg5qjYAAAEISURBVDGV8Q0stzG/6950AVBord1+shedXH9nxOmjqPUf1J0lsZa6I9S/dk/7PXUfVoBI6v70Xg8sBjr6MNs51P2ZtwJY5n5cCtwO3O6e54fASuqOqn8NDPdhvo7u5S53Zzi2/k7MZ4DH3es3Hxjo459vNHWFnHDCNMfWH3X/kOwEjlK3VXgLdcdU/g2sc39Nds87EHjmhPfe7P4crgdu8mG+9dTtPz72GTx2VlZr4KNTfRZ8lO9l92drBXWlnFk/n/v7b/2u+yKfe/oLxz5zJ8zr8/XX3IeG0ouIBCh/24UiIiKNpAIXEQlQKnARkQClAhcRCVAqcBGRAKUCFxEJUCpwEZEA9f8B9QazxF/fpwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(20), np.logspace(1,0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground token 7516\n",
      "decoded ground word  Charles\n",
      "ground word prob is:  2.0199675e-05\n",
      "sorted indices [18434  7773  1718  2952   339   788  1807   351 14593   373]\n",
      "ten sps values [0.10372717 0.09787275 0.05299053 0.04268101 0.02341009 0.02085523\n",
      " 0.01563338 0.01546261 0.01534993 0.01454636]\n",
      "prob slices: [0.03457572 0.02766058 0.02074543 0.01383029 0.00691514 0.        ]\n",
      "[0.10372717 0.02085523 0.01228744 0.00357661 0.01042557 0.00542129]\n",
      "words wanted rel positions [0, 5, 10, 42, 15, 30]\n",
      "absolute positions of slice words [0, 5, 10, 42, 15, 30]\n",
      "['steadily' 'then' 'poured' 'tried' 'kept' 'held']\n",
      "ground token 5166\n",
      "decoded ground word  pair\n",
      "ground word prob is:  0.17913476\n",
      "sorted indices [ 5166    13  3704  2378    11  1517  3918 17292 16313   804]\n",
      "ten sps values [0.17913476 0.17665565 0.07442557 0.04131892 0.02990923 0.02411442\n",
      " 0.02320323 0.02176797 0.01888203 0.01749844]\n",
      "prob slices: [0.05971159 0.04776927 0.03582695 0.02388463 0.01194232 0.        ]\n",
      "[0.17913476 0.07442557 0.02411442 0.00993254 0.02176797 0.00743699]\n",
      "words wanted rel positions [0, 2, 5, 12, 7, 15]\n",
      "absolute positions of slice words [0, 2, 5, 12, 7, 15]\n",
      "['pair' 'item' 'shoe' 'good' 'look' 'fashion']\n",
      "ground token 5399\n",
      "decoded ground word  joined\n",
      "ground word prob is:  0.0061504683\n",
      "sorted indices [   11  9349  4120  1625  8278   373  3940 10764   287  3888]\n",
      "ten sps values [0.2035434  0.05413388 0.03354428 0.024269   0.02371438 0.02137096\n",
      " 0.02052315 0.01788445 0.01463069 0.01422812]\n",
      "prob slices: [0.0678478  0.05427824 0.04070868 0.02713912 0.01356956 0.        ]\n",
      "[0.2035434  0.02371438 0.01463069 0.00356245 0.00939475 0.00586896]\n",
      "words wanted rel positions [0, 4, 8, 45, 12, 24]\n",
      "absolute positions of slice words [0, 4, 8, 45, 12, 24]\n",
      "['emerged' 'was' 'moved' 'climbed' 'approached' 'floated']\n",
      "ground token 922\n",
      "decoded ground word  good\n",
      "ground word prob is:  0.027579067\n",
      "sorted indices [ 582  922  890 1178 1310 1110 1049 1365 1402 7319]\n",
      "ten sps values [0.05573973 0.02757909 0.02114042 0.01868893 0.01766578 0.01154677\n",
      " 0.01147247 0.01090836 0.00943015 0.00900043]\n",
      "prob slices: [0.01857991 0.01486393 0.01114795 0.00743196 0.00371598 0.        ]\n",
      "[0.05573973 0.00720579 0.00459934 0.00047751 0.00282857 0.00153218]\n",
      "words wanted rel positions [0, 13, 27, 332, 40, 81]\n",
      "absolute positions of slice words [0, 13, 27, 332, 40, 81]\n",
      "['man' 'step' 'lifetime' 'call' 'half' 'light']\n",
      "ground token 5405\n",
      "decoded ground word  glass\n",
      "ground word prob is:  0.7756876\n",
      "sorted indices [ 5405    11   286  2823 25152 29219   460 35245   290  2933]\n",
      "ten sps values [0.7756876  0.06518605 0.01381235 0.00918343 0.00650748 0.0051772\n",
      " 0.00424999 0.0038568  0.0034958  0.00312026]\n",
      "prob slices: [0.25856253 0.20685002 0.15513752 0.10342501 0.05171251 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 290\n",
      "decoded ground word  and\n",
      "ground word prob is:  0.14070147\n",
      "sorted indices [ 13 355 290  11 379 284 287 351 422 625]\n",
      "ten sps values [0.4007027  0.16286299 0.14070147 0.11272091 0.03973731 0.0221282\n",
      " 0.01167742 0.00960696 0.00388029 0.00381042]\n",
      "prob slices: [0.13356756 0.10685405 0.08014054 0.05342702 0.02671351 0.        ]\n",
      "[0.4007027  0.14070147 0.03973731 0.11272091 0.01167742 0.00300338]\n",
      "words wanted rel positions [0, 2, 4, 3, 6, 12]\n",
      "absolute positions of slice words [0, 2, 4, 3, 6, 12]\n",
      "['as' 'at' 'in' 'to' 'from' 'a']\n",
      "ground token 220\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 15506\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 13\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 299\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 734\n",
      "decoded ground word  two\n",
      "ground word prob is:  0.058444157\n",
      "sorted indices [ 257 2745  734 1115 1528 1933  625 2250 1811  281]\n",
      "ten sps values [0.16936234 0.07504328 0.05844416 0.05712805 0.05275198 0.05199063\n",
      " 0.03449607 0.02567895 0.02355575 0.02130255]\n",
      "prob slices: [0.05645411 0.04516329 0.03387247 0.02258164 0.01129082 0.        ]\n",
      "[0.16936234 0.02567895 0.01533528 0.01554464 0.00912496 0.00255243]\n",
      "words wanted rel positions [0, 7, 15, 14, 22, 45]\n",
      "absolute positions of slice words [0, 7, 15, 14, 22, 45]\n",
      "['a' 'hours' 'five' 'six' 'some' '24']\n",
      "ground token 1464\n",
      "decoded ground word  always\n",
      "ground word prob is:  0.029037535\n",
      "sorted indices [ 547  550   11  290 1464  422  373 1625  287 2067]\n",
      "ten sps values [0.2050555  0.04903817 0.03209    0.0306621  0.02903754 0.01616019\n",
      " 0.01580592 0.0135012  0.00999508 0.009921  ]\n",
      "prob slices: [0.06835184 0.05468147 0.0410111  0.02734073 0.01367037 0.        ]\n",
      "[0.2050555  0.03209    0.01616019 0.0022301  0.0135012  0.00766306]\n",
      "words wanted rel positions [0, 2, 5, 58, 7, 15]\n",
      "absolute positions of slice words [0, 2, 5, 58, 7, 15]\n",
      "['were' 'and' 'was' 'did' 'in' 'life']\n",
      "ground token 2722\n",
      "decoded ground word  received\n",
      "ground word prob is:  0.0024621165\n",
      "sorted indices [ 587  655  257 1541  284 2067 7334  645  691  465]\n",
      "ten sps values [0.12943263 0.08285868 0.04890388 0.04804401 0.03075121 0.02593125\n",
      " 0.0258764  0.02312811 0.02088718 0.01726433]\n",
      "prob slices: [0.04314421 0.03451537 0.02588653 0.01725768 0.00862884 0.        ]\n",
      "[0.12943263 0.02312811 0.01263704 0.00648846 0.00828762 0.00325544]\n",
      "words wanted rel positions [0, 7, 14, 27, 21, 42]\n",
      "absolute positions of slice words [0, 7, 14, 27, 21, 42]\n",
      "['been' 'no' 'turned' 'left' 'lived' 'seen']\n",
      "ground token 262\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 523\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 517\n",
      "decoded ground word  more\n",
      "ground word prob is:  0.18948807\n",
      "sorted indices [ 286  517 1342 3131  357   11 1365   13  267  220]\n",
      "ten sps values [7.8349549e-01 1.8948807e-01 7.5735971e-03 1.4496733e-03 1.2986902e-03\n",
      " 1.0389868e-03 7.8320480e-04 6.7112013e-04 5.5652461e-04 5.4600509e-04]\n",
      "prob slices: [0.26116516 0.20893213 0.1566991  0.10446606 0.05223303 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 606\n",
      "decoded ground word  them\n",
      "ground word prob is:  0.5511749\n",
      "sorted indices [  606   345   514   262  1479   683   257   340   674 31798]\n",
      "ten sps values [0.5511754  0.1938899  0.08748517 0.05746469 0.01287367 0.01188989\n",
      " 0.01013561 0.00636295 0.00593953 0.00364609]\n",
      "prob slices: [0.18372514 0.14698011 0.11023508 0.07349006 0.03674503 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 299\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 1900\n",
      "decoded ground word  known\n",
      "ground word prob is:  0.0010964803\n",
      "sorted indices [ 286  345  326  356 9635  314   11  543   13  290]\n",
      "ten sps values [0.51000386 0.16448319 0.08973123 0.051479   0.02961543 0.01435646\n",
      " 0.01130874 0.01032655 0.00850538 0.00748215]\n",
      "prob slices: [0.17000129 0.13600103 0.10200077 0.06800052 0.03400026 0.        ]\n",
      "[0.51000386 0.16448319 0.051479   0.08973123 0.02961543 0.00748215]\n",
      "words wanted rel positions [0, 1, 3, 2, 4, 9]\n",
      "absolute positions of slice words [0, 1, 3, 2, 4, 9]\n",
      "['of' 'you' 'we' 'that' 'spoken' 'for']\n",
      "ground token 886\n",
      "decoded ground word  end\n",
      "ground word prob is:  0.001602285\n",
      "sorted indices [ 616  262  502 1123  543  465  674  257 7603  307]\n",
      "ten sps values [0.37410486 0.1755186  0.04418552 0.02846112 0.02339543 0.01930818\n",
      " 0.01567026 0.0121125  0.01148706 0.01125007]\n",
      "prob slices: [0.12470162 0.0997613  0.07482097 0.04988065 0.02494032 0.        ]\n",
      "[0.37410486 0.1755186  0.02846112 0.01930818 0.02339543 0.01125007]\n",
      "words wanted rel positions [0, 1, 3, 5, 4, 9]\n",
      "absolute positions of slice words [0, 1, 3, 5, 4, 9]\n",
      "['my' 'the' 'each' 'his' 'which' 'be']\n",
      "ground token 3371\n",
      "decoded ground word  towards\n",
      "ground word prob is:  0.12346591\n",
      "sorted indices [ 284 3371  422 3812  736  625  287  290 1088   13]\n",
      "ten sps values [0.60627675 0.12346591 0.05313582 0.0300992  0.01981989 0.01884255\n",
      " 0.01459114 0.01252926 0.01143118 0.0093263 ]\n",
      "prob slices: [0.20209225 0.1616738  0.12125535 0.0808369  0.04041845 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 262\n",
      "decoded ground word  the\n",
      "ground word prob is:  0.017019408\n",
      "sorted indices [ 3114  3332  2936  7342  6204   262  1309 23831  5954  2900]\n",
      "ten sps values [0.02934939 0.02072048 0.01834196 0.01789185 0.01778746 0.01701941\n",
      " 0.01688727 0.01681817 0.0156762  0.0152475 ]\n",
      "prob slices: [0.00978313 0.00782651 0.00586988 0.00391325 0.00195663 0.        ]\n",
      "[0.02934939 0.00580498 0.00246857 0.00173229 0.0015577  0.0007649 ]\n",
      "words wanted rel positions [0, 37, 75, 103, 112, 225]\n",
      "absolute positions of slice words [0, 37, 75, 103, 112, 225]\n",
      "['looked' 'saw' 'had' 'removed' 'headed' 'snapped']\n",
      "ground token 15967\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 34918\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 26834\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 921\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 2187\n",
      "decoded ground word  whole\n",
      "ground word prob is:  0.0054514846\n",
      "sorted indices [ 3084 26951   983 44703 35715  1907  1263  1310  3715  2151]\n",
      "ten sps values [0.03326915 0.03274027 0.02153346 0.02026374 0.01932367 0.01744227\n",
      " 0.01652164 0.01432937 0.01337495 0.01290881]\n",
      "prob slices: [0.01108972 0.00887177 0.00665383 0.00443589 0.00221794 0.        ]\n",
      "[0.03326915 0.00790212 0.00412119 0.00066134 0.00250299 0.00138059]\n",
      "words wanted rel positions [0, 17, 35, 227, 52, 105]\n",
      "absolute positions of slice words [0, 17, 35, 227, 52, 105]\n",
      "['table' 'meal' 'mess' 'video' 'battle' 'private']\n",
      "ground token 15983\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 262\n",
      "decoded ground word  the\n",
      "ground word prob is:  0.102679566\n",
      "sorted indices [ 284 4497  262  287 1107 1266  517  749 1016 4988]\n",
      "ten sps values [0.3068631  0.112725   0.10267957 0.05132615 0.04334367 0.04038368\n",
      " 0.03938571 0.03858295 0.0296425  0.022976  ]\n",
      "prob slices: [0.1022877  0.08183016 0.06137262 0.04091508 0.02045754 0.        ]\n",
      "[0.3068631  0.05132615 0.03858295 0.03938571 0.01910395 0.00311931]\n",
      "words wanted rel positions [0, 3, 7, 6, 10, 21]\n",
      "absolute positions of slice words [0, 3, 7, 6, 10, 21]\n",
      "['to' 'in' 'most' 'more' 'actually' 'qualified']\n",
      "ground token 284\n",
      "decoded ground word  to\n",
      "ground word prob is:  0.6656705\n",
      "sorted indices [284 286 287 475 329 422 832 656  11  13]\n",
      "ten sps values [0.66566986 0.13291462 0.033196   0.02901479 0.02034839 0.00838365\n",
      " 0.00800297 0.00673453 0.00619588 0.00573706]\n",
      "prob slices: [0.22188995 0.17751196 0.13313397 0.08875598 0.04437799 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 2460\n",
      "decoded ground word  friends\n",
      "ground word prob is:  0.021820728\n",
      "sorted indices [1545 2460 1110 9846 1528 6726 4724 6979 4088  494]\n",
      "ten sps values [0.87277967 0.02182073 0.00631489 0.00483401 0.00465391 0.00384596\n",
      " 0.00317385 0.00299622 0.0021484  0.00208084]\n",
      "prob slices: [0.29092656 0.23274124 0.17455593 0.11637062 0.05818531 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 345\n",
      "decoded ground word  you\n",
      "ground word prob is:  0.6433909\n",
      "sorted indices [  345   286   534   318   262  2753   468  4940  6140 23816]\n",
      "ten sps values [0.6433909  0.18073854 0.11413656 0.00827281 0.00395807 0.0015309\n",
      " 0.00134019 0.00100742 0.00091513 0.00090763]\n",
      "prob slices: [0.21446363 0.17157091 0.12867818 0.08578545 0.04289273 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 832\n",
      "decoded ground word  through\n",
      "ground word prob is:  0.034577254\n",
      "sorted indices [ 220  287  656  832  572 1088  319  503  625 2641]\n",
      "ten sps values [0.302741   0.25636706 0.12086674 0.03457725 0.01853007 0.01661555\n",
      " 0.015697   0.01539108 0.01516646 0.01423504]\n",
      "prob slices: [0.10091366 0.08073093 0.0605482  0.04036547 0.02018273 0.        ]\n",
      "[0.302741   0.12086674 0.01853007 0.03457725 0.015697   0.01237713]\n",
      "words wanted rel positions [0, 2, 4, 3, 6, 12]\n",
      "absolute positions of slice words [0, 2, 4, 3, 6, 12]\n",
      "['in' 'through' 'around' 'off' 'out' 'away']\n",
      "ground token 11\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 663\n",
      "decoded ground word  its\n",
      "ground word prob is:  0.21136764\n",
      "sorted indices [ 13 262 663 257  11 355 290 465 281 588]\n",
      "ten sps values [0.292927   0.24354474 0.21136764 0.05230688 0.05165895 0.01812567\n",
      " 0.01399166 0.00923045 0.00770091 0.00712121]\n",
      "prob slices: [0.09764233 0.07811387 0.0585854  0.03905693 0.01952847 0.        ]\n",
      "[0.292927   0.21136764 0.01812567 0.05230688 0.00923045 0.00272553]\n",
      "words wanted rel positions [0, 2, 5, 3, 7, 15]\n",
      "absolute positions of slice words [0, 2, 5, 3, 7, 15]\n",
      "['the' 'a' 'his' 'as' 'like' 'John']\n",
      "ground token 0\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 16343\n",
      "decoded ground word  nest\n",
      "ground word prob is:  0.0002416219\n",
      "sorted indices [15061 29461  8278 17522  3797   285  6512   582 35113   256]\n",
      "ten sps values [0.01678319 0.01543598 0.01210746 0.01170793 0.00980438 0.00873011\n",
      " 0.00792967 0.00745647 0.00717192 0.00630598]\n",
      "prob slices: [0.0055944  0.00447552 0.00335664 0.00223776 0.00111888 0.        ]\n",
      "[0.01678319 0.00263605 0.00156819 0.00057067 0.00114546 0.00061246]\n",
      "words wanted rel positions [0, 57, 114, 367, 171, 342]\n",
      "absolute positions of slice words [0, 57, 114, 367, 171, 342]\n",
      "['flower' 'stick' 'hedge' 'leather' 'pearl' 'stone']\n",
      "ground token 7559\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 314\n",
      "decoded ground word  I\n",
      "ground word prob is:  0.77883273\n",
      "sorted indices [314 340 356 345 262 484 428 616 339 326]\n",
      "ten sps values [0.77883273 0.05036688 0.05022088 0.04423388 0.0115222  0.0106533\n",
      " 0.00728096 0.00541547 0.00485369 0.00394073]\n",
      "prob slices: [0.25961091 0.20768873 0.15576655 0.10384436 0.05192218 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 284\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 10883\n",
      "decoded ground word  magical\n",
      "ground word prob is:  0.0011530055\n",
      "sorted indices [ 2495   257  4385   407   845   477  1107  1611   262 17855]\n",
      "ten sps values [0.08390506 0.04701327 0.03741981 0.02922298 0.02609142 0.02523194\n",
      " 0.02016415 0.01791218 0.016101   0.01315952]\n",
      "prob slices: [0.02796835 0.02237468 0.01678101 0.01118734 0.00559367 0.        ]\n",
      "[0.08390506 0.01097001 0.00655563 0.00173645 0.00395893 0.00222466]\n",
      "words wanted rel positions [0, 11, 22, 88, 33, 66]\n",
      "absolute positions of slice words [0, 11, 22, 88, 33, 66]\n",
      "['pretty' 'big' 'born' 'scared' 'hard' 'great']\n",
      "ground token 275\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 290\n",
      "decoded ground word  and\n",
      "ground word prob is:  0.042155005\n",
      "sorted indices [ 262  257 1341  290  284  534 3661  502  616   11]\n",
      "ten sps values [0.47284025 0.07772423 0.05612737 0.04215501 0.0397209  0.02667166\n",
      " 0.02652446 0.02528451 0.02053877 0.01826932]\n",
      "prob slices: [0.15761342 0.12609073 0.09456805 0.06304537 0.03152268 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 3195\n",
      "decoded ground word  TV\n",
      "ground word prob is:  0.011283733\n",
      "sorted indices [2250  661 5861 7444  812 5581 2431 1661  584 1180]\n",
      "ten sps values [0.13064274 0.05587833 0.04983101 0.03688696 0.02923483 0.02496256\n",
      " 0.02098486 0.02047129 0.01933771 0.01917214]\n",
      "prob slices: [0.04354758 0.03483806 0.02612855 0.01741903 0.00870952 0.        ]\n",
      "[0.13064274 0.02047129 0.01129238 0.00181201 0.00488199 0.00197778]\n",
      "words wanted rel positions [0, 7, 15, 50, 22, 45]\n",
      "absolute positions of slice words [0, 7, 15, 50, 22, 45]\n",
      "['hours' 'other' 'TV' 'sun' 're' 'thoughts']\n",
      "ground token 16343\n",
      "decoded ground word  nest\n",
      "ground word prob is:  0.0002416219\n",
      "sorted indices [15061 29461  8278 17522  3797   285  6512   582 35113   256]\n",
      "ten sps values [0.01678319 0.01543598 0.01210746 0.01170793 0.00980438 0.00873011\n",
      " 0.00792967 0.00745647 0.00717192 0.00630598]\n",
      "prob slices: [0.0055944  0.00447552 0.00335664 0.00223776 0.00111888 0.        ]\n",
      "[0.01678319 0.00263605 0.00156819 0.00057067 0.00114546 0.00061246]\n",
      "words wanted rel positions [0, 57, 114, 367, 171, 342]\n",
      "absolute positions of slice words [0, 57, 114, 367, 171, 342]\n",
      "['flower' 'stick' 'hedge' 'leather' 'pearl' 'stone']\n",
      "ground token 1867\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 7061\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 43672\n",
      "one of the three tokens in front were not words so skipping\n",
      "ground token 898\n",
      "decoded ground word  own\n",
      "ground word prob is:  0.007845591\n",
      "sorted indices [  717 41220   845  2988   649   898 17981  4082  4639  3850]\n",
      "ten sps values [0.40387088 0.01500284 0.01142776 0.00980775 0.00807525 0.00784559\n",
      " 0.00775713 0.00597697 0.00573419 0.00558858]\n",
      "prob slices: [0.13462363 0.1076989  0.08077418 0.05384945 0.02692473 0.        ]\n",
      "not all specific indices selected are unique!!\n",
      "ground token 2562\n",
      "one of the three tokens in front were not words so skipping\n"
     ]
    }
   ],
   "source": [
    "# applying all analyses to the logits. \n",
    "prompt_length = 100\n",
    "slices_from_each = 6 # as one will also be the ground truth word. \n",
    "to_df = []\n",
    "\n",
    "# randomly select generations and positions in those generations. from the original prompts. \n",
    "for r_ind in range(0, num_prompts_and_timepoints_wanted):\n",
    "    \n",
    "    if want_min_max ==True:\n",
    "        prompt = 999\n",
    "        batch_ind, ind_in_batch = minmax.iloc[r_ind, 1], minmax.iloc[r_ind, 2]\n",
    "        time_point = minmax.iloc[r_ind,3]\n",
    "        if time_point>=149:\n",
    "            continue # because of the stop token being predicted. \n",
    "        text_timepoint = time_point+prompt_length+1 # +1 because the perplexities keeps the end prediction token. \n",
    "    else:\n",
    "        prompt = rand_prompts[r_ind]\n",
    "        time_point = rand_times[r_ind]\n",
    "        text_timepoint = time_point+prompt_length+1 # +1 because the perplexities keeps the end prediction token. \n",
    "        batch_ind, ind_in_batch = mapping_to_batch[prompt]\n",
    "    \n",
    "    sps_no_sort = softmax(all_logits[batch_ind][ind_in_batch, time_point, :])\n",
    "    sps = softmax(-np.sort(-all_logits[batch_ind][ind_in_batch, time_point, :]))\n",
    "    \n",
    "    prob_slices_wanted = np.linspace(sps[0],0,slices_from_each)/3\n",
    "    \n",
    "    indices = np.argsort(-all_logits[batch_ind][ind_in_batch, time_point, :])\n",
    "    ground_token = text[batch_ind][ind_in_batch][text_timepoint]\n",
    "    print('ground token', ground_token)\n",
    "    prev_token = text[batch_ind][ind_in_batch][text_timepoint-1]\n",
    "    prev_prev_token = text[batch_ind][ind_in_batch][text_timepoint-2]\n",
    "    prev_tokens = [ground_token, prev_token,prev_prev_token]\n",
    "    \n",
    "    # check if these are even real words first \n",
    "    real_prompt_words, _ = remove_non_words(prev_tokens, wantPrint=False)\n",
    "    #print(real_prompt_words)\n",
    "    if len(real_prompt_words)<len(prev_tokens):\n",
    "        print('one of the three tokens in front were not words so skipping')\n",
    "        continue\n",
    "        \n",
    "    else: \n",
    "        ground_word = decoder_text([ground_token])\n",
    "        print('decoded ground word', ground_word)\n",
    "        #stripped_prev_tokens.append(space_free[0])\n",
    "\n",
    "        #ground_word = stripped_prev_tokens[-1]]) #[ground_token])\n",
    "        # what the ground token is\n",
    "        ground_word_prob = sps_no_sort[ground_token]\n",
    "        \n",
    "        print('ground word prob is: ', ground_word_prob)\n",
    "        print('sorted indices', indices[:10])\n",
    "    \n",
    "    #get the 15 words in front. \n",
    "    lead_prompt_words = decoder_text(text[batch_ind][ind_in_batch][text_timepoint-leading_prompt:text_timepoint])\n",
    "    df_row = [prompt, time_point, batch_ind, ind_in_batch, lead_prompt_words, ground_word, ground_word_prob] # taking it from the last one. \n",
    "    \n",
    "    print('ten sps values', sps[0:10])\n",
    "    print('prob slices:', prob_slices_wanted)\n",
    "    \n",
    "    #remove any non word tokens from whole list. (could be done more efficiently)\n",
    "    real_word_tokens, abs_pos = remove_non_words(indices)\n",
    "    \n",
    "    real_word_probs = sps[np.asarray(abs_pos)]\n",
    "    \n",
    "    rel_to_abs_index = {rel:absolute for rel, absolute in zip(range(len(abs_pos)), abs_pos )}\n",
    "    abs_to_rel_index = {absolute:rel for rel, absolute in zip(range(len(abs_pos)), abs_pos )}\n",
    "    \n",
    "    # select the right positions and words: \n",
    "    #NEED TO IGNORE ANY OF THE SLICES THAT ARE TOO LARGE.  TAKE THE HIGHEST PROB WORD AND THEN DO THE SLICES.\n",
    "    \n",
    "    ##################\n",
    "    # TAKING SPECIFIC PROBS RATHER THAN PROB SLICES AS BEFORE\n",
    "    first = real_word_probs[1:] - real_word_probs[:-1]\n",
    "    second = first[1:] - first[:-1]\n",
    "    tail_id = new_tfs(second, 0.9)\n",
    "               \n",
    "    tail_id_nuc = nucleus_calc(sps, 0.63)\n",
    "    \n",
    "    rel_words_positions_wanted = [0,int(tail_id/2), tail_id, tail_id_nuc, int(tail_id*1.5), tail_id*3]\n",
    "    if len(abs_words_positions_wanted) != len(list(set(abs_words_positions_wanted))):\n",
    "        print('not all specific indices selected are unique!!')\n",
    "        continue\n",
    "        \n",
    "    #ENSURE THIS HERE GIVES THE SAME PROB AS THE TWO LINES COMMENTED OUT BELOW!    \n",
    "    sel_word_probs = real_word_probs[np.asarray(rel_words_positions_wanted)]\n",
    "    #abs_words_positions_wanted = [ rel_to_abs_index[rel] for rel in rel_words_positions_wanted]\n",
    "    #sel_word_probs = sps[np.asarray(abs_words_positions_wanted)]\n",
    "    print(sel_word_probs)\n",
    "    ############\n",
    "    \n",
    "    #rel_words_positions_wanted, sel_word_probs = get_specific_positions_from_probs(real_word_probs, prob_slices_wanted)\n",
    "    #abs_words_positions_wanted = [ rel_to_abs_index[rel] for rel in rel_words_positions_wanted]\n",
    "   \n",
    "    print('words wanted rel positions', rel_words_positions_wanted)\n",
    "    \n",
    "    print('absolute positions of slice words', abs_words_positions_wanted)\n",
    "    print(np.asarray(real_word_tokens)[np.asarray(rel_words_positions_wanted)])\n",
    "    df_row.append(np.asarray(real_word_tokens)[np.asarray(rel_words_positions_wanted)]) # adding the words themselves. \n",
    "    df_row.append(abs_words_positions_wanted)\n",
    "    df_row.append(sel_word_probs)\n",
    "        \n",
    "    to_df.append(df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = enchant.Dict(\"en_US\")\n",
    "d.check('rust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(to_df, columns = ['prompt_ind', 'time_point', \n",
    "                               'batch_ind', 'ind_in_batch', 'leading_words',\n",
    "                               'ground_word', 'ground_word_prob', 'words', 'abs_inds', 'probs'])\n",
    "                                         \n",
    "results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_ind</th>\n",
       "      <th>time_point</th>\n",
       "      <th>batch_ind</th>\n",
       "      <th>ind_in_batch</th>\n",
       "      <th>leading_words</th>\n",
       "      <th>ground_word</th>\n",
       "      <th>ground_word_prob</th>\n",
       "      <th>words</th>\n",
       "      <th>abs_inds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>short glass from the nightstand alongside Jam...</td>\n",
       "      <td>Charles</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>[steadily, then, poured, tried, kept, held]</td>\n",
       "      <td>[0, 5, 10, 42, 15, 30]</td>\n",
       "      <td>[0.10372717, 0.02085523, 0.012287442, 0.003576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>shoes. They were nice shoes, a little dirty, ...</td>\n",
       "      <td>pair</td>\n",
       "      <td>0.179135</td>\n",
       "      <td>[pair, item, shoe, good, look, fashion]</td>\n",
       "      <td>[0, 2, 5, 12, 7, 15]</td>\n",
       "      <td>[0.17913476, 0.07442557, 0.024114424, 0.009932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>, smashing a white plastic mask and the face b...</td>\n",
       "      <td>joined</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>[emerged, was, moved, climbed, approached, flo...</td>\n",
       "      <td>[0, 4, 8, 45, 12, 24]</td>\n",
       "      <td>[0.2035434, 0.023714384, 0.014630686, 0.003562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>never cover it. He considered, took in his pa...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>[man, step, lifetime, call, half, light]</td>\n",
       "      <td>[0, 13, 27, 332, 40, 81]</td>\n",
       "      <td>[0.05573973, 0.00720579, 0.0045993393, 0.00047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>race. \\n \\n ``Time to show off, ''he grinned</td>\n",
       "      <td>and</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>[as, at, in, to, from, a]</td>\n",
       "      <td>[0, 2, 4, 3, 6, 12]</td>\n",
       "      <td>[0.4007027, 0.14070147, 0.039737307, 0.1127209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>the day it would've been easy! Not so today, ...</td>\n",
       "      <td>two</td>\n",
       "      <td>0.058444</td>\n",
       "      <td>[a, hours, five, six, some, 24]</td>\n",
       "      <td>[0, 7, 15, 14, 22, 45]</td>\n",
       "      <td>[0.16936234, 0.025678951, 0.015335284, 0.01554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>like to feel her warmth in person. \\n \\n His ...</td>\n",
       "      <td>always</td>\n",
       "      <td>0.029038</td>\n",
       "      <td>[were, and, was, did, in, life]</td>\n",
       "      <td>[0, 2, 5, 58, 7, 15]</td>\n",
       "      <td>[0.2050555, 0.032089997, 0.016160188, 0.002230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>back in the day ''. Before John's eighteenth b...</td>\n",
       "      <td>received</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>[been, no, turned, left, lived, seen]</td>\n",
       "      <td>[0, 7, 14, 27, 21, 42]</td>\n",
       "      <td>[0.12943263, 0.02312811, 0.012637037, 0.006488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>of the human race are you not? And I believe ...</td>\n",
       "      <td>known</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>[of, you, we, that, spoken, for]</td>\n",
       "      <td>[0, 1, 3, 2, 4, 9]</td>\n",
       "      <td>[0.51000386, 0.16448319, 0.051479, 0.08973123,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>than a few seconds, with a grunt of approval ...</td>\n",
       "      <td>end</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>[my, the, each, his, which, be]</td>\n",
       "      <td>[0, 1, 3, 5, 4, 9]</td>\n",
       "      <td>[0.37410486, 0.1755186, 0.028461115, 0.0193081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>scape. He pushed back the low, thin limbs of t...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>[looked, saw, had, removed, headed, snapped]</td>\n",
       "      <td>[0, 37, 75, 103, 112, 225]</td>\n",
       "      <td>[0.029349394, 0.0058049792, 0.0024685704, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>at the buffet delivered to the table I was si...</td>\n",
       "      <td>whole</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>[table, meal, mess, video, battle, private]</td>\n",
       "      <td>[0, 17, 35, 227, 52, 105]</td>\n",
       "      <td>[0.03326915, 0.007902123, 0.004121192, 0.00066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>ones have promised to combat the threat, but a...</td>\n",
       "      <td>the</td>\n",
       "      <td>0.102680</td>\n",
       "      <td>[to, in, most, more, actually, qualified]</td>\n",
       "      <td>[0, 3, 7, 6, 10, 21]</td>\n",
       "      <td>[0.3068631, 0.051326152, 0.03858295, 0.0393857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>out like a drum \\n hair like a nest \\n rats h...</td>\n",
       "      <td>through</td>\n",
       "      <td>0.034577</td>\n",
       "      <td>[in, through, around, off, out, away]</td>\n",
       "      <td>[0, 2, 4, 3, 6, 12]</td>\n",
       "      <td>[0.302741, 0.12086674, 0.01853007, 0.034577254...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>. It followed behind him closely, its prismati...</td>\n",
       "      <td>its</td>\n",
       "      <td>0.211368</td>\n",
       "      <td>[the, a, his, as, like, John]</td>\n",
       "      <td>[0, 2, 5, 3, 7, 15]</td>\n",
       "      <td>[0.292927, 0.21136764, 0.018125672, 0.05230688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>\\n pal skin stretched \\n out like a drum \\n ha...</td>\n",
       "      <td>nest</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>[flower, stick, hedge, leather, pearl, stone]</td>\n",
       "      <td>[0, 57, 114, 367, 171, 342]</td>\n",
       "      <td>[0.016783189, 0.0026360513, 0.0015681898, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>\\n Tom waited. \\n \\n ``Plus, we dragons are</td>\n",
       "      <td>magical</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>[pretty, big, born, scared, hard, great]</td>\n",
       "      <td>[0, 11, 22, 88, 33, 66]</td>\n",
       "      <td>[0.08390506, 0.010970011, 0.0065556336, 0.0017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>. It was as if he were strapped in and forced ...</td>\n",
       "      <td>TV</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>[hours, other, TV, sun, re, thoughts]</td>\n",
       "      <td>[0, 7, 15, 50, 22, 45]</td>\n",
       "      <td>[0.13064274, 0.020471288, 0.0112923775, 0.0018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>\\n pal skin stretched \\n out like a drum \\n ha...</td>\n",
       "      <td>nest</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>[flower, stick, hedge, leather, pearl, stone]</td>\n",
       "      <td>[0, 57, 114, 367, 171, 342]</td>\n",
       "      <td>[0.016783189, 0.0026360513, 0.0015681898, 0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prompt_ind  time_point  batch_ind  ind_in_batch  \\\n",
       "0           85          59          3            15   \n",
       "1           34          47          1            11   \n",
       "2           40         132          1            17   \n",
       "3           24         115          1             1   \n",
       "4           83          78          3            13   \n",
       "5           78          78          3             8   \n",
       "6           23         132          1             0   \n",
       "7           64          11          2            18   \n",
       "8           67           9          2            21   \n",
       "9           32          54          1             9   \n",
       "10          24          32          1             1   \n",
       "11          26          85          1             3   \n",
       "12          22          92          0            22   \n",
       "13          84          71          3            14   \n",
       "14          50          95          2             4   \n",
       "15          84          65          3            14   \n",
       "16          20          97          0            20   \n",
       "17           6          52          0             6   \n",
       "18          84          65          3            14   \n",
       "\n",
       "                                        leading_words ground_word  \\\n",
       "0    short glass from the nightstand alongside Jam...     Charles   \n",
       "1    shoes. They were nice shoes, a little dirty, ...        pair   \n",
       "2   , smashing a white plastic mask and the face b...      joined   \n",
       "3    never cover it. He considered, took in his pa...        good   \n",
       "4        race. \\n \\n ``Time to show off, ''he grinned         and   \n",
       "5    the day it would've been easy! Not so today, ...         two   \n",
       "6    like to feel her warmth in person. \\n \\n His ...      always   \n",
       "7   back in the day ''. Before John's eighteenth b...    received   \n",
       "8    of the human race are you not? And I believe ...       known   \n",
       "9    than a few seconds, with a grunt of approval ...         end   \n",
       "10  scape. He pushed back the low, thin limbs of t...         the   \n",
       "11   at the buffet delivered to the table I was si...       whole   \n",
       "12  ones have promised to combat the threat, but a...         the   \n",
       "13   out like a drum \\n hair like a nest \\n rats h...     through   \n",
       "14  . It followed behind him closely, its prismati...         its   \n",
       "15  \\n pal skin stretched \\n out like a drum \\n ha...        nest   \n",
       "16        \\n Tom waited. \\n \\n ``Plus, we dragons are     magical   \n",
       "17  . It was as if he were strapped in and forced ...          TV   \n",
       "18  \\n pal skin stretched \\n out like a drum \\n ha...        nest   \n",
       "\n",
       "    ground_word_prob                                              words  \\\n",
       "0           0.000020        [steadily, then, poured, tried, kept, held]   \n",
       "1           0.179135            [pair, item, shoe, good, look, fashion]   \n",
       "2           0.006150  [emerged, was, moved, climbed, approached, flo...   \n",
       "3           0.027579           [man, step, lifetime, call, half, light]   \n",
       "4           0.140701                          [as, at, in, to, from, a]   \n",
       "5           0.058444                    [a, hours, five, six, some, 24]   \n",
       "6           0.029038                    [were, and, was, did, in, life]   \n",
       "7           0.002462              [been, no, turned, left, lived, seen]   \n",
       "8           0.001096                   [of, you, we, that, spoken, for]   \n",
       "9           0.001602                    [my, the, each, his, which, be]   \n",
       "10          0.017019       [looked, saw, had, removed, headed, snapped]   \n",
       "11          0.005451        [table, meal, mess, video, battle, private]   \n",
       "12          0.102680          [to, in, most, more, actually, qualified]   \n",
       "13          0.034577              [in, through, around, off, out, away]   \n",
       "14          0.211368                      [the, a, his, as, like, John]   \n",
       "15          0.000242      [flower, stick, hedge, leather, pearl, stone]   \n",
       "16          0.001153           [pretty, big, born, scared, hard, great]   \n",
       "17          0.011284              [hours, other, TV, sun, re, thoughts]   \n",
       "18          0.000242      [flower, stick, hedge, leather, pearl, stone]   \n",
       "\n",
       "                       abs_inds  \\\n",
       "0        [0, 5, 10, 42, 15, 30]   \n",
       "1          [0, 2, 5, 12, 7, 15]   \n",
       "2         [0, 4, 8, 45, 12, 24]   \n",
       "3      [0, 13, 27, 332, 40, 81]   \n",
       "4           [0, 2, 4, 3, 6, 12]   \n",
       "5        [0, 7, 15, 14, 22, 45]   \n",
       "6          [0, 2, 5, 58, 7, 15]   \n",
       "7        [0, 7, 14, 27, 21, 42]   \n",
       "8            [0, 1, 3, 2, 4, 9]   \n",
       "9            [0, 1, 3, 5, 4, 9]   \n",
       "10   [0, 37, 75, 103, 112, 225]   \n",
       "11    [0, 17, 35, 227, 52, 105]   \n",
       "12         [0, 3, 7, 6, 10, 21]   \n",
       "13          [0, 2, 4, 3, 6, 12]   \n",
       "14          [0, 2, 5, 3, 7, 15]   \n",
       "15  [0, 57, 114, 367, 171, 342]   \n",
       "16      [0, 11, 22, 88, 33, 66]   \n",
       "17       [0, 7, 15, 50, 22, 45]   \n",
       "18  [0, 57, 114, 367, 171, 342]   \n",
       "\n",
       "                                                probs  \n",
       "0   [0.10372717, 0.02085523, 0.012287442, 0.003576...  \n",
       "1   [0.17913476, 0.07442557, 0.024114424, 0.009932...  \n",
       "2   [0.2035434, 0.023714384, 0.014630686, 0.003562...  \n",
       "3   [0.05573973, 0.00720579, 0.0045993393, 0.00047...  \n",
       "4   [0.4007027, 0.14070147, 0.039737307, 0.1127209...  \n",
       "5   [0.16936234, 0.025678951, 0.015335284, 0.01554...  \n",
       "6   [0.2050555, 0.032089997, 0.016160188, 0.002230...  \n",
       "7   [0.12943263, 0.02312811, 0.012637037, 0.006488...  \n",
       "8   [0.51000386, 0.16448319, 0.051479, 0.08973123,...  \n",
       "9   [0.37410486, 0.1755186, 0.028461115, 0.0193081...  \n",
       "10  [0.029349394, 0.0058049792, 0.0024685704, 0.00...  \n",
       "11  [0.03326915, 0.007902123, 0.004121192, 0.00066...  \n",
       "12  [0.3068631, 0.051326152, 0.03858295, 0.0393857...  \n",
       "13  [0.302741, 0.12086674, 0.01853007, 0.034577254...  \n",
       "14  [0.292927, 0.21136764, 0.018125672, 0.05230688...  \n",
       "15  [0.016783189, 0.0026360513, 0.0015681898, 0.00...  \n",
       "16  [0.08390506, 0.010970011, 0.0065556336, 0.0017...  \n",
       "17  [0.13064274, 0.020471288, 0.0112923775, 0.0018...  \n",
       "18  [0.016783189, 0.0026360513, 0.0015681898, 0.00...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-c2b9f9886ab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'leading_words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert results.drop_duplicates('leading_words').shape == results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_ind</th>\n",
       "      <th>time_point</th>\n",
       "      <th>batch_ind</th>\n",
       "      <th>ind_in_batch</th>\n",
       "      <th>leading_words</th>\n",
       "      <th>ground_word</th>\n",
       "      <th>ground_word_prob</th>\n",
       "      <th>words</th>\n",
       "      <th>abs_inds</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>short glass from the nightstand alongside Jam...</td>\n",
       "      <td>Charles</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>[steadily, then, poured, tried, kept, held]</td>\n",
       "      <td>[0, 5, 10, 42, 15, 30]</td>\n",
       "      <td>[0.10372717, 0.02085523, 0.012287442, 0.003576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>shoes. They were nice shoes, a little dirty, ...</td>\n",
       "      <td>pair</td>\n",
       "      <td>0.179135</td>\n",
       "      <td>[pair, item, shoe, good, look, fashion]</td>\n",
       "      <td>[0, 2, 5, 12, 7, 15]</td>\n",
       "      <td>[0.17913476, 0.07442557, 0.024114424, 0.009932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>, smashing a white plastic mask and the face b...</td>\n",
       "      <td>joined</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>[emerged, was, moved, climbed, approached, flo...</td>\n",
       "      <td>[0, 4, 8, 45, 12, 24]</td>\n",
       "      <td>[0.2035434, 0.023714384, 0.014630686, 0.003562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>never cover it. He considered, took in his pa...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>[man, step, lifetime, call, half, light]</td>\n",
       "      <td>[0, 13, 27, 332, 40, 81]</td>\n",
       "      <td>[0.05573973, 0.00720579, 0.0045993393, 0.00047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>race. \\n \\n ``Time to show off, ''he grinned</td>\n",
       "      <td>and</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>[as, at, in, to, from, a]</td>\n",
       "      <td>[0, 2, 4, 3, 6, 12]</td>\n",
       "      <td>[0.4007027, 0.14070147, 0.039737307, 0.1127209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>the day it would've been easy! Not so today, ...</td>\n",
       "      <td>two</td>\n",
       "      <td>0.058444</td>\n",
       "      <td>[a, hours, five, six, some, 24]</td>\n",
       "      <td>[0, 7, 15, 14, 22, 45]</td>\n",
       "      <td>[0.16936234, 0.025678951, 0.015335284, 0.01554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>like to feel her warmth in person. \\n \\n His ...</td>\n",
       "      <td>always</td>\n",
       "      <td>0.029038</td>\n",
       "      <td>[were, and, was, did, in, life]</td>\n",
       "      <td>[0, 2, 5, 58, 7, 15]</td>\n",
       "      <td>[0.2050555, 0.032089997, 0.016160188, 0.002230...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_ind  time_point  batch_ind  ind_in_batch  \\\n",
       "0          85          59          3            15   \n",
       "1          34          47          1            11   \n",
       "2          40         132          1            17   \n",
       "3          24         115          1             1   \n",
       "4          83          78          3            13   \n",
       "5          78          78          3             8   \n",
       "6          23         132          1             0   \n",
       "\n",
       "                                       leading_words ground_word  \\\n",
       "0   short glass from the nightstand alongside Jam...     Charles   \n",
       "1   shoes. They were nice shoes, a little dirty, ...        pair   \n",
       "2  , smashing a white plastic mask and the face b...      joined   \n",
       "3   never cover it. He considered, took in his pa...        good   \n",
       "4       race. \\n \\n ``Time to show off, ''he grinned         and   \n",
       "5   the day it would've been easy! Not so today, ...         two   \n",
       "6   like to feel her warmth in person. \\n \\n His ...      always   \n",
       "\n",
       "   ground_word_prob                                              words  \\\n",
       "0          0.000020        [steadily, then, poured, tried, kept, held]   \n",
       "1          0.179135            [pair, item, shoe, good, look, fashion]   \n",
       "2          0.006150  [emerged, was, moved, climbed, approached, flo...   \n",
       "3          0.027579           [man, step, lifetime, call, half, light]   \n",
       "4          0.140701                          [as, at, in, to, from, a]   \n",
       "5          0.058444                    [a, hours, five, six, some, 24]   \n",
       "6          0.029038                    [were, and, was, did, in, life]   \n",
       "\n",
       "                   abs_inds                                              probs  \n",
       "0    [0, 5, 10, 42, 15, 30]  [0.10372717, 0.02085523, 0.012287442, 0.003576...  \n",
       "1      [0, 2, 5, 12, 7, 15]  [0.17913476, 0.07442557, 0.024114424, 0.009932...  \n",
       "2     [0, 4, 8, 45, 12, 24]  [0.2035434, 0.023714384, 0.014630686, 0.003562...  \n",
       "3  [0, 13, 27, 332, 40, 81]  [0.05573973, 0.00720579, 0.0045993393, 0.00047...  \n",
       "4       [0, 2, 4, 3, 6, 12]  [0.4007027, 0.14070147, 0.039737307, 0.1127209...  \n",
       "5    [0, 7, 15, 14, 22, 45]  [0.16936234, 0.025678951, 0.015335284, 0.01554...  \n",
       "6      [0, 2, 5, 58, 7, 15]  [0.2050555, 0.032089997, 0.016160188, 0.002230...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" the day it would've been easy! Not so today, it took me\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[5, 'leading_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_base = 'MTURK_QUESTIONS_THREE_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(file_name_base+'_backup_of_different_prob_slices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_orders = []\n",
    "with open(file_name_base + '_blind_output.txt', 'w') as file: \n",
    "    file.write('For each of the following assignments, rank on a scale of 1-5 how possible each word is, given the provided context. \\n')\n",
    "    file.write('Some words are stems, if the word could be completed then you can still rank it highly. And be generous with acronyms that could be plausible. ')\n",
    "    file.write('It helps to repeat the last few words of the prompt in your head while deciding how replaceable the current one is.')\n",
    "    file.write('5 means the word would work very well here, 1 means it doesnt make any sense, 3 means it could potentially work.')\n",
    "    file.write('===================================================== \\n \\n')\n",
    "    for ind in range(results.shape[0]):\n",
    "        file.write('Prompt '+str(ind)+'. \\n')\n",
    "        file.write('The '+str(leading_prompt)+' words in front: \\n \\n')\n",
    "        file.write(results.loc[ind, 'leading_words']+' _______')\n",
    "        #file.write(results.loc[ind, 'leading_words']+' : '+ results.loc[ind, 'ground_word'] )\n",
    "        file.write('\\n')\n",
    "        \n",
    "        words = [results.loc[ind, 'ground_word']]\n",
    "        words += list(results.loc[ind, 'words'])\n",
    "        words =np.asarray(words)\n",
    "        \n",
    "        order = ['ground_word']\n",
    "        order += [str(i) for i in range(len(words)-1)]\n",
    "        order = np.asarray(order)\n",
    "        \n",
    "        probs = [results.loc[ind, 'ground_word_prob']]\n",
    "        #print('ground word', probs)\n",
    "        probs += results.loc[ind, 'probs'].tolist()\n",
    "        #print('all other probs added', probs)\n",
    "        probs = np.asarray(probs)\n",
    "                \n",
    "        #print(words, order)\n",
    "        shuffler = np.random.choice(range(len(words)), size =len(words), replace=False )\n",
    "        #print(len(words))\n",
    "        #print(shuffler)\n",
    "        #print(len(words))\n",
    "        #print(words)\n",
    "        words = words[shuffler]\n",
    "        order = order[shuffler]\n",
    "        #print(probs)\n",
    "        probs = probs[shuffler]\n",
    "        \n",
    "        question_answers = []\n",
    "        for w, p, o in zip(words,probs, order):\n",
    "            \n",
    "            if o=='ground_word':\n",
    "                w_p = (w,p,1)\n",
    "            else: \n",
    "                w_p = (w,p,0)\n",
    "        \n",
    "            question_answers.append(w_p)\n",
    "            \n",
    "        answer_orders.append(question_answers)\n",
    "        \n",
    "        #print('after', words, order)\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            file.write(str(i+1)+'. '+words[i]+' ')\n",
    "                \n",
    "        file.write('\\n \\n')\n",
    "        file.write('=====================================================')\n",
    "        file.write('\\n \\n')\n",
    "        \n",
    "with open(file_name_base + '_answers.txt', 'w') as file: \n",
    "    for ind, w_p in enumerate(answer_orders):\n",
    "        file.write('Prompt '+str(ind)+' : \\n')\n",
    "        for el_ind, el in enumerate(w_p): \n",
    "            file.write(str(el_ind+1) + '. '+str(el) +' ')\n",
    "        file.write('\\n')\n",
    "        file.write('=====================================================')\n",
    "        file.write('\\n')\n",
    "\n",
    "pickle.dump(answer_orders,open(file_name_base + '_answers_list.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('tried', 0.003576610004529357, 0),\n",
       "  ('held', 0.005421289708465338, 0),\n",
       "  ('steadily', 0.10372716933488846, 0),\n",
       "  ('kept', 0.010425571352243423, 0),\n",
       "  ('then', 0.02085522934794426, 0),\n",
       "  ('poured', 0.0122874416410923, 0),\n",
       "  (' Charles', 2.0199675418552943e-05, 1)],\n",
       " [('good', 0.009932535700500011, 0),\n",
       "  ('look', 0.02176796644926071, 0),\n",
       "  ('fashion', 0.00743699399754405, 0),\n",
       "  ('item', 0.07442557066679001, 0),\n",
       "  ('pair', 0.17913475632667542, 0),\n",
       "  (' pair', 0.17913475632667542, 1),\n",
       "  ('shoe', 0.024114424362778664, 0)],\n",
       " [('floated', 0.005868957843631506, 0),\n",
       "  ('emerged', 0.20354339480400085, 0),\n",
       "  ('was', 0.02371438406407833, 0),\n",
       "  ('moved', 0.014630685560405254, 0),\n",
       "  ('approached', 0.00939475279301405, 0),\n",
       "  (' joined', 0.006150468252599239, 1),\n",
       "  ('climbed', 0.0035624520387500525, 0)],\n",
       " [(' good', 0.027579067274928093, 1),\n",
       "  ('half', 0.0028285677544772625, 0),\n",
       "  ('call', 0.00047750750673003495, 0),\n",
       "  ('man', 0.05573973059654236, 0),\n",
       "  ('light', 0.0015321819810196757, 0),\n",
       "  ('lifetime', 0.0045993393287062645, 0),\n",
       "  ('step', 0.0072057899087667465, 0)],\n",
       " [('at', 0.14070147275924683, 0),\n",
       "  ('from', 0.011677422560751438, 0),\n",
       "  ('as', 0.40070268511772156, 0),\n",
       "  ('in', 0.03973730653524399, 0),\n",
       "  ('a', 0.003003384917974472, 0),\n",
       "  ('to', 0.11272090673446655, 0),\n",
       "  (' and', 0.14070147275924683, 1)],\n",
       " [(' two', 0.05844415724277496, 1),\n",
       "  ('hours', 0.025678951293230057, 0),\n",
       "  ('five', 0.015335284173488617, 0),\n",
       "  ('six', 0.01554463617503643, 0),\n",
       "  ('24', 0.0025524254888296127, 0),\n",
       "  ('some', 0.00912496168166399, 0),\n",
       "  ('a', 0.16936233639717102, 0)],\n",
       " [('in', 0.013501197099685669, 0),\n",
       "  (' always', 0.029037535190582275, 1),\n",
       "  ('and', 0.032089997082948685, 0),\n",
       "  ('life', 0.007663062307983637, 0),\n",
       "  ('were', 0.20505550503730774, 0),\n",
       "  ('was', 0.016160188242793083, 0),\n",
       "  ('did', 0.002230095211416483, 0)],\n",
       " [('been', 0.12943263351917267, 0),\n",
       "  ('seen', 0.0032554396893829107, 0),\n",
       "  ('left', 0.006488459184765816, 0),\n",
       "  ('turned', 0.012637036852538586, 0),\n",
       "  ('lived', 0.008287622593343258, 0),\n",
       "  ('no', 0.02312811091542244, 0),\n",
       "  (' received', 0.0024621165357530117, 1)],\n",
       " [('we', 0.051479000598192215, 0),\n",
       "  ('you', 0.1644831895828247, 0),\n",
       "  ('spoken', 0.029615432024002075, 0),\n",
       "  ('of', 0.5100038647651672, 0),\n",
       "  ('for', 0.007482153829187155, 0),\n",
       "  (' known', 0.00109648029319942, 1),\n",
       "  ('that', 0.08973123133182526, 0)],\n",
       " [('each', 0.028461115434765816, 0),\n",
       "  ('be', 0.011250074952840805, 0),\n",
       "  ('the', 0.17551860213279724, 0),\n",
       "  ('his', 0.01930817775428295, 0),\n",
       "  (' end', 0.0016022849595174193, 1),\n",
       "  ('my', 0.3741048574447632, 0),\n",
       "  ('which', 0.02339542657136917, 0)],\n",
       " [('saw', 0.005804979242384434, 0),\n",
       "  ('had', 0.0024685703683644533, 0),\n",
       "  ('removed', 0.0017322930507361889, 0),\n",
       "  ('headed', 0.001557698706164956, 0),\n",
       "  ('looked', 0.029349394142627716, 0),\n",
       "  (' the', 0.01701940782368183, 1),\n",
       "  ('snapped', 0.0007649028557352722, 0)],\n",
       " [('battle', 0.002502989023923874, 0),\n",
       "  ('meal', 0.007902123034000397, 0),\n",
       "  ('mess', 0.0041211917996406555, 0),\n",
       "  ('table', 0.03326914831995964, 0),\n",
       "  ('video', 0.0006613422883674502, 0),\n",
       "  (' whole', 0.0054514845833182335, 1),\n",
       "  ('private', 0.001380592817440629, 0)],\n",
       " [(' the', 0.10267956554889679, 1),\n",
       "  ('to', 0.30686309933662415, 0),\n",
       "  ('actually', 0.01910395361483097, 0),\n",
       "  ('qualified', 0.0031193112954497337, 0),\n",
       "  ('most', 0.038582950830459595, 0),\n",
       "  ('in', 0.05132615193724632, 0),\n",
       "  ('more', 0.03938571363687515, 0)],\n",
       " [('through', 0.12086673825979233, 0),\n",
       "  ('in', 0.30274099111557007, 0),\n",
       "  ('away', 0.01237712986767292, 0),\n",
       "  ('out', 0.01569700427353382, 0),\n",
       "  (' through', 0.034577254205942154, 1),\n",
       "  ('off', 0.034577254205942154, 0),\n",
       "  ('around', 0.018530070781707764, 0)],\n",
       " [('the', 0.29292699694633484, 0),\n",
       "  (' its', 0.2113676369190216, 1),\n",
       "  ('as', 0.0523068830370903, 0),\n",
       "  ('John', 0.0027255264576524496, 0),\n",
       "  ('a', 0.2113676369190216, 0),\n",
       "  ('his', 0.01812567189335823, 0),\n",
       "  ('like', 0.009230446070432663, 0)],\n",
       " [('pearl', 0.0011454552877694368, 0),\n",
       "  ('hedge', 0.0015681898221373558, 0),\n",
       "  (' nest', 0.00024162190675269812, 1),\n",
       "  ('flower', 0.01678318902850151, 0),\n",
       "  ('stone', 0.0006124623469077051, 0),\n",
       "  ('leather', 0.0005706683732569218, 0),\n",
       "  ('stick', 0.002636051271110773, 0)],\n",
       " [('hard', 0.003958933055400848, 0),\n",
       "  ('born', 0.006555633619427681, 0),\n",
       "  ('pretty', 0.08390506356954575, 0),\n",
       "  (' magical', 0.0011530055198818445, 1),\n",
       "  ('scared', 0.001736448029987514, 0),\n",
       "  ('great', 0.0022246637381613255, 0),\n",
       "  ('big', 0.010970011353492737, 0)],\n",
       " [(' TV', 0.011283732950687408, 1),\n",
       "  ('re', 0.004881990607827902, 0),\n",
       "  ('hours', 0.13064274191856384, 0),\n",
       "  ('sun', 0.001812005415558815, 0),\n",
       "  ('TV', 0.01129237748682499, 0),\n",
       "  ('thoughts', 0.001977781532332301, 0),\n",
       "  ('other', 0.02047128789126873, 0)],\n",
       " [('pearl', 0.0011454552877694368, 0),\n",
       "  ('flower', 0.01678318902850151, 0),\n",
       "  ('leather', 0.0005706683732569218, 0),\n",
       "  ('hedge', 0.0015681898221373558, 0),\n",
       "  (' nest', 0.00024162190675269812, 1),\n",
       "  ('stick', 0.002636051271110773, 0),\n",
       "  ('stone', 0.0006124623469077051, 0)]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 3, 4, 3, 1, 4, 5, 4, 4, 2],\n",
       " [3, 2, 5, 1, 4, 5, 3, 5, 2, 4],\n",
       " [5, 4, 1, 5, 3, 5, 4, 5, 2, 2],\n",
       " [3, 5, 3, 5, 5, 3, 4, 5, 4],\n",
       " [3, 5, 2, 2, 3, 4, 4, 1, 5, 5],\n",
       " [5, 2, 1, 5, 2, 5, 4, 5, 1, 4],\n",
       " [1, 5, 5, 4, 5, 5, 5, 4, 3],\n",
       " [1, 1, 2, 1, 1, 5, 5, 5, 2, 4],\n",
       " [4, 1, 5, 5, 4, 3, 5, 3, 2, 2],\n",
       " [5, 2, 3, 4, 5, 5, 5, 5, 5, 4]]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[5, 3, 4, 3, 1, 4, 5, 4, 4, 2,], [3,2,5,1,4,5,3,5,2,4],[5,4,1,5, 3,5,4,5,2,2], [3,5,3,5,5,3,4,5,4], [3,5,2,2,3,4,4,1,5,5],[5, 2, 1,5,2,5,4,5,1,4], [1,5,5,4,5,5,5,4,3], [1,1,2,1,1,5,5,5,2,4], [4,1,5,5,4,3,5,3,2,2], [5,2,3,4,5,5,5,5,5,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for r in res: \n",
    "    print(len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = dict()\n",
    "for ind, (r, a) in enumerate(zip(res, answer_orders)):\n",
    "    for r_el, a_el in zip(r,a):\n",
    "        try:\n",
    "            prd[a_el[1]].append(r_el)\n",
    "        except:\n",
    "            prd[a_el[1]] = [r_el]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = pd.DataFrame(prd).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.438798e-02</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.133592e-01</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.043329e-02</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.023387e-06</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.646489e-11</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "1.438798e-02  5\n",
       "1.133592e-01  1\n",
       "1.043329e-02  5\n",
       "4.023387e-06  4\n",
       "4.646489e-11  5"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probs</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.438798e-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.133592e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.043329e-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.023387e-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.646489e-11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          probs  rep\n",
       "0  1.438798e-02    5\n",
       "1  1.133592e-01    1\n",
       "2  1.043329e-02    5\n",
       "3  4.023387e-06    4\n",
       "4  4.646489e-11    5"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.reset_index(inplace=True)\n",
    "#prd.drop('index', axis=1, inplace=True)\n",
    "prd.columns = ['probs', 'rep']\n",
    "prd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd['rep'] = prd['rep']*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x821a70fd0>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do a scatter plot of this. \n",
    "plt.scatter(prd['probs'], prd['rep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rep</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.083610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.023622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.054777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        probs\n",
       "rep          \n",
       "2    0.081718\n",
       "4    0.025102\n",
       "6    0.083610\n",
       "8    0.023622\n",
       "10   0.054777"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = prd.groupby('rep').mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x822685400>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(means['probs'], means.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_plot_columns(prd, 'TFS is tighter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAFACAYAAACcBJbJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAH4pJREFUeJzt3Xm4XFWZ7/HvjwDKPEgAGZIIKgqKqAH0yhWlHRAEvKAIDQgqxqFtZwG9dnew1cahW7tRW3FCVKS1FQcmBSVIRJAEAjJIKxiIjAEEAgoIvP3HWkV2KlWn6oSza9eq+n2e5zynau9d+11r7aq3Vq09KSIwM7NyrNZ0AczMbHKcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GNIUkh6co3rn5VjrN5l/gclfbnTspLOlHR4XWWzFUm6V9I2Ta2z7vfiqHLiBiQtlvSgpE3apl+a31izBlyeF0l6JH8Alkm6RtLrB1mGOkXExyLiyC7zXhERXweQdISk+asaR9JWkr4n6XZJd0u6QtIRq7q+Qcnvx9skrVOZdqSkeVMdKyLWjYjrJlG2D+b35b2S7pf0cOX5lauyzgliPabtP8qcuJf7A3Bw64mkZwJrN1ccboqIdYH1gXcDX5K0XYPlKdE3gCXATOAJwGHArVMZoNuviikwDXhnTeteZflLd9383nwL8KvW84jYoenyVdW4bRrnxL3cN4DXVZ4fDpxUXUDS4yR9StINkm6V9AVJa+V5G0k6TdJSSX/Kj7eqvHaepH+W9Mvci/5pew+/k0jOAO4Edqys72mSzpZ0Z+6RH1iZd2Iu29k51nmSZnZav6S98y+LeyQtkTS3bf5uki6QdFeef0Q/r8veIOkmSTdLel9lnXMlfbNLeebl3uXTgS8Az8+9ubsk7ZzbfVpl+f0lXdal+XYGToyI+yLioYi4NCLO7KNuG0g6KW/L6yV9SNJqed4ReRt+WtIdwNw8/Q2Srs7b/ifd2nsSPgm8T9KGHdpopaGoVrtVnr8pl2eZpKskPadTEFWGKiTtlZddJunG6jabjLZ1PkHSj/P75GJJH+nQi36JpN/l7fA5JStt/7y+iT6DL5L0R0lHS7oF+NqqlL8ETtzLXQisL+npOTEcBLQnl+OApwI7AU8GtgT+Mc9bjfRGmQnMAP4CfLbt9X8LvB7YFFgT6PnBkLSapH2BTYDf52nrAGcDJ+d1HQR8XtL2lZceAvxzft0i4FtdQtxH+sLaENgbeKukV+U4M4EzgeOB6bnei3q9ruLFwFOAlwFHS3pJr/q2RMTVrNij2zAiLgbuyOtrOYy2L9iKC4HPSTpI0ozqjB51Ox7YANgG2D3XszpUtStwHbAZ8FFJ+wEfBPbP6zof+Ha/de1iATCPPt4j7SS9hvSF8jrSL7Z9Se3Wy1eAN0fEesAzgJ9PNnYHnyO9VzYndYY67b94JelLdkfgQODlnbZ/XnaizyA5zsakz+GcKSj/cIqIsf8DFgMvAT4E/AuwJykxrg4EMAsQ6Q24beV1zwf+0GWdOwF/qjyfB3yo8vxtwFldXvsi4BHgLuAB4GHgXZX5rwXOb3vNF4F/yo9PBE6pzFs3r2Pr/DyAJ3eJ/Rng0/nxB4BT+2zD6utm5RhPq8z/BPCV/Hgu8M22ZVevtNOR+fERwPy2OEcD38qPNwb+DDyxS5k2In3Qr8z1XwTsPFHdSEMUDwLbV6a9GZhXKdMNba85E3hj5flquVwzH+P78RnA3aQvgyMrZVihzTq020+Ad/YZ69H3AnBDruv6fb52pe1TXWduy78C21XmfaT6mrzsbpXn3wGO6bR+enwGSZ+bB4HHr0q7l/TnHveKvkHqFR/Byr246aQx74X5J91dwFl5OpLWlvTF/NP6HuAXwIbVn/XALZXHfyYl1G5uitTLWB/4D2CPyryZwK6tcuSyHELqbbQsaT2IiHtJQy1btAeRtKukc/OwwN2kXk5rCGdr4NpOhevxupXKAFzfKf4q+CawT/7VcSDpC+zmTgtGxJ8i4phIY6+bkRL3DySJ7nXbBFgjl7da9i0rz5ewopnAv1e2xZ2kJLNl23Lkn/atnXkfnKiiEXEFcBpwzETLddB1u/VwALAXcL3S8NrzV2EdVdNJnZ9qe7W3HfT/uZjwM5gtjYj7V73IZXDiroiI60k7KfcCvt82+3bS8McOkX62bxgRG0TaSQPwXmA7YNeIWB94YZ6ux1imB0i9zGdWhiKWAOdVyrFhpJ+Tb628dOvWA0nrknqnN3UIcTLwI1JvfAPSuGKrzEuAbbsUbaLXrVQG0vBRp/gTWenSlRFxI/Ar0rDEYaQv294rirgd+BTpy2NjutftdlIvsTpGPQO4cYJyLSENMVS3x1oRcUGHcrwllu/M+1gfRf8n4E2s+CVwX/5f3Xne/qXdbbt1FREXR8R+pOG3H5B6v4/FUuAhYKvKtK27LNuxSG3Pe30GO71mJDlxr+yNwB4RcV91YkQ8AnwJ+LSkTQEkbSnp5XmR9UhvqrskbUz6wE2JiHgQ+FeWj+WdBjxV0mGS1sh/O+cdOi175Z1va5LGui+MiE69nfWAOyPifkm7kH5xtHyLtOPoQEmr5x1NO/XxupZ/yL9EdiCNEf/XJKt+K7BVrkPVScBRwDNZ+Qv2UZI+LukZuezrAW8Ffh8Rd3SrW0Q8TEpYH5W0Xh4Lfw8r7++o+gLwgVzP1s7N10yyrh1FxO9J7faOyrSlpC+SQyVNk/QGVkzUXybt2Hxu3tH3ZPXYWSppTUmHSNogIv4K3EMarnssZX+YtH3m5vfB01jxAIBeVtj+fXwGx4YTd5uIuDYiFnSZfTRpB+GFeTjkHFIvG9IY71qkXsGFpJ9wU+mrwAxJ+0TEMtIOuoNIvdhbgI8Dj6ssfzLpy+NO4LnAoV3W+zbgw5KWkb4YHu1lRcQNpF8f783rWQQ8q9frKs4jtdfPgE9FxE8nWeefk8anb5F0e2X6qaQe8akR8ecJXr92XvYu0s7EmaQddb3q9vekXu11wHxSW361W5CIOJXU/qfk98UVwCsmU9EePgys0zbtTcD7STsddwAe7d1HxHeBj+ZyLyP1njfuI85hwOJch7eQht8eq7eTdvTeQvp19G3Sfpt+dNr+E30Gx4byoL6NEEknAn+MiA81XZa6SLqWNDxxTtNlsf5J+jiweUT47NjHwD1uK46kA0hjmVNxuJrVSOl8gx3zkM0upKHIU5suV+lG9swiG01Kp31vDxyWxzxtuK1HGh7ZgjRm/a/ADxst0QjwUImZWWE8VGJmVhgnbjOzwtQyxr3JJpvErFmz6li1mdlIWrhw4e0RMb33kjUl7lmzZrFgQbdDoc3MrJ2k63svlXioxMysME7cZmaFceI2MyuME7eZWWGcuM3MCtPXUSWSFpOuMvYw8FBEzK6zUGZm1t1kDgd8cb4YvZmZNchDJWZmhem3xx3ATyUF8MWIOKF9AUlzyHdVnjFjRvtss45mHXN67TEWH7d37THMBqnfHvduEfEc0l09/k7SC9sXiIgTImJ2RMyePr2vszbNzGwV9JW48w1aiYjbSBdB36XOQpmZWXc9E7ekdfKNVpG0Duleh1fUXTAzM+usnzHuzYBTJbWWPzkipvpGuGZm1qeeiTsirmP53a/NzKxhPhzQzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwKU8s9Jx+LJk+B9unXZlYC97jNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwKM3RnTo4rn7VpVq9R+oy5x21mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlYYJ24zs8L4lHezMTNKp36PK/e4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysMH0nbknTJF0q6bQ6C2RmZhObTI/7ncDVdRXEzMz601filrQVsDfw5XqLY2ZmvfTb4/4McBTwSI1lMTOzPvRM3JJeCdwWEQt7LDdH0gJJC5YuXTplBTQzsxX10+N+AbCvpMXAKcAekr7ZvlBEnBARsyNi9vTp06e4mGZm1tIzcUfEByJiq4iYBRwE/DwiDq29ZGZm1pGP4zYzK8ykrg4YEfOAebWUxMzM+uIet5lZYZy4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWGcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrzKRupGBmU2PWMafXHmPxcXvXHsOa4R63mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYXzmpJkNjM8YnRrucZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWF6Jm5Jj5f0a0mXSbpS0rGDKJiZmXXWz+GADwB7RMS9ktYA5ks6MyIurLlsZmbWQc/EHREB3JufrpH/os5CmZlZd32NcUuaJmkRcBtwdkRcVG+xzMysm74Sd0Q8HBE7AVsBu0h6RvsykuZIWiBpwdKlS6e6nGZmlk3qqJKIuAs4F9izw7wTImJ2RMyePn36VJXPzMza9HNUyXRJG+bHawEvBX5bd8HMzKyzfo4qeSLwdUnTSIn+OxFxWr3FMjOzbvo5quRy4NkDKIuZmfXBZ06amRXGidvMrDBO3GZmhXHiNjMrjBO3mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWGcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrjBO3mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVpmfilrS1pHMlXSXpSknvHETBzMyss9X7WOYh4L0RcYmk9YCFks6OiKtqLpuZmXXQs8cdETdHxCX58TLgamDLugtmZmadTWqMW9Is4NnARXUUxszMeus7cUtaF/ge8K6IuKfD/DmSFkhasHTp0qkso5mZVfSVuCWtQUra34qI73daJiJOiIjZETF7+vTpU1lGMzOr6OeoEgFfAa6OiH+rv0hmZjaRfnrcLwAOA/aQtCj/7VVzuczMrIuehwNGxHxAAyiLmZn1wWdOmpkVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWGcuM3MCuPEbWZWmJ7X4zYbVbOOOb32GIuP27v2GDZ+3OM2MyuME7eZWWGcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrjBO3mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoXpmbglfVXSbZKuGESBzMxsYv30uE8E9qy5HGZm1qeeiTsifgHcOYCymJlZHzzGbWZWmCm7WbCkOcAcgBkzZkzVam0AfNNcs7JMWY87Ik6IiNkRMXv69OlTtVozM2vjoRIzs8L0czjgt4FfAdtJ+qOkN9ZfLDMz66bnGHdEHDyIgpiZWX88VGJmVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlYYJ24zs8I4cZuZFcaJ28ysME7cZmaFceI2MyuME7eZWWGcuM3MCuPEbWZWGCduM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrjBO3mVlhnLjNzArjxG1mVhgnbjOzwjhxm5kVxonbzKwwTtxmZoVx4jYzK4wTt5lZYZy4zcwK48RtZlaYvhK3pD0lXSPp95KOqbtQZmbWXc/ELWka8DngFcD2wMGStq+7YGZm1lk/Pe5dgN9HxHUR8SBwCrBfvcUyM7Nu+kncWwJLKs//mKeZmVkDFBETLyC9GtgzIo7Mzw8Ddo2It7ctNweYk59uB1wz9cXtaBPg9gHFcuzxjt10fMce7dgzI2J6Pwuu3scyNwJbV55vlaetICJOAE7oq3hTSNKCiJg96LiOPX6xm47v2OMVeyL9DJVcDDxF0pMkrQkcBPyo3mKZmVk3PXvcEfGQpLcDPwGmAV+NiCtrL5mZmXXUz1AJEXEGcEbNZVlVAx+eceyxjd10fMcer9hd9dw5aWZmw8WnvJuZFcaJ28ysME7cZmaF6Wvn5DCRtDbwdiCA40mHJ+4P/Bb4cETcW2PsacCRpGPZz4qIX1bmfSgiPlJX7AnK9JSI+N0A4igiQtLqpGvWXB8Rd9cdt0eZToiIOb2XfMxxpkXEw23TNoqIP9UduxJv44i4c0Cx9p9ofkR8fxDlqJK0bp2f7dKU2OM+EdgMeBJwOjAb+CQg4D9rjv1FYHfgDuA/JP1bZd6Eb/Ya/azOlUvaV9ItwE2SXgnMJ31hXiVp7zpj5/gbd/l7ArBXzbF3l3QDcJukMyTNqMyurd0lvUDS1ZKulLSrpLOBiyUtkfT8uuJW7JP/3gh8BTgk/30ZeMMA4ndyVZ0rl/RMSRfmNj5B0kaVeb+uM/aqKK7HDTw1Ig6UJOBm4CW5JzgfuKzm2LtExI4Akj4LfF7S94GDSV8ctWj7glhhFrBBXXGzY4FnA2sDl5Iud3C1pCcB3yF9edZpKXA9K7Zv5Oeb1hz7U8Argd8ArwXOkXRIRFxMjdsb+DRwILAuqX1fFRHzJT2H9KX5ghpjExGvB5D0U2D7iLg5P38iqeNUC0nv6TaL1BZ1+k9gLnAh6Vf1fEn7RsS1wBo1x560EhM3ADlZnxH5eMb8vO5jG9esxH8ImCPpH4GfU+8baw5wFPBAh3l/rTEuAJUP7g0RcXWe9oc8dFS364C/iYgb2mdIWtJh+am0ZkRcnh+fIulK4L8lvY/05VGXNSLiNwCSlkbEfICIuETSWjXGbbd1a9tntwIzui08BT5G+vX8UId5dY8OrBcRZ+XHn5K0EDgrX5tp6I6ZLjFxL2iNd0XEoz/bJG0LLBtA7D0rG5iI+LCkm6h3mOZi4NKI+FX7DElza4ybQ2i1iHgEeFNl4mpUvshq9BlgI2ClxA18oubYD0naLCJuBYiI30h6KXAaMKvGuNUk9YG2eYNo85afSfoJ8O38/LXAOTXGuwT4QUQsbJ8h6cga47ZibNDabxMR50o6APgesHHdsSdrpE7Aae1Aa7ocU03SdODPEXFfA7GfByyKiPvbps8Cdo+Irw+6TIMi6eXArRGxqG36RsA7IuLYmuLuC5wTEX9um74tcEBE1P2FVY35/4AX5qe/iIhTa4y1HXBHRKx0Nb7qF2hNsf8WuC4iLmybPgP4h4h4U+dXNmMkEvegji4YptiSdqz8jB+b2Dl+k9u7kbpL2jwibhlgvGmkL48XDypml3IMtN7DEruXEo8q6aTJyy42FfvEhuI2HRua3d4nNhR3oNcKyoc/PiKp7p3fvTR5jaRhvT5TkWPcndw2hrHrPKphmGNDs9u7qbo3Efde4Df5cMRHh+ki4h0DLMM4v8+7GonEHRF7jmHsgZ/sMySxG93eNFf3LzUQ8/v5r0lN1HsYYk+ouDHufDTDEcABpDMYHwb+B/hCRMwbxdiSdpxofp1jrk3GzvGb3N6N1r2tLAM7c7It7prAU/PTayKi9sNP2+I3Uu+mY/dSYuL+GumEjHOAVwP3AOcDRwM/jIjjRy22pPMnmB0R8cIJ5hcbO8dvcns3Uvfq5RMkbQ/8gHQSiIDXRsRFdcTtUI4XAV8HFufYWwOHR8QvaorXWL2Hpc37FhFF/QGXtz2/MP9/HHD1qMYe179xbHPgksrj04FX5Me7ABcMsBwLge0qz58KLBzFeg9Lm/f7V+IY918lbRsR1+ZTgB8EiIgHBnDmZCOxJe0eEefl43tXEhG13QO0ydhZY9t7COoOsEVEnJnj/XrAZ06uERHXtJ5ExP9IGtTp303Wu8nYfSkxcb8fOFfSA6TyHwSPnqRy2ojGfilwHvCaDvOCem/e3GRsaHZ7N1X3bST9iPQzfStJa8fyk3EGed2MBZK+DHwzPz8EWFBjvCbrPSxt3pfixrghnSEJPCE6nGE1yrHH1bi1uaTd2yYtjIh7JW0GvDoiPjegcjwO+DtgtzzpfODzEdHpmjlTEa+xeg9Lm/eruMSdT0G9LSLuzx/oI4DnkC77+KVIF38audiVMrwc2AF4fGtaRHys7rhNxR6GNs/laKzdmyLpb0jju39puiy2ohLPnDyD5eU+DtgbuAjYmfrvyNxkbCR9HjgceA+wFnAo8OS64zYcu9E2h8HXXdJqkl4v6TRJl0m6RNIp+SiPQXodcJnSdao/KWkfVa5TPdWarPcQtXlfSuxxXxUR2+fHC4GdI125DkmXRcSzRjF2jnF5ROzYiiVpPeD0qPmQvCZjN93mOc5A697kIZBdyrNFLsf7SDvuatk3No6H+q6qEnvcSyTtkR8vJh1bitIdUUY5NkDrJ+v9kjYH7ge2GPHYTbc5DL7uz42IuRExPyLeBbwsIs4m/dp4W41xVyDpUElfBP4beAnwWeD/1hiyyXoPRZv3q8SjSo4ETlK6DvXdwCJJi4ANST9lRzU2wJmSNiTdmWUR6SzCQV1WtanYTbc5DL7uTR7yWvUZ4FrgC8C5EbG45nhjd6jvqipuqKRF0tNJJwSsDvwRuLj1E3rUYkt6Xqx8neC1gLWi5lNym4zdFnPg27upuudfGCeS7ni0OnBQRFyUD4F8f0QcVVfsDmXZgXQ97t2Ap5BOez+spliN1XuY2rwfxSbucSLpkoh4zrjFblrD7d74IZCS1ifd33J30hDJJqQzVw+vMaYP9e1DiWPcXUkayFEGwxZ7XI1ym0fS6U4wmw+wGPNJd3u/nHS9ju3qTNrQbL2HpM37MlI9bknPjQ73qys9tqS7gK4X9omIjqdklx67l7q39zDWXdLpEbH3oON2Iun4iPj7AcVqrN7D1OYtI5W4R5Wk35F20nUUEeeNYuymjXPd+zHOw2hNK+6oEqVbKX0AeBWwKemaEbcBPwSOi4i7RjD2sgaTRJOxG93eNFj3PN66C7BlnnQj8OsY8Z5Wk/Uuqc1LHOP+DvAn4EURsXFEPAF4cZ72nRGNvbjGdQ9zbGh2ey+uef0dSXoZ8DtgLrBX/jsW+F2eN5KarHdpbV7cUImkayJiu8nOKz12Jc7/AWZR+bUUESfVHbep2MPQ5jnWwOou6WrS9aAXt01/EnBGRDy9jriTJenSiHj2FK6vsXqX0uYtxQ2VANdLOgr4ekTcCqB0Ba8jgCUjHBtJ3wC2ZflJIJCGDmpP3A3GbrTNc7xB1711rHq7GxmuS4z++xSvr8l6l9LmQJmJ+7XAMcB5kjbN024lXRv5wBGODTAb2L6hMbemYjfd5jD4un8VuFjSKSz/ctqadC3yr9QdXNKPSV9MHbWOpomIE6c4dJP1brTNJ6u4oZJ+STo8IgZ1OvhAYkv6LvCOiLh5qtc9zLH7Uef2bqLu+UzR/VhxR9mPIuKqAcRuXZt6f2Bzlt9I4WDg1oh4d42xm6x3Y7Ena5QT98idbSjpXGAn4NekU3OBwRxP3GTsftS5vYe17pK+FxEH1Lj+BRExu9e0Qau73sMau6rEoZJ+aQRjz61pvcMeux91bu+5Na77sdim5vWvI2mbiLgOHt1Rt07NMftRd72HNfajRjlxN/lTopbYTR5PXcDJJrVt7yGue93v8XcD8yRdR/pinAm8ueaY/Ri5z/ZkjXLiHpket6RldH7DiHSJhfWnMt6wxJ6kKd/eBdW9FhFxlqSnAE/Lk34bNd1v0ian2MStdCPTA1j52NoP54e/HJXYEbHeVK6vlNhVTWzvYan7BAbROXkuy9v8WZIGdt7ABEamU7aqik3cpFOe7wYWUtlh1BIRbx/R2ONqrNtc6V6PW0fE5ZXJR9ccs7HzBiplGHi9hyF2L8UeVSLpioh4xrjFHlfj2OaS5gH7kjpYC0nXaPllRAzkzj/5bMKBH7vfZL2bbvN+lXitkpYLJD1zDGOPq3Fs8w0i4h7S8dQnRcSupHs/DsoVpOO4B63Jejfd5n0peahkN+AISX8g/XRu7TDaccRjj6txbPPVJT2RdIbo/28g/ibAVZIGffx6k/Vuus37UnLifsWYxh5X49jmxwI/AeZHxMWStiFdwW5Q5g4wVlWT9W66zftS7Bi32aiS9PGIOFrSayLiu02XZ1CarHdpbe7EbTZkJP0G2BFY2NRlG3I5qsexr0m6St59dR2/3mS9h6XN+1XyUInZqDqLdKOIdSXdU5k+0BN/qsex57vD7Ac8r8aQTdZ7KNq8X+5xmw0pST+NiJe1TftERBzVYJmm9OYJXWI0Vu9hbPNOSj4c0GzUbdJh2p6DCi5p/8rfqyUdB9w/gNBN1rvRNu+Xh0rMhoyktwJvA7aRVD1rbz3gggEWZZ/K44dI9+Dcr65gTdZ7iNq8Lx4qMRsySne23wj4F9Ldf1qWRcSdzZSqfk3Wu7Q2d+I2s44kbQUcD7wgTzofeGdEdLo3ow2Qx7jNrJuvke7tuUX++3GeZg1zj9vMOpK0KCJ26jXNBs89bjPr5g5Jh0qalv8OBe5oulDmHreZdSFpJmmM+/mkMygvIN3t/oZGC2Y+HNDMViZpGrB/03eyt848VGJmK4mIh4GDmy6HdeahEjPrSNKnSReW+i/gvtb0iLiksUIZ4MRtZl1IOjc/bCWJ1gWX9mioSJZ5jNvMujmNlLRbdzYP4B5JO0XEouaKZe5xm1lHkk4GZpNOwhHwSuByYBbw3Yj4RHOlG29O3GbWkaRfAHtFxL35+brA6aSr5S2MiO2bLN8481ElZtbNplRuEgz8FdgsIv7SNt0GzGPcZtbNt4CLJP0wP98HOFnSOsBVzRXLPFRiZl1Jms3yqwP+MiIWNFkeS5y4zcwK4zFuM7PCOHGbmRXGidvMrDBO3GZmhXHiNjMrzP8CNbSzl5FHT5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_plot_columns(nuc_tighter, 'Nuc is Tighter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want when Nuc is tighter for the difference between Nuc and TFS to be smaller than it is when TFS is tighter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: 1 = 0.3999999999999999\n",
      "position: 2 = 0.6000000000000001\n",
      "position: 3 = 0.7999999999999998\n"
     ]
    }
   ],
   "source": [
    "abs_diff_of_different_locations(tfs_tighter, tfs_label, n_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: 1 = 1.75\n",
      "position: 2 = 0.25\n",
      "position: 3 = 1.25\n"
     ]
    }
   ],
   "source": [
    "abs_diff_of_different_locations(nuc_tighter,tfs_label, n_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
