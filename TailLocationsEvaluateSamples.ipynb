{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the difference between nucleus and TFS set of words. See if the words in this set are reasonable. They should be reasonable for when TFS is looser and should not be when TFS is tighter. Out of this set of words, take the highest, lowest prob ones and the middle one? Need at least 3 word gap between them. \n",
    "Rank each one in how reasonable it is. Control baseline is how reasonable words at different points in the body are. The first word, half way and at the closer of the tails. Can also get words outside of the last tail, just outside, halfway to the end, and at the very end. \n",
    "There are 9 different words in total. Should i rank all of them, scramble up a subset? Or have a ranking for each of the subsets differently? Probably scramble them all up. And then present 3 of them??\n",
    "Can then see overall how replaceable different parts of the distributions is, and for TFS and nucleus specifically. Have a control with the bad words. And should be able to hopefully show that the difference in replaceability between the TFS and nucleus words is small when TFS is looser and large when TFS is tighter. Can see how specific this is also. Eg could just look at the last TFS and nucleus words, see the diff in replaceability, or maybe need to look at the averages. Look most at this unique subset and these three points should hopefully categorize it. Want them because i dont know how good the signal is going to be. For the closest words for example. \n",
    "Can also get overall data on how replaceability corresponds to model probability. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pandas as pd    \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decodeLogits import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\\n'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#updated\n",
    "vals_dict = {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99],\n",
    "'n': [0.5, 0.63, 0.69, 0.81, 0.75, 0.9], 'k':[1,40,200]  }\n",
    "\n",
    "\n",
    "''' {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\n",
    "'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing analysis for the same logit going to use the ground truth as it is a Schelling point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=25\n",
    "num_batches=4\n",
    "prompt_length=100\n",
    "generated_length=150\n",
    "tot_len = prompt_length+generated_length\n",
    "\n",
    "import encoder\n",
    "model_name='345M'\n",
    "models_dir='../gpt-2/models'\n",
    "enc = encoder.get_encoder(model_name, models_dir)\n",
    "\n",
    "prompts=pd.read_csv('test_dataframe_500primer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_out_path = 'gpt-2_output/'\n",
    "additional_path = ''#'' -model_774M-seed_27'\n",
    "#all_perps = pickle.load( gzip.open(gpt_out_path+'all_perplexities_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb'))\n",
    "all_logits = pickle.load( gzip.open(gpt_out_path+'all_logits_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb')) # needed to get the probabilities\n",
    "text = pickle.load( gzip.open(gpt_out_path+'all_text_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n",
      "24\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_num = 0\n",
    "mapping_to_batch = dict()\n",
    "for i in range(num_batches):\n",
    "    num_in_batch = all_logits[i].shape[0]\n",
    "    for el, b_ind in zip(range(tot_num, tot_num+num_in_batch), range(0, num_in_batch)):\n",
    "        mapping_to_batch[el] = (i, b_ind) # actual batch and then the ind in that batch\n",
    "    print( num_in_batch)\n",
    "    tot_num+= num_in_batch\n",
    "tot_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 150, 50257)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at max deviation and getting these points within the tails of each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to also focus on the maximum deviation portions at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinorMax</th>\n",
       "      <th>batch_ind</th>\n",
       "      <th>ind_in_batch</th>\n",
       "      <th>time_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Max</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Min</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Max</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Max</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Min</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinorMax  batch_ind  ind_in_batch  time_point\n",
       "95      Max          3             3          86\n",
       "31      Min          1            10         117\n",
       "99      Max          1            10         125\n",
       "56      Max          1             7          55\n",
       "6       Min          0            10          39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random prompts and locations within the 150 generation locations\n",
    "\n",
    "num_prompts_and_timepoints_wanted = 100 # cant be larger than 100 right now!!!\n",
    "assert num_prompts_and_timepoints_wanted <=100\n",
    "leading_prompt = 15\n",
    "\n",
    "want_min_max = True\n",
    "\n",
    "if want_min_max==True:\n",
    "    assert model_name=='345M', 'THIS IS FOR THE 345 NOT THE 774!!!!'\n",
    "    minmax = pd.read_csv('Min_Max_Disagreement_Coords_TFS90.csv') \n",
    "    #shuffle it and take the number that is wanted. \n",
    "    minmax = minmax.sample(frac= num_prompts_and_timepoints_wanted/minmax.shape[0])\n",
    "    display(minmax.head())\n",
    "    \n",
    "else:\n",
    "    rand_prompts = np.random.randint(0,tot_num, num_prompts_and_timepoints_wanted)\n",
    "    # leadingprompt until 150. as the logits are 150 not 250. \n",
    "    # -1 because of the end token prediction\n",
    "    rand_times = np.random.randint(0,generated_length-1, num_prompts_and_timepoints_wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting randomly from the max deviations: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_logits[0][0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting random locations\n",
    "for the differnet gen strategies. find the tail locations. take the tokens at each position. \n",
    "move onto the next random location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying all analyses to the logits. \n",
    "prompt_length = 100\n",
    "methods_wanted = ['tfs_0.9', 'n_0.63']#['tfs_0.95', 'n_0.69']#, 'k_40']\n",
    "tfs_label = methods_wanted[0]\n",
    "nuc_label = methods_wanted[1]\n",
    "nuc_org = float(nuc_label.split('_')[-1])\n",
    "methods_wanted += ['InTail']\n",
    "to_df = []\n",
    "\n",
    "# randomly select generations and positions in those generations. from the original prompts. \n",
    "for r_ind in range(0, num_prompts_and_timepoints_wanted):\n",
    "    \n",
    "    if want_min_max ==True:\n",
    "        prompt = 999\n",
    "        batch_ind, ind_in_batch = minmax.iloc[r_ind, 1], minmax.iloc[r_ind, 2]\n",
    "        time_point = minmax.iloc[r_ind,3]\n",
    "        if time_point>=149:\n",
    "            continue # because of the stop token being predicted. \n",
    "        text_timepoint = time_point+prompt_length+1 # +1 because the perplexities keeps the end prediction token. \n",
    "    else:\n",
    "        prompt = rand_prompts[r_ind]\n",
    "        time_point = rand_times[r_ind]\n",
    "        text_timepoint = time_point+prompt_length+1 # +1 because the perplexities keeps the end prediction token. \n",
    "        batch_ind, ind_in_batch = mapping_to_batch[prompt]\n",
    "    \n",
    "    diff_tail_positions = dict()\n",
    "    largest_tail_id = 0\n",
    "    method_of_largest_tail_id = None\n",
    "    \n",
    "    sps = softmax(-np.sort(-all_logits[batch_ind][ind_in_batch, time_point, :]))\n",
    "    indices = np.argsort(-all_logits[batch_ind][ind_in_batch, time_point, :])\n",
    "    ground_token = text[batch_ind][ind_in_batch][text_timepoint]\n",
    "                \n",
    "    for key,all_params in vals_dict.items():\n",
    "        for par in all_params:\n",
    "            method = key+'_'+str(par)\n",
    "            if method in methods_wanted:\n",
    "            \n",
    "                if key == 'tfs':\n",
    "                    first = sps[1:] - sps[:-1]\n",
    "                    second = first[1:] - first[:-1]\n",
    "                    tail_id = new_tfs(second, par)\n",
    "                elif key=='flat':\n",
    "                    tail_id = flat(sps, par)\n",
    "                elif key=='n':\n",
    "                    tail_id = nucleus_calc(sps, par)\n",
    "                elif key=='k':\n",
    "                    tail_id = par\n",
    "                else:\n",
    "                    print('key not recognized')\n",
    "                    break\n",
    "                    \n",
    "                if tail_id > largest_tail_id:\n",
    "                    largest_tail_id=tail_id\n",
    "                    method_of_largest_tail_id=method\n",
    "            \n",
    "                diff_tail_positions[method] = tail_id#, ids_above_tail)\n",
    "\n",
    "    if len(diff_tail_positions.keys()) >2: \n",
    "        print('CURRENTLY CANT LOOK AT MORE THAN 2 THINGS!')\n",
    "        break\n",
    "        \n",
    "    # indices is still sorted. and can be used \n",
    "    smaller_method = list(diff_tail_positions.keys())\n",
    "    smaller_method.remove(method_of_largest_tail_id)\n",
    "    smaller_method = smaller_method[0]\n",
    "    smaller_tail_id = diff_tail_positions[smaller_method]\n",
    "    \n",
    "    #now I deal with this later where I can rerun the nucleus part of it. \n",
    "    #if largest_tail_id - smaller_tail_id < 3:\n",
    "    #    #print('not enough space between the tail locations')\n",
    "    #    continue\n",
    "        \n",
    "    # what the ground token is and what the looser method is here. \n",
    "    ground_word = decoder_text([ground_token])\n",
    "    \n",
    "    #get the 15 words in front. \n",
    "    lead_prompt_words = decoder_text(text[batch_ind][ind_in_batch][text_timepoint-leading_prompt:text_timepoint])\n",
    "    df_row = [prompt, time_point, batch_ind, ind_in_batch, lead_prompt_words, ground_word, method_of_largest_tail_id] # taking it from the last one. \n",
    "    \n",
    "    diff_tail_positions['InTail'] = 50527\n",
    "    for method in methods_wanted: # want to do them in the same order.\n",
    "        # add the tail for each method: \n",
    "        df_row += [diff_tail_positions[method]]\n",
    "        if method == method_of_largest_tail_id: # the cut between the tighter and looser\n",
    "            unique_tokens = indices[smaller_tail_id:largest_tail_id]\n",
    "            starting_pos = smaller_tail_id\n",
    "        elif method == 'InTail': #the tail itself\n",
    "            unique_tokens = indices[largest_tail_id:]\n",
    "            starting_pos = largest_tail_id\n",
    "        else: # the closest one\n",
    "            unique_tokens = indices[:smaller_tail_id]\n",
    "            starting_pos = 0\n",
    "            \n",
    "        #remove any non word tokens: \n",
    "        unique_tokens, relative_pos = remove_non_words(unique_tokens)\n",
    "        # select the right positions\n",
    "        words_and_positions_wanted = get_specific_positions(unique_tokens, starting_pos, relative_pos)\n",
    "        \n",
    "        while method_of_largest_tail_id == tfs_label and words_and_positions_wanted[0] == [None,None,None]: # need to rerun with a looser nucleus threshold. \n",
    "            # get a tighter nucleus sample\n",
    "            nuc_org = nuc_org-0.03\n",
    "            tail_id = nucleus_calc(sps, nuc_org)\n",
    "            \n",
    "            if tail_id == 1: # cant get any tighter. \n",
    "                break\n",
    "            \n",
    "            unique_tokens = indices[:tail_id]\n",
    "            starting_pos = 0\n",
    "            \n",
    "            unique_tokens, relative_pos = remove_non_words(unique_tokens)\n",
    "            # select the right positions\n",
    "            words_and_positions_wanted = get_specific_positions(unique_tokens, starting_pos, relative_pos)\n",
    "\n",
    "        specific_probs = []\n",
    "        for abs_pos in words_and_positions_wanted[1]:\n",
    "            specific_probs.append(sps[abs_pos])\n",
    "        \n",
    "        df_row += [words_and_positions_wanted[0], words_and_positions_wanted[1], specific_probs ]\n",
    "        \n",
    "    to_df.append(df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(to_df, columns = ['prompt_ind', 'time_point', \n",
    "                               'batch_ind', 'ind_in_batch', 'leading_words',\n",
    "                               'ground_word', 'looser_method', 'tail_pos_'+methods_wanted[0], \n",
    "        'specific_words_'+methods_wanted[0], 'positions_'+methods_wanted[0],'probs'+methods_wanted[0],\n",
    "                                         'tail_pos_'+methods_wanted[1],\n",
    "                    'specific_words_'+methods_wanted[1], 'positions_'+methods_wanted[1],\n",
    "                    'probs'+methods_wanted[1],'tail_pos_'+methods_wanted[2],\n",
    "                    'specific_words_'+methods_wanted[2], 'positions_'+methods_wanted[2], 'probs'+methods_wanted[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert results.drop_duplicates('leading_words').shape == results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number that are not none 58\n"
     ]
    }
   ],
   "source": [
    "# need to remove nones: \n",
    "none_mask = []\n",
    "for ind in range(results.shape[0]):\n",
    "    if results.loc[ind, 'specific_words_'+tfs_label]==[None, None, None] or results.loc[ind, 'specific_words_'+nuc_label]==[None, None, None]:\n",
    "        none_mask.append(False)\n",
    "    else:\n",
    "        none_mask.append(True)\n",
    "        \n",
    "print('number that are not none', sum(none_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = results[none_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 19)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_ind</th>\n",
       "      <th>time_point</th>\n",
       "      <th>batch_ind</th>\n",
       "      <th>ind_in_batch</th>\n",
       "      <th>leading_words</th>\n",
       "      <th>ground_word</th>\n",
       "      <th>looser_method</th>\n",
       "      <th>tail_pos_tfs_0.9</th>\n",
       "      <th>specific_words_tfs_0.9</th>\n",
       "      <th>positions_tfs_0.9</th>\n",
       "      <th>probstfs_0.9</th>\n",
       "      <th>tail_pos_n_0.63</th>\n",
       "      <th>specific_words_n_0.63</th>\n",
       "      <th>positions_n_0.63</th>\n",
       "      <th>probsn_0.63</th>\n",
       "      <th>tail_pos_InTail</th>\n",
       "      <th>specific_words_InTail</th>\n",
       "      <th>positions_InTail</th>\n",
       "      <th>probsInTail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aged weapons. Everyone else was given or assi...</td>\n",
       "      <td>infantry</td>\n",
       "      <td>n_0.63</td>\n",
       "      <td>13</td>\n",
       "      <td>[only, last, most]</td>\n",
       "      <td>[0, 6, 12]</td>\n",
       "      <td>[0.06087858, 0.008750073, 0.0055404124]</td>\n",
       "      <td>550</td>\n",
       "      <td>[humans, captain, workforce]</td>\n",
       "      <td>[13, 275, 549]</td>\n",
       "      <td>[0.0052030683, 0.00049465947, 0.00025142057]</td>\n",
       "      <td>50527</td>\n",
       "      <td>[name, nutrients, interstitial]</td>\n",
       "      <td>[550, 21428, 50224]</td>\n",
       "      <td>[0.0002514129, 8.5582576e-07, 1.9516675e-11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>never understood words too well, but I guess ...</td>\n",
       "      <td>;</td>\n",
       "      <td>tfs_0.9</td>\n",
       "      <td>6</td>\n",
       "      <td>[and, for, because]</td>\n",
       "      <td>[0, 2, 3]</td>\n",
       "      <td>[0.33381513, 0.09870116, 0.07159144]</td>\n",
       "      <td>4</td>\n",
       "      <td>[and, for, because]</td>\n",
       "      <td>[0, 2, 3]</td>\n",
       "      <td>[0.33381513, 0.09870116, 0.07159144]</td>\n",
       "      <td>50527</td>\n",
       "      <td>[as, drains, cumbers]</td>\n",
       "      <td>[6, 21375, 50249]</td>\n",
       "      <td>[0.014609966, 1.7478184e-08, 7.535083e-14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>999</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>no longer individuals. Mothers are no longer ...</td>\n",
       "      <td>occasional</td>\n",
       "      <td>n_0.63</td>\n",
       "      <td>7</td>\n",
       "      <td>[jokes, pun, a]</td>\n",
       "      <td>[0, 3, 6]</td>\n",
       "      <td>[0.084562816, 0.009146591, 0.007705728]</td>\n",
       "      <td>579</td>\n",
       "      <td>[to, image, inventions]</td>\n",
       "      <td>[7, 297, 578]</td>\n",
       "      <td>[0.007355045, 0.00052459346, 0.00028983405]</td>\n",
       "      <td>50527</td>\n",
       "      <td>[impressions, Fitzgerald, conservancy]</td>\n",
       "      <td>[580, 20968, 50238]</td>\n",
       "      <td>[0.00028833427, 3.9972744e-07, 6.7375017e-13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>999</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>\\n \\n A child's broken plaything, risen with e...</td>\n",
       "      <td>c</td>\n",
       "      <td>n_0.63</td>\n",
       "      <td>8</td>\n",
       "      <td>[and, its, but]</td>\n",
       "      <td>[0, 4, 7]</td>\n",
       "      <td>[0.0692719, 0.010805639, 0.00824078]</td>\n",
       "      <td>374</td>\n",
       "      <td>[with, leaving, turns]</td>\n",
       "      <td>[8, 202, 373]</td>\n",
       "      <td>[0.0060455734, 0.0009405914, 0.0005247816]</td>\n",
       "      <td>50527</td>\n",
       "      <td>[sought, mainland, Interstitial]</td>\n",
       "      <td>[374, 21177, 50216]</td>\n",
       "      <td>[0.00052268384, 2.634107e-07, 1.730388e-11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>999</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>would realize truly how powerful Anonymous wa...</td>\n",
       "      <td>friends</td>\n",
       "      <td>n_0.63</td>\n",
       "      <td>5</td>\n",
       "      <td>[newfound, mask, father]</td>\n",
       "      <td>[0, 2, 4]</td>\n",
       "      <td>[0.071420684, 0.020989213, 0.01060408]</td>\n",
       "      <td>425</td>\n",
       "      <td>[success, creative, trusted]</td>\n",
       "      <td>[5, 212, 424]</td>\n",
       "      <td>[0.010030248, 0.0006455564, 0.00034931596]</td>\n",
       "      <td>50527</td>\n",
       "      <td>[huge, fall, Els]</td>\n",
       "      <td>[425, 21131, 50249]</td>\n",
       "      <td>[0.00034922536, 5.2094526e-07, 3.5534642e-12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_ind  time_point  batch_ind  ind_in_batch  \\\n",
       "1         999         117          1            10   \n",
       "3         999          55          1             7   \n",
       "4         999          39          0            10   \n",
       "5         999          14          1            17   \n",
       "8         999          47          2             1   \n",
       "\n",
       "                                       leading_words  ground_word  \\\n",
       "1   aged weapons. Everyone else was given or assi...     infantry   \n",
       "3   never understood words too well, but I guess ...            ;   \n",
       "4   no longer individuals. Mothers are no longer ...   occasional   \n",
       "5  \\n \\n A child's broken plaything, risen with e...            c   \n",
       "8   would realize truly how powerful Anonymous wa...      friends   \n",
       "\n",
       "  looser_method  tail_pos_tfs_0.9    specific_words_tfs_0.9 positions_tfs_0.9  \\\n",
       "1        n_0.63                13        [only, last, most]        [0, 6, 12]   \n",
       "3       tfs_0.9                 6       [and, for, because]         [0, 2, 3]   \n",
       "4        n_0.63                 7           [jokes, pun, a]         [0, 3, 6]   \n",
       "5        n_0.63                 8           [and, its, but]         [0, 4, 7]   \n",
       "8        n_0.63                 5  [newfound, mask, father]         [0, 2, 4]   \n",
       "\n",
       "                              probstfs_0.9  tail_pos_n_0.63  \\\n",
       "1  [0.06087858, 0.008750073, 0.0055404124]              550   \n",
       "3     [0.33381513, 0.09870116, 0.07159144]                4   \n",
       "4  [0.084562816, 0.009146591, 0.007705728]              579   \n",
       "5     [0.0692719, 0.010805639, 0.00824078]              374   \n",
       "8   [0.071420684, 0.020989213, 0.01060408]              425   \n",
       "\n",
       "          specific_words_n_0.63 positions_n_0.63  \\\n",
       "1  [humans, captain, workforce]   [13, 275, 549]   \n",
       "3           [and, for, because]        [0, 2, 3]   \n",
       "4       [to, image, inventions]    [7, 297, 578]   \n",
       "5        [with, leaving, turns]    [8, 202, 373]   \n",
       "8  [success, creative, trusted]    [5, 212, 424]   \n",
       "\n",
       "                                    probsn_0.63  tail_pos_InTail  \\\n",
       "1  [0.0052030683, 0.00049465947, 0.00025142057]            50527   \n",
       "3          [0.33381513, 0.09870116, 0.07159144]            50527   \n",
       "4   [0.007355045, 0.00052459346, 0.00028983405]            50527   \n",
       "5    [0.0060455734, 0.0009405914, 0.0005247816]            50527   \n",
       "8    [0.010030248, 0.0006455564, 0.00034931596]            50527   \n",
       "\n",
       "                    specific_words_InTail     positions_InTail  \\\n",
       "1         [name, nutrients, interstitial]  [550, 21428, 50224]   \n",
       "3                   [as, drains, cumbers]    [6, 21375, 50249]   \n",
       "4  [impressions, Fitzgerald, conservancy]  [580, 20968, 50238]   \n",
       "5        [sought, mainland, Interstitial]  [374, 21177, 50216]   \n",
       "8                       [huge, fall, Els]  [425, 21131, 50249]   \n",
       "\n",
       "                                     probsInTail  \n",
       "1   [0.0002514129, 8.5582576e-07, 1.9516675e-11]  \n",
       "3     [0.014609966, 1.7478184e-08, 7.535083e-14]  \n",
       "4  [0.00028833427, 3.9972744e-07, 6.7375017e-13]  \n",
       "5    [0.00052268384, 2.634107e-07, 1.730388e-11]  \n",
       "8  [0.00034922536, 5.2094526e-07, 3.5534642e-12]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results['looser_method'] == nuc_label).sum() # only 12 of these have TFS as the looser method. \n",
    "# using iterative nucleus i got this up to 15\n",
    "# need to try other tighter nucleus values for these ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.reset_index(inplace=True)\n",
    "results.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('backup_of_different_tail_slices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "apply() missing 1 required positional argument: 'func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-de1219211c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msamp_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'looser_method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# want to get the specific entries from each:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: apply() missing 1 required positional argument: 'func'"
     ]
    }
   ],
   "source": [
    "samp_methods = set(results['looser_method'].unique().tolist())\n",
    "# want to get the specific entries from each: \n",
    "results.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_base = 'tail_replaceable_comparisons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_orders = []\n",
    "with open(file_name_base + '_blind_output.txt', 'w') as file: \n",
    "    file.write('For each of the following assignments, rank on a scale of 1-5 how replaceable each word is, given the provided context. \\n')\n",
    "    file.write('Some words are stems, if the word could be completed then you can still rank it highly. And be generous with acronyms that could be plausible. ')\n",
    "    file.write('===================================================== \\n \\n')\n",
    "    for ind in range(results.shape[0]):\n",
    "        file.write('Prompt '+str(ind)+'. \\n')\n",
    "        file.write('The '+str(leading_prompt)+' words in front: \\n \\n')\n",
    "        file.write(results.loc[ind, 'leading_words']+' _______')\n",
    "        file.write('\\n')\n",
    "        \n",
    "        words = [results.loc[ind, 'ground_word']]\n",
    "        order = ['ground_word']\n",
    "        for m in methods_wanted: \n",
    "            col = 'specific_words_'+m\n",
    "            words += results.loc[ind, col]\n",
    "            for i in range(1,4):\n",
    "                order.append(m+\"-\"+str(i))\n",
    "                \n",
    "        words =np.asarray(words)\n",
    "        order = np.asarray(order)\n",
    "        \n",
    "        #print(words, order)\n",
    "        shuffler = np.random.choice(range(len(words)), size =len(words), replace=False )\n",
    "        \n",
    "        words = words[shuffler]\n",
    "        order = order[shuffler]\n",
    "        answer_orders.append(list(order))\n",
    "        #print('after', words, order)\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            file.write(str(i+1)+'. '+words[i]+' ')\n",
    "                \n",
    "        file.write('\\n \\n')\n",
    "        file.write('=====================================================')\n",
    "        file.write('\\n \\n')\n",
    "        \n",
    "with open(file_name_base + '_answers.txt', 'w') as file: \n",
    "    for ind, order in enumerate(answer_orders):\n",
    "        file.write('Prompt '+str(ind)+' : \\n')\n",
    "        for el_ind, el in enumerate(order): \n",
    "            file.write(str(el_ind+1) + '. '+el +' ')\n",
    "        file.write('\\n')\n",
    "        file.write('=====================================================')\n",
    "        file.write('\\n')\n",
    "\n",
    "pickle.dump(answer_orders,open(file_name_base + '_answers_list.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [[3, 5, 4, 5, 5, 4, 1, 3, 2, 1],\n",
    "       [5, 5, 5, 1, 5, 1, 4, 5, 4, 5], \n",
    "       [4, 5, 4, 2, 2, 4, 2, 1,1, 5], \n",
    "       [4, 4, 5, 4, 4, 2, 5, 4, 5, 2], \n",
    "       [5, 5, 5, 1, 3, 4, 5, 5, 5, 4], \n",
    "       [4, 3, 5,5,4,5, 5, 4, 1,1], \n",
    "       [5, 5, 4, 1, 4, 5,1,4,4,2], \n",
    "       [5,4,2,1,5,4,1,1,5,1], \n",
    "       [3,4,5,5,4,1,3,5,4,5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for r in res: \n",
    "    print(len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_0.69'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_wanted[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_tighter = dict()\n",
    "nuc_tighter = dict()\n",
    "\n",
    "for ind, (r, a) in enumerate(zip(res, answer_orders)):\n",
    "    lose_method = results.loc[ind, 'looser_method']\n",
    "    for r_el, a_el in zip(r,a):\n",
    "        if lose_method == tfs_label:\n",
    "            try:\n",
    "                nuc_tighter[a_el].append(r_el)\n",
    "            except:\n",
    "                nuc_tighter[a_el] = [r_el]\n",
    "        else: \n",
    "            try:\n",
    "                tfs_tighter[a_el].append(r_el)\n",
    "            except:\n",
    "                tfs_tighter[a_el] = [r_el]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_tighter = pd.DataFrame(tfs_tighter)\n",
    "nuc_tighter = pd.DataFrame(nuc_tighter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_plot_columns(tfs_tighter, 'TFS is tighter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_plot_columns(nuc_tighter, 'Nuc is Tighter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want when Nuc is tighter for the difference between Nuc and TFS to be smaller than it is when TFS is tighter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: 1 = 0.3999999999999999\n",
      "position: 2 = 0.6000000000000001\n",
      "position: 3 = 0.7999999999999998\n"
     ]
    }
   ],
   "source": [
    "abs_diff_of_different_locations(tfs_tighter, tfs_label, n_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: 1 = 1.75\n",
      "position: 2 = 0.25\n",
      "position: 3 = 1.25\n"
     ]
    }
   ],
   "source": [
    "abs_diff_of_different_locations(nuc_tighter,tfs_label, n_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
