{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\\n'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "#how be able to iterate through all of the different files\n",
    "\n",
    "#updated\n",
    "vals_dict = {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99],\n",
    "'n': [0.5, 0.63, 0.69, 0.81, 0.75, 0.9], 'k':[1,40,200]  }\n",
    "'''{'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\n",
    "'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.7222222222222222 stand err 0.2069207252957695\n",
      "mean 0.5153014969264527\n"
     ]
    }
   ],
   "source": [
    "#stat sig:\n",
    "import numpy as np\n",
    "vals = [1]*13\n",
    "vals += [0]*5\n",
    "tot  = len(vals)\n",
    "vals = np.asarray(vals)\n",
    "print('mean',vals.mean(), 'stand err',(1.96*(vals.std()/np.sqrt(tot))))\n",
    "print('mean',vals.mean()-(1.96*(vals.std()/np.sqrt(tot))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "prompts=pd.read_csv('test_dataframe_500primer.csv') # the text has the prompts so dont need this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_out_path = 'gpt-2_output/'\n",
    "additional_path = '-model_774M-seed_27'\n",
    "text = pickle.load( gzip.open(gpt_out_path+'all_text_perplexity_scores_for_the_dataset_Human_StoryPrompts_Completion.csv'+additional_path+'.pickle.gz', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert all of the numbers text from all of the different models into one dataframe with all of the prompts and the produced text separated out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[WP] You look out at the bright lights of the city and wonder how you ever grew up. \\n The lights dance across the evening sky. You can see the buildings in the distance, some lights turning of as the stores close down. You wonder how this all happened, when did everything change? \\n \\n When did *you* change? \\n \\n Everyone is born a child. Some grow up faster than others. Some do n't grow up at all. Hours of playing. Even school was fun. Learning games and imaginary friends, but that stuff is boring now. A little older and sports are the thing. Running around the field, ball between your legs, trying not to trip as you kick for the goal. Does n't matter much if you miss, you're having fun with friends. Sure, they may laugh if you miss, but you laugh right along with them. \\n \\n A glance at the body next to you. So calm, so quiet. Were you ever like that? It's hard to remember. You feel the knife in your hand. It feels heavier now than normal, as if this moment is more important than any other. Maybe it is. \\n \\n Did\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used to decode:\n",
    "\n",
    "from decodeLogits import *\n",
    "batch = 0\n",
    "ind = 0\n",
    "'''\n",
    "tokens = []\n",
    "for j in range(text[0].shape[2]):\n",
    "    tokens.append(np.argmax(df[0][ind, :, j]))'''\n",
    "decoder_text(text[batch][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating all completions for a particular random prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 27\n",
    "prompt_length = 100\n",
    "gs=dict()\n",
    "methods_wanted = ['tfs_0.95', 'n_0.69']#, 'k_40']\n",
    "additional_path = '774M_model'\n",
    "first = True\n",
    "for key, params in vals_dict.items():\n",
    "    for par in params:\n",
    "        if key+'_'+str(par) in methods_wanted:\n",
    "            #all_logits = pickle.load( gzip.open('gpt-2_output/all_logits_'+key+'-sampling-type_'+par+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "            text = pickle.load( gzip.open('gpt-2_output/all_text_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts_'+str(seed)+'-seed_'+additional_path+'.pickle.gz', 'rb'))\n",
    "            rand_selects = pickle.load( gzip.open('gpt-2_output/prompt_rand_selections_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts_'+str(seed)+'-seed_'+additional_path+'.pickle.gz', 'rb'))\n",
    "\n",
    "            generated_output = []\n",
    "            for batch in text:\n",
    "                for entry in batch:\n",
    "                    generated_output.append(decoder_text(entry[prompt_length:]))\n",
    "            col_name = 'Samp Type:'+key+' Param:'+str(par)\n",
    "            gs[col_name] = generated_output\n",
    "            \n",
    "    if first==True:\n",
    "        prompts_used = []\n",
    "        for batch in text:\n",
    "            for entry in batch:\n",
    "                prompts_used.append(decoder_text(entry[0:prompt_length]))\n",
    "        \n",
    "        first=False\n",
    "gs = pd.DataFrame(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Samp Type:tfs Param:0.95</th>\n",
       "      <th>Samp Type:n Param:0.69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pass, and your time is up. You are one of the...</td>\n",
       "      <td>, days, weeks, months, years. The life you liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n't I make sure he doesn't come back? \\n \\n \\n...</td>\n",
       "      <td>I try to tell it not to worry? \\n \\n \\n This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a lamp. So he was forced to create one. \\n \\n...</td>\n",
       "      <td>himself. He wished for the boy's family.\\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we have her. She's now with us.''\\n ``Oh, it'...</td>\n",
       "      <td>are holding her hostage. We'll have her for r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>, was a complete fucking idiot, who could neve...</td>\n",
       "      <td>, didn ’ t quite fit the character, and didn ’...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Samp Type:tfs Param:0.95  \\\n",
       "0   pass, and your time is up. You are one of the...   \n",
       "1  n't I make sure he doesn't come back? \\n \\n \\n...   \n",
       "2   a lamp. So he was forced to create one. \\n \\n...   \n",
       "3   we have her. She's now with us.''\\n ``Oh, it'...   \n",
       "4  , was a complete fucking idiot, who could neve...   \n",
       "\n",
       "                              Samp Type:n Param:0.69  \n",
       "0  , days, weeks, months, years. The life you liv...  \n",
       "1   I try to tell it not to worry? \\n \\n \\n This ...  \n",
       "2   himself. He wished for the boy's family.\\nAnd...  \n",
       "3   are holding her hostage. We'll have her for r...  \n",
       "4  , didn ’ t quite fit the character, and didn ’...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "for ind, p in enumerate(prompts_used):\n",
    "    if 'Write a story that seems normal on first sight' in p:\n",
    "        print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "16\n",
      "60\n",
      "35\n",
      "88\n",
      "62\n",
      "3\n",
      "54\n",
      "87\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "num_gens = 10\n",
    "file_name_base = 'test_big'\n",
    "answer_keys = []\n",
    "with open(file_name_base + '_blind_output.txt', 'w') as file: \n",
    "    \n",
    "    for ind in range(num_gens):\n",
    "    \n",
    "        select_a_random_prompt = np.random.choice(gs.shape[0])\n",
    "        select_random_generation_methods = np.random.choice(range(gs.shape[1]), size =gs.shape[1], replace=False )\n",
    "        #select_random_generation_methods = np.insert(select_random_generation_methods, 0, 0)\n",
    "        print(select_a_random_prompt)\n",
    "        select_random_generation_methods;\n",
    "        \n",
    "        answer_keys.append(gs.iloc[select_a_random_prompt,select_random_generation_methods].index.values)\n",
    "\n",
    "        file.write('Prompt: \\n \\n')\n",
    "        file.write(prompts_used[select_a_random_prompt])\n",
    "        file.write('\\n')\n",
    "        file.write('================== \\n')\n",
    "        for ind, out in enumerate(gs.iloc[select_a_random_prompt,select_random_generation_methods].tolist()):\n",
    "            file.write('Random Generation: '+str(ind)+' \\n \\n')\n",
    "            file.write(out)\n",
    "\n",
    "            file.write('\\n')\n",
    "            file.write('================== \\n')\n",
    "            if ind == gs.shape[1]-1: # dont write random generation at the end. \n",
    "                continue\n",
    "                \n",
    "        file.write('\\n \\n')\n",
    "        file.write('=====================================================')\n",
    "        file.write('\\n \\n')\n",
    "        \n",
    "with open(file_name_base + '_answers.txt', 'w') as file: \n",
    "    for ak in answer_keys:\n",
    "        for ind, k in enumerate(ak):\n",
    "            file.write(str(ind)+' : '+k+' \\n')\n",
    "        file.write('\\n')\n",
    "        file.write('=====================================================')\n",
    "        file.write('\\n')\n",
    "pickle.dump(answer_keys,open(file_name_base + '_answers_list.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the very tight ones are too close and degenerate into repeats. The prompts and stochasticity of a single generation are really hard to deal with though. it is also a lot to read in order to evaluate the quality. \n",
    "What is something I can evaluate algorithmically and where diverse beam search is outperformed? It may inherently need to be something that is long. \n",
    "Seems like there is definitely a sweet spot where dont want too many options but also dont want it to be degenerate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object),\n",
       " array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessing:\n",
    "\n",
    "\n",
    "alex_answers = [1, 0.5, 0.5, 0, 0, 0, 1, 0.5, 0, 1] # liked generation 0\n",
    "alex_chose = []\n",
    "\n",
    "for ind, a in enumerate(alex_answers):\n",
    "    if a==0.5:\n",
    "        continue\n",
    "    elif a==1:\n",
    "        want_key_ind = 0\n",
    "    elif a==0:\n",
    "        want_key_ind = 1\n",
    "    chosen = answer_keys[ind][want_key_ind]\n",
    "    alex_chose.append(chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object),\n",
       " array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object),\n",
       " array(['Samp Type:tfs Param:0.95', 'Samp Type:n Param:0.69'], dtype=object),\n",
       " array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Samp Type:n Param:0.69',\n",
       " 'Samp Type:n Param:0.69',\n",
       " 'Samp Type:n Param:0.69',\n",
       " 'Samp Type:n Param:0.69',\n",
       " 'Samp Type:n Param:0.69',\n",
       " 'Samp Type:n Param:0.69',\n",
       " 'Samp Type:n Param:0.69']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Samp Type:n Param:0.69', 'Samp Type:tfs Param:0.95'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.iloc[select_a_random_prompt,select_random_generation_methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.iloc[select_a_random_prompt,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_prompt =rand_selects[select_a_random_prompt]\n",
    "choose_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts.iloc[choose_prompt].test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
