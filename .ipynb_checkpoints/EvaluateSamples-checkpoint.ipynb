{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "#how be able to iterate through all of the different files\n",
    "\n",
    "#updated\n",
    "vals_dict = {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\n",
    "'n': [0.1, 0.25, 0.5, 0.75, 0.9], 'k':[1,10,40,200]  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, params in vals_dict.items():\n",
    "    for par in params:\n",
    "        if par ==None:\n",
    "            par = \"None\"\n",
    "        #all_logits = pickle.load( gzip.open('gpt-2_output/all_logits_'+key+'-sampling-type_'+par+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        text = pickle.load( gzip.open('gpt-2_output/all_text_'+key+'-sampling-type_'+par+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        rand_selects = pickle.load( gzip.open('gpt-2_output/prompt_rand_selections_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 250)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5139,  3768,  3912, 14879,  4848, 13605,  7192,  4237, 11121,\n",
       "        1026,  8831,  8895,  9386,  8417, 10926, 12170,   689, 11198,\n",
       "        5558, 14495,  9743,  3571, 10490, 15136, 14165,  5939,  1996,\n",
       "        5117,  7427,  1754,  8566,  8908,  3902,  7495, 11357,  5927,\n",
       "       14523,  7528, 11829, 12279, 14369,  3906,  3151,  9904,  9827,\n",
       "       12211, 12933,  3498,  9235,  6581, 14304, 14487,  5428, 11345,\n",
       "        7185, 10007,  5472,  4487,   540, 11144,  7012,  4381, 12873,\n",
       "        7952,  2756, 11068, 15111,  6720, 10393,  3551, 14269, 12066,\n",
       "        2866, 10860,  7183, 11955, 13936,  7243, 14593,  9269,  3369,\n",
       "        9500,  2613,  1021,  3822,  7491,  9998,  6938,  1582,  7865,\n",
       "        2662,  9045,  1324, 11431,  9123, 11092,  2847, 13290,   653,\n",
       "        1838])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "prompts=pd.read_csv('test_dataframe_500primer.csv') # the text has the prompts so dont need this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert all of the numbers text from all of the different models into one dataframe with all of the prompts and the produced text separated out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   58, 25527,    60,   921,   804,   503,   379,   262,  6016,\n",
       "        7588,   286,   262,  1748,   290,  4240,   703,   345,  1683,\n",
       "        6348,   510,    13,   220,   198,   383,  7588,  9280,  1973,\n",
       "         262,  6180,  6766,    13,   921,   460,   766,   262,  6832,\n",
       "         287,   262,  5253,    11,   617,  7588,  6225,   286,   355,\n",
       "         262,  7000,  1969,   866,    13,   921,  4240,   703,   428,\n",
       "         477,  3022,    11,   618,   750,  2279,  1487,    30,   220,\n",
       "         198,   220,   198,  1649,   750,  1635,  5832,     9,  1487,\n",
       "          30,   220,   198,   220,   198, 11075,   318,  4642,   257,\n",
       "        1200,    13,  2773,  1663,   510,  5443,   621,  1854,    13,\n",
       "        2773,   466,   299,   470,  1663,   510,   379,   477,    13,\n",
       "       19347,  1208,   319,   262,  4417,   286,   262,  2323,    26,\n",
       "         257,  1110,  8318,   416,  6364,  1973,   262,  1755,  6766,\n",
       "          13,   921,  4240,   508,   318,  1016,   284,  1663,   510,\n",
       "         262, 14162,    13,   220,   198,   220,   198,   198,  1849,\n",
       "           1,  1639,  1053,  1392,   257,  1693,  1909,    11,   788,\n",
       "        1701,   198,     1, 19457,    13,   632,   338,   655,   257,\n",
       "        1310,   517,  8253,   621,   314,  2938,    11,   475,   340,\n",
       "         338,   477,   922,   526,   220,   198,  1639,  2342,   262,\n",
       "        6016,  8824,  2971, 15360,   832,   262,  4675, 32209,    13,\n",
       "         632,   338,  6016,   290,   612,  3588,   470,   597,  6832,\n",
       "         287,   340,    13,   554,   257,  1310,  1643,    13,  1320,\n",
       "        1595,   470,  1612,   340,   338,   407,  7895,    13,   383,\n",
       "        6483,   389,  6565,    11,   612,   338,   645,  4979,   290,\n",
       "        2506,   338,   655,  3375,    13,   632,   338,  5897,   290,\n",
       "         991,   290,   345,   460,  1254,   703,  4950,  1243,   389,\n",
       "          13,   632,   338,   588,   345,  1053,  1392,   257,  4320,\n",
       "        1282,  2081,    13,  1320,   338,   618,   262], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[WP] You look out at the bright lights of the city and wonder how you ever grew up. \\n The lights dance across the evening sky. You can see the buildings in the distance, some lights turning of as the stores close down. You wonder how this all happened, when did everything change? \\n \\n When did *you* change? \\n \\n Everyone is born a child. Some grow up faster than others. Some do n\\'t grow up at all. Hours pass on the surface of the ground; a day passes by slowly across the night sky. You wonder who is going to grow up the fastest. \\n \\n\\n\\xa0\"You\\'ve got a job today, then?\"\\n\"Sure. It\\'s just a little more complicated than I expected, but it\\'s all good.\" \\nYou watch the bright moonlight dancing through the street lamps. It\\'s bright and there aren\\'t any buildings in it. In a little bit. That doesn\\'t mean it\\'s not exciting. The streets are empty, there\\'s no traffic and everyone\\'s just talking. It\\'s quiet and still and you can feel how beautiful things are. It\\'s like you\\'ve got a dream come true. That\\'s when the'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used to decode:\n",
    "\n",
    "from decodeLogits import *\n",
    "batch = 0\n",
    "ind = 0\n",
    "'''\n",
    "tokens = []\n",
    "for j in range(text[0].shape[2]):\n",
    "    tokens.append(np.argmax(df[0][ind, :, j]))'''\n",
    "decoder_text(text[batch][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, params in vals_dict.items():\n",
    "    for par in params:\n",
    "        if par ==None:\n",
    "            par = \"None\"\n",
    "        all_logits = pickle.load( gzip.open('gpt-2_output/all_logits_'+key+'-sampling-type_'+par+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        text = pickle.load( gzip.open('gpt-2_output/all_text_'+key+'-sampling-type_'+par+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        rand_selects = pickle.load( gzip.open('gpt-2_output/prompt_rand_selections_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_and_completion = []\n",
    "#prompt_length = 100\n",
    "#generation_length = 150+200 # just for safety\n",
    "for batch in text:\n",
    "    for entry in batch:\n",
    "        prompt_and_completion = decoder_text(entry)\n",
    "        \n",
    "gs = pd.DataFrame({'Prompt And Completion':prompt_and_completion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Rest of Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[WP] You look out at the bright lights of the ...</td>\n",
       "      <td>pass on the surface of the ground; a day pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[FF] - 250 Words; 2 months Reddit Gold prize \\...</td>\n",
       "      <td>I have given it a few more days? \\n\\n \\n\\n I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[WP] The shortest story ever told. Once upon a...</td>\n",
       "      <td>this, because it was evil, so the genie was n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[WP] Stockholm syndrome, but the other way aro...</td>\n",
       "      <td>taken her to the hospital and we gave her a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[WP] Your grandparents always playfully bicker...</td>\n",
       "      <td>was Swedish and his first name had no resembl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt  \\\n",
       "0  [WP] You look out at the bright lights of the ...   \n",
       "1  [FF] - 250 Words; 2 months Reddit Gold prize \\...   \n",
       "2  [WP] The shortest story ever told. Once upon a...   \n",
       "3  [WP] Stockholm syndrome, but the other way aro...   \n",
       "4  [WP] Your grandparents always playfully bicker...   \n",
       "\n",
       "                                      Rest of Prompt  \n",
       "0   pass on the surface of the ground; a day pass...  \n",
       "1   I have given it a few more days? \\n\\n \\n\\n I ...  \n",
       "2   this, because it was evil, so the genie was n...  \n",
       "3   taken her to the hospital and we gave her a s...  \n",
       "4   was Swedish and his first name had no resembl...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the human prompt completions so that the perplexity can be scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.to_csv('Human_StoryPrompts_Completion.csv', index=False, columns =['Prompt And Completion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating all completions for a particular random prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-ff9ac135490b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-ff9ac135490b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    I also need to store the sorted indices of the differnet words\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " vals_dict.items()\n",
    "    \n",
    "I also need to store the sorted indices of the differnet words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, params in vals_dict.items():\n",
    "    for par in params:\n",
    "        if par ==None:\n",
    "            par = \"None\"\n",
    "        #all_logits = pickle.load( gzip.open('gpt-2_output/all_logits_'+key+'-sampling-type_'+par+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        text = pickle.load( gzip.open('gpt-2_output/all_text_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        rand_selects = pickle.load( gzip.open('gpt-2_output/prompt_rand_selections_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "\n",
    "        generated_output = []\n",
    "        for batch in text:\n",
    "            for entry in batch:\n",
    "                generated_output.append(decoder_text(entry[prompt_length:]))\n",
    "        col_name = 'Samp Type:'+key+' Param:'+str(par)\n",
    "        gs[col_name] = generated_output\n",
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4, 13,  3, 11,  1, 12,  5,  9, 14, 10,  8, 15,  6,  7])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "select_a_random_prompt = np.random.choice(gs.shape[0])\n",
    "select_random_generation_methods = np.random.choice(gs.shape[1]-1, size =gs.shape[1]-1, replace=False )+1\n",
    "select_random_generation_methods = np.insert(select_random_generation_methods, 0, 0)\n",
    "print(select_a_random_prompt)\n",
    "select_random_generation_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_blind_output1.txt', 'w') as file: \n",
    "    for ind, out in enumerate(gs.iloc[select_a_random_prompt,select_random_generation_methods].tolist()):\n",
    "        if ind ==0:\n",
    "            file.write('Prompt: \\n \\n')\n",
    "        file.write(out)\n",
    "        \n",
    "        file.write('\\n')\n",
    "        file.write('================== \\n')\n",
    "        if ind == gs.shape[1]-1: # dont write random generation at the end. \n",
    "            continue\n",
    "        file.write('Random Generation: '+str(ind)+' \\n \\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the very tight ones are too close and degenerate into repeats. The prompts and stochasticity of a single generation are really hard to deal with though. it is also a lot to read in order to evaluate the quality. \n",
    "What is something I can evaluate algorithmically and where diverse beam search is outperformed? It may inherently need to be something that is long. \n",
    "Seems like there is definitely a sweet spot where dont want too many options but also dont want it to be degenerate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4, 13,  3, 11,  1, 12,  5,  9, 14, 10,  8, 15,  6,  7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(select_a_random_prompt)\n",
    "select_random_generation_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt                      [WP] Monsters under the bed exists and the wor...\n",
       "Samp Type:tfs Param:0.01     like a naked zombie.\\n\\nI had to admit, I was...\n",
       "Samp Type:tfs Param:0.1      strange. Well, I wasn't the first to wear thi...\n",
       "Samp Type:k Param:10         ridiculous because of my long black hair and ...\n",
       "Samp Type:tfs Param:0.05     strange. The day had been nice and sunny, but...\n",
       "Samp Type:n Param:0.9        ridiculous because I was tall and tall. It di...\n",
       "Samp Type:tfs Param:None     weird and I was in an emergency room. But the...\n",
       "Samp Type:k Param:1          like a Halloween costume. I was surprised to ...\n",
       "Samp Type:tfs Param:0.5      strange. Well, I wasn't the first to wear thi...\n",
       "Samp Type:n Param:0.5        ridiculous, but they all agreed it was cool. ...\n",
       "Samp Type:k Param:40         ridiculous because of my long black hair and ...\n",
       "Samp Type:n Param:0.75       ridiculous, but they all agreed it looked coo...\n",
       "Samp Type:n Param:0.25       weird. I was glad they didn't think I was a m...\n",
       "Samp Type:k Param:200        ridiculous because of my enormous black makeu...\n",
       "Samp Type:tfs Param:0.75     strange. Well, I wasn't the first to wear thi...\n",
       "Samp Type:n Param:0.1        like a costume. I was surprised to find that ...\n",
       "Name: 56, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.iloc[select_a_random_prompt,select_random_generation_methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.iloc[select_a_random_prompt,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_prompt =rand_selects[select_a_random_prompt]\n",
    "choose_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts.iloc[choose_prompt].test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
