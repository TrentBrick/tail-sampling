{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "#how be able to iterate through all of the different files\n",
    "\n",
    "#updated\n",
    "vals_dict = {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\n",
    "'n': [0.1, 0.25, 0.5, 0.63, 0.69, 0.75, 0.81, 0.9], 'k':[1,10,40,200]  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "prompts=pd.read_csv('test_dataframe_500primer.csv') # the text has the prompts so dont need this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert all of the numbers text from all of the different models into one dataframe with all of the prompts and the produced text separated out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-91b3e41f5067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8f9ed3c4ba4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     tokens.append(np.argmax(df[0][ind, :, j]))'''\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdecoder_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# used to decode:\n",
    "\n",
    "from decodeLogits import *\n",
    "batch = 0\n",
    "ind = 0\n",
    "'''\n",
    "tokens = []\n",
    "for j in range(text[0].shape[2]):\n",
    "    tokens.append(np.argmax(df[0][ind, :, j]))'''\n",
    "decoder_text(text[batch][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating all completions for a particular random prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-ff9ac135490b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ff9ac135490b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    I also need to store the sorted indices of the differnet words\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " vals_dict.items()\n",
    "    \n",
    "I also need to store the sorted indices of the differnet words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[WP] You look out at the bright lights of the city and wonder how you ever grew up. \\n The lights dance across the evening sky. You can see the buildings in the distance, some lights turning of as the stores close down. You wonder how this all happened, when did everything change? \\n \\n When did *you* change? \\n \\n Everyone is born a child. Some grow up faster than others. Some do n't grow up at all. Hours\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_text(text[0][0][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 27\n",
    "prompt_length = 100\n",
    "gs=dict()\n",
    "methods_wanted = ['tfs_0.95', 'n_0.69', 'k_40']\n",
    "first = True\n",
    "for key, params in vals_dict.items():\n",
    "    for par in params:\n",
    "        if key+'_'+str(par) in methods_wanted:\n",
    "            #all_logits = pickle.load( gzip.open('gpt-2_output/all_logits_'+key+'-sampling-type_'+par+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "            text = pickle.load( gzip.open('gpt-2_output/all_text_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts_'+str(seed)+'-seed.pickle.gz', 'rb'))\n",
    "            rand_selects = pickle.load( gzip.open('gpt-2_output/prompt_rand_selections_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts_'+str(seed)+'-seed.pickle.gz', 'rb'))\n",
    "\n",
    "            generated_output = []\n",
    "            for batch in text:\n",
    "                for entry in batch:\n",
    "                    generated_output.append(decoder_text(entry[prompt_length:]))\n",
    "            col_name = 'Samp Type:'+key+' Param:'+str(par)\n",
    "            gs[col_name] = generated_output\n",
    "            \n",
    "    if first==True:\n",
    "        prompts_used = []\n",
    "        for batch in text:\n",
    "            for entry in batch:\n",
    "                prompts_used.append(decoder_text(entry[0:prompt_length]))\n",
    "        \n",
    "        first=False\n",
    "gs = pd.DataFrame(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Samp Type:tfs Param:0.95</th>\n",
       "      <th>Samp Type:n Param:0.69</th>\n",
       "      <th>Samp Type:k Param:40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go by. Months go by. You can't remember the l...</td>\n",
       "      <td>have passed, and yet you still feel the touch...</td>\n",
       "      <td>later, it's your turn.\\n It's my turn.  It se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I throw in my towel and sit around crying? It...</td>\n",
       "      <td>I rush out of there?\\n\\nThen I was suddenly p...</td>\n",
       "      <td>I just ignore that and jump right in? \\n \\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the boy to lose his virginity, for it would b...</td>\n",
       "      <td>a child to marry. It was the magic of the cav...</td>\n",
       "      <td>the boy's wife and child and what could a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have taken her to the government. She doesn't...</td>\n",
       "      <td>you're here? It's not a coincidence. I'm sure...</td>\n",
       "      <td>raised her. We're going to leave her here, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>’ t didn't know who I was, that I ’ ve spoken...</td>\n",
       "      <td>, was one of the only ones of us who could und...</td>\n",
       "      <td>, ’ t resembled Bjørn Bjørnson in his youth, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Samp Type:tfs Param:0.95  \\\n",
       "0   go by. Months go by. You can't remember the l...   \n",
       "1   I throw in my towel and sit around crying? It...   \n",
       "2   the boy to lose his virginity, for it would b...   \n",
       "3   have taken her to the government. She doesn't...   \n",
       "4   ’ t didn't know who I was, that I ’ ve spoken...   \n",
       "\n",
       "                              Samp Type:n Param:0.69  \\\n",
       "0   have passed, and yet you still feel the touch...   \n",
       "1   I rush out of there?\\n\\nThen I was suddenly p...   \n",
       "2   a child to marry. It was the magic of the cav...   \n",
       "3   you're here? It's not a coincidence. I'm sure...   \n",
       "4  , was one of the only ones of us who could und...   \n",
       "\n",
       "                                Samp Type:k Param:40  \n",
       "0   later, it's your turn.\\n It's my turn.  It se...  \n",
       "1   I just ignore that and jump right in? \\n \\n\\n...  \n",
       "2   the boy's wife and child and what could a man...  \n",
       "3   raised her. We're going to leave her here, an...  \n",
       "4  , ’ t resembled Bjørn Bjørnson in his youth, a...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "select_a_random_prompt = np.random.choice(gs.shape[0])\n",
    "select_random_generation_methods = np.random.choice(range(gs.shape[1]), size =gs.shape[1], replace=False )\n",
    "#select_random_generation_methods = np.insert(select_random_generation_methods, 0, 0)\n",
    "print(select_a_random_prompt)\n",
    "select_random_generation_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_blind_output3.txt', 'w') as file: \n",
    "    file.write('Prompt: \\n \\n')\n",
    "    file.write(prompts_used[select_a_random_prompt])\n",
    "    file.write('\\n')\n",
    "    file.write('================== \\n')\n",
    "    for ind, out in enumerate(gs.iloc[select_a_random_prompt,select_random_generation_methods].tolist()):\n",
    "        file.write('Random Generation: '+str(ind)+' \\n \\n')\n",
    "        file.write(out)\n",
    "        \n",
    "        file.write('\\n')\n",
    "        file.write('================== \\n')\n",
    "        if ind == gs.shape[1]-1: # dont write random generation at the end. \n",
    "            continue\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the very tight ones are too close and degenerate into repeats. The prompts and stochasticity of a single generation are really hard to deal with though. it is also a lot to read in order to evaluate the quality. \n",
    "What is something I can evaluate algorithmically and where diverse beam search is outperformed? It may inherently need to be something that is long. \n",
    "Seems like there is definitely a sweet spot where dont want too many options but also dont want it to be degenerate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(select_a_random_prompt)\n",
    "select_random_generation_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Samp Type:tfs Param:0.95     life was about to change if she didn't give i...\n",
       "Samp Type:n Param:0.69       heart stopped beating and the pounding of his...\n",
       "Samp Type:k Param:40         mind was always busy, but he wouldn't be able...\n",
       "Name: 25, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.iloc[select_a_random_prompt,select_random_generation_methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.iloc[select_a_random_prompt,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_prompt =rand_selects[select_a_random_prompt]\n",
    "choose_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts.iloc[choose_prompt].test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
