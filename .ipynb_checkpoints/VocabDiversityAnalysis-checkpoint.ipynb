{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Gram Analysis\n",
    "get every word generated by a method and its frequency. \n",
    "Get the 4grams of each of the words and their frequencies. Can then make these plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pandas as pd    \n",
    "import torch\n",
    "\n",
    "n_gram = 4\n",
    "prompt_length = 100\n",
    "num_batches = 4\n",
    "batch_size=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_inds = [11, 20, 29, 35, 63, 80, 84, 94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to decode:\n",
    "from decodeLogits import *\n",
    "vals_dict = {'tfs':[0.25, 0.75, 0.9, 0.95, 0.99], 'flat':[0.01, 0.02, 0.05],\n",
    "'n': [0.1, 0.25, 0.5, 0.75, 0.9], 'k':[1,10,40,200]  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key is: tfs\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.25-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n"
     ]
    }
   ],
   "source": [
    "for key, params in vals_dict.items():\n",
    "    print('Key is:', key)\n",
    "    for par in params:\n",
    "        if par ==None:\n",
    "            par = \"None\"\n",
    "        print('opening file:', 'gpt-2_output/all_logits_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz')\n",
    "        #all_logits = pickle.load( gzip.open('gpt-2_output/all_logits_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        text = pickle.load( gzip.open('gpt-2_output/all_text_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        break\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 250)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of samples: 100\n"
     ]
    }
   ],
   "source": [
    "tot_num = 0\n",
    "for i in range(num_batches):\n",
    "    tot_num+= text[i].shape[0]\n",
    "print('total number of samples:', tot_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_good_samples = list(set(range(tot_num)) - set(bad_inds))\n",
    "tot_good_samples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey you'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\n', ' ','hey\\nyou' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Hey'.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# works for all but the generated text. \n",
    "\n",
    "# need to use moses to detokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key is: tfs\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.25-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.75-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.9-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.95-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.99-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "Key is: flat\n",
      "opening file: gpt-2_output/all_logits_flat-sampling-type_0.01-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_flat-sampling-type_0.02-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_flat-sampling-type_0.05-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "Key is: n\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.1-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.25-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.5-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.75-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.9-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "Key is: k\n",
      "opening file: gpt-2_output/all_logits_k-sampling-type_1-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_k-sampling-type_10-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_k-sampling-type_40-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "opening file: gpt-2_output/all_logits_k-sampling-type_200-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pandas as pd    \n",
    "import torch\n",
    "import copy\n",
    "num_samples = tot_num\n",
    "num_batches = num_samples//batch_size\n",
    "\n",
    "word_frequency_for_all = dict()\n",
    "\n",
    "num_target_too_short = 0\n",
    "\n",
    "for key, params in vals_dict.items():\n",
    "    print('Key is:', key)\n",
    "    for par in params:\n",
    "        if par ==None:\n",
    "            par = \"None\"\n",
    "        print('opening file:', 'gpt-2_output/all_logits_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz')\n",
    "        text = pickle.load( gzip.open('gpt-2_output/all_text_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "\n",
    "        p_ind = 0\n",
    "        word_freq_temp = dict()\n",
    "        for batch in range(num_batches):\n",
    "            for ind in range(0,text[batch].shape[0]):\n",
    "                \n",
    "                if p_ind in bad_inds:\n",
    "                    p_ind+=1\n",
    "                    continue\n",
    "                \n",
    "                if p_ind%25 == 0:\n",
    "                    pass\n",
    "                    #print('index', str(p_ind))\n",
    "                    \n",
    "                # this is the ground truth calculations =====\n",
    "\n",
    "                decoded_text_generated = decoder_text(text[batch][ind, prompt_length:])\n",
    "                #decoded_text_generated = decoded_text_generated.lower()\n",
    "                #decoded_text_generated = re.sub('\\n', ' ',decoded_text_generated )\n",
    "                word_set = list(set(decoded_text_generated.split(' '))) # may be some fuction that does this\n",
    "                for w in word_set:\n",
    "                    w = w.strip()\n",
    "                    #removing punctuation:\n",
    "                    #w = re.sub(r'[^\\w\\s]','',w)\n",
    "                    if w in word_freq_temp.keys():\n",
    "                        word_freq_temp[w] += 1\n",
    "                    else:\n",
    "                        word_freq_temp[w] = 1\n",
    "                \n",
    "                word_frequency_for_all[key+'-sampling-type_'+str(par)+'prompt_'+str(p_ind)] = copy.copy(word_freq_temp)\n",
    "                \n",
    "                p_ind+=1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1564"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_frequency_for_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_frequency_for_all['tfs-sampling-type_0.75prompt_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>Or</th>\n",
       "      <th>You</th>\n",
       "      <th>a</th>\n",
       "      <th>about</th>\n",
       "      <th>again?</th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>back</th>\n",
       "      <th>...</th>\n",
       "      <th>soul.</th>\n",
       "      <th>stop</th>\n",
       "      <th>the</th>\n",
       "      <th>things</th>\n",
       "      <th>thinking</th>\n",
       "      <th>to</th>\n",
       "      <th>up</th>\n",
       "      <th>up,</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      I  Or  You  a  about  again?  and  are  back  ...  soul.  stop  the  \\\n",
       "0  8  1   1    3  1      1       1    2    1     1  ...      1     1    2   \n",
       "\n",
       "   things  thinking  to  up  up,  you  your  \n",
       "0       1         1   1   1    1    1     1  \n",
       "\n",
       "[1 rows x 51 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict([word_frequency_for_all['tfs-sampling-type_0.75prompt_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key is: tfs\n",
      "Key is: flat\n",
      "Key is: n\n",
      "Key is: k\n"
     ]
    }
   ],
   "source": [
    "word_freq_percentage = dict()\n",
    "tot_word_occ = dict()\n",
    "for key, params in vals_dict.items():\n",
    "    print('Key is:', key)\n",
    "    for par in params:\n",
    "        num_unique_words = []\n",
    "        for i in tot_good_samples:\n",
    "            unique_num_words_temp = len(word_frequency_for_all[key+'-sampling-type_'+str(par)+'prompt_'+str(i)])\n",
    "            unique_word_occurences_temp = 0\n",
    "            for k, v in word_frequency_for_all[key+'-sampling-type_'+str(par)+'prompt_'+str(i)].items():\n",
    "                unique_word_occurences_temp += v\n",
    "            num_unique_words.append((unique_num_words_temp,unique_word_occurences_temp)) \n",
    "            to_df = []\n",
    "            for k, v in word_frequency_for_all[key+'-sampling-type_'+str(par)+'prompt_'+str(i)].items():\n",
    "                to_df.append( (k, v / unique_word_occurences_temp) )\n",
    "            word_freq_percentage[key+'-sampling-type_'+str(par)+'prompt_'+str(i)] = pd.DataFrame(to_df,\n",
    "                                                                                                columns=['words', 'freq'])\n",
    "        \n",
    "        tot_word_occ[key+'-sampling-type_'+str(par)] = num_unique_words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(36, 39),\n",
       " (48, 55),\n",
       " (51, 62),\n",
       " (67, 85),\n",
       " (99, 122),\n",
       " (139, 176),\n",
       " (171, 223),\n",
       " (203, 265),\n",
       " (248, 330),\n",
       " (294, 399),\n",
       " (334, 456),\n",
       " (386, 538),\n",
       " (408, 586),\n",
       " (409, 587),\n",
       " (426, 631),\n",
       " (457, 693),\n",
       " (467, 717),\n",
       " (481, 753),\n",
       " (486, 765),\n",
       " (486, 767),\n",
       " (512, 824),\n",
       " (523, 850),\n",
       " (557, 920),\n",
       " (571, 955),\n",
       " (614, 1022),\n",
       " (627, 1056),\n",
       " (638, 1095),\n",
       " (667, 1163),\n",
       " (678, 1186),\n",
       " (696, 1224),\n",
       " (732, 1294),\n",
       " (739, 1326),\n",
       " (766, 1385),\n",
       " (778, 1405),\n",
       " (794, 1458),\n",
       " (831, 1528),\n",
       " (844, 1557),\n",
       " (866, 1619),\n",
       " (875, 1657),\n",
       " (904, 1708),\n",
       " (918, 1734),\n",
       " (932, 1772),\n",
       " (940, 1791),\n",
       " (960, 1831),\n",
       " (978, 1896),\n",
       " (981, 1913),\n",
       " (1014, 1984),\n",
       " (1035, 2036),\n",
       " (1048, 2075),\n",
       " (1065, 2122),\n",
       " (1069, 2139),\n",
       " (1087, 2198),\n",
       " (1109, 2256),\n",
       " (1116, 2303),\n",
       " (1125, 2349),\n",
       " (1155, 2429),\n",
       " (1177, 2500),\n",
       " (1183, 2515),\n",
       " (1205, 2579),\n",
       " (1210, 2594),\n",
       " (1231, 2656),\n",
       " (1247, 2687),\n",
       " (1267, 2753),\n",
       " (1281, 2800),\n",
       " (1309, 2865),\n",
       " (1332, 2923),\n",
       " (1345, 2957),\n",
       " (1369, 3010),\n",
       " (1381, 3062),\n",
       " (1398, 3120),\n",
       " (1402, 3137),\n",
       " (1415, 3179),\n",
       " (1445, 3241),\n",
       " (1457, 3275),\n",
       " (1457, 3277),\n",
       " (1466, 3321),\n",
       " (1484, 3376),\n",
       " (1492, 3415),\n",
       " (1501, 3431),\n",
       " (1516, 3473),\n",
       " (1544, 3539),\n",
       " (1545, 3548),\n",
       " (1555, 3585),\n",
       " (1568, 3629),\n",
       " (1579, 3681),\n",
       " (1596, 3738),\n",
       " (1605, 3801),\n",
       " (1614, 3836),\n",
       " (1630, 3884),\n",
       " (1651, 3966),\n",
       " (1678, 4046),\n",
       " (1694, 4106)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_word_occ['tfs-sampling-type_0.75']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.103896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry.</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You</td>\n",
       "      <td>0.025974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>were</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words      freq\n",
       "0          0.103896\n",
       "1  angry.  0.012987\n",
       "2     You  0.025974\n",
       "3     you  0.012987\n",
       "4    were  0.012987"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_percentage['tfs-sampling-type_0.25prompt_4'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>burns</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>clippings,</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>wrote</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>facing</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>wake</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>library.</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>surrounded</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>coma,</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>mild</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>dead,</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>novels</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>string</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>searching</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>newspaper</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>progress.\\n The</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>sees</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>are:\\n*</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>accomplishment,</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>hell.</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>case</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>end.</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>right,</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>begun</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>finished?\"\\n John</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>disappear.</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>exponentially</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>lost</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>before:\\n\\nFor</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>California,</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>emotions</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>had</td>\n",
       "      <td>0.004078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>this</td>\n",
       "      <td>0.004078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>so</td>\n",
       "      <td>0.004460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>have</td>\n",
       "      <td>0.004460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>be</td>\n",
       "      <td>0.004460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>his</td>\n",
       "      <td>0.004588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>but</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>just</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>he</td>\n",
       "      <td>0.004843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>is</td>\n",
       "      <td>0.004843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>The</td>\n",
       "      <td>0.005097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>from</td>\n",
       "      <td>0.005097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>at</td>\n",
       "      <td>0.005225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>with</td>\n",
       "      <td>0.005480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>my</td>\n",
       "      <td>0.005480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>on</td>\n",
       "      <td>0.005862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>for</td>\n",
       "      <td>0.005862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>you</td>\n",
       "      <td>0.006244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>it</td>\n",
       "      <td>0.007009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>was</td>\n",
       "      <td>0.007391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>that</td>\n",
       "      <td>0.008538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I</td>\n",
       "      <td>0.008666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>in</td>\n",
       "      <td>0.009175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>of</td>\n",
       "      <td>0.010068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>and</td>\n",
       "      <td>0.010322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>a</td>\n",
       "      <td>0.010322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>to</td>\n",
       "      <td>0.011087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>the</td>\n",
       "      <td>0.011724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.014528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  words      freq\n",
       "1579              burns  0.000127\n",
       "2081         clippings,  0.000127\n",
       "2083              wrote  0.000127\n",
       "2084             facing  0.000127\n",
       "2085               wake  0.000127\n",
       "2086           library.  0.000127\n",
       "2090         surrounded  0.000127\n",
       "2091              coma,  0.000127\n",
       "2094               mild  0.000127\n",
       "2095              dead,  0.000127\n",
       "2096             novels  0.000127\n",
       "2097             string  0.000127\n",
       "2098          searching  0.000127\n",
       "2099          newspaper  0.000127\n",
       "2102    progress.\\n The  0.000127\n",
       "2103               sees  0.000127\n",
       "2104            are:\\n*  0.000127\n",
       "2105    accomplishment,  0.000127\n",
       "2106              hell.  0.000127\n",
       "2108               case  0.000127\n",
       "2080               end.  0.000127\n",
       "2109             right,  0.000127\n",
       "2079              begun  0.000127\n",
       "2077  finished?\"\\n John  0.000127\n",
       "2054         disappear.  0.000127\n",
       "2055      exponentially  0.000127\n",
       "2057               lost  0.000127\n",
       "2058     before:\\n\\nFor  0.000127\n",
       "2059        California,  0.000127\n",
       "2060           emotions  0.000127\n",
       "...                 ...       ...\n",
       "368                 had  0.004078\n",
       "107                this  0.004078\n",
       "97                   so  0.004460\n",
       "22                 have  0.004460\n",
       "104                  be  0.004460\n",
       "215                 his  0.004588\n",
       "148                 but  0.004715\n",
       "126                just  0.004715\n",
       "10                   as  0.004715\n",
       "152                  he  0.004843\n",
       "89                   is  0.004843\n",
       "184                 The  0.005097\n",
       "519                from  0.005097\n",
       "83                   at  0.005225\n",
       "134                with  0.005480\n",
       "59                   my  0.005480\n",
       "101                  on  0.005862\n",
       "29                  for  0.005862\n",
       "141                 you  0.006244\n",
       "52                   it  0.007009\n",
       "61                  was  0.007391\n",
       "79                 that  0.008538\n",
       "28                    I  0.008666\n",
       "32                   in  0.009175\n",
       "34                   of  0.010068\n",
       "63                  and  0.010322\n",
       "33                    a  0.010322\n",
       "81                   to  0.011087\n",
       "78                  the  0.011724\n",
       "0                        0.014528\n",
       "\n",
       "[3160 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tfs', 'flat', 'n', 'k'])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHMRJREFUeJzt3Xt4XHW97/H3N/f7vZe0TZreKC0tLSVSuRcEKaB0iyCtyhYP7LpVPKjbCxw9gMg5W4+iHo6Iu9sLiFsK4ka7oVrlJiC3ppTSO7RJaJM2TZprc51M8jt/zFSH2DaTZpI1Wfm8nmeeZ9Zav1nzmaTz6cpaa2aZcw4REfGXBK8DiIhI7KncRUR8SOUuIuJDKncRER9SuYuI+JDKXUTEh1TuIiI+pHIXEfEhlbuIiA8lefXERUVFrqyszKunFxEZkzZt2nTYOTdhsHGelXtZWRkVFRVePb2IyJhkZu9EM067ZUREfEjlLiLiQyp3EREfUrmLiPiQyl1ExIcGLXcz+5mZ1ZvZtuMsNzO718z2mNmbZrYk9jFFRGQootlyfwBYfoLllwNzwrfVwP3DjyUiIsMx6HnuzrnnzazsBENWAL9woev1vWJmeWZW7Jw7GKOMIiJxrS8YpONIE4cPVtPaUEt7Ux1drYfpaWumt72VYEcb/V2d0N0F3T0UXfRBLrn+1hHNFIsPMU0F9kdM14Tn/V25m9lqQlv3lJaWxuCpRUSGpi8Y5EhrA02H9tN6aD/tzXV0tjQSONJEoL2Nvs4joSLuChWxBQIkBoIkBPpI6u0nKeBI7g3dUnohJQCpvZDUH1p/Wvh2IlvyXoAxUO5Rc86tAdYAlJeX68rcInJCfcEgbc2HaKp7h7bDB0NF3NxAz5Fmejta6etoD28Rd0N3DwmBAAk9QRJ7+0gM9JPUG1HE4RJODUBiuH2iKeKuFAgk/+0WTDG60432nCT6UhLoT0miPyUZl5oC6ekkpKeTmJFNcmY2Kdl5pOUUklVQTM6EYvInlpA/YRrzUlJH+kcXk3KvBUoipqeF54mIvEtfMMiuTc9Q9doG2vduJ6GugeSu3nAR95Pcy9+KOABpvZAwxCLuSYZACvQmQ2/yMYo4NRlSU3FpaRFFnEtqTqiIM/MnvauIk0ehiEdCLMp9HXCzma0FlgKt2t8uMr51dbSx9S/rqH39ebqr3yalvpnspgCFTY6MAMwKj+tMgfbMiCLOSKA9OYG+5L8VsUtLxdLSsLQMkjKySDpaxHkTySqYQHbhFAonlZBbOGXMFvFIGLTczexhYBlQZGY1wB1AMoBz7sfAeuAKYA/QCXxypMKKSPzoCwap3vkaVZufo3nPVvr27yPtcBu5TUEKWyC7D04Nj23JhKaCBPbOT6d/8kSyZp/GrKXLWXzGMhKTPPv+Ql+L5myZVYMsd8BnY5ZIROLCX8v7jedpqdpBsK6GxMZW0tp6yGrrI78ttA97KqFbv0FjLrTkJ1I/MxOmTiH/1CXMO/9DzJu1wOuXM+7ov0yRcazp0H42P/UwLXu30VtXS0JTC2mtPWQfo7wBOlKhJQfa8pKoL0vDFRaQOmU6RacsYuGFV3NaYbGXL0ciqNxFxrHXVl3G9AOOKeHpyPJuKEujvyCflCmlFMxexKwlF2kLfAxRuYuMY+ldjqppCWR86p9V3j6jchcZZ9qa63nq/tuwVzYyuxUOFydzxbWf8zqWxJjKXWQcaGk8yAu//DY9zz/HjD09zOuBtgzYtTCDshu/5HU8GQEqd5Exqi8YpLZqO7W7K2is3klX3X76mg5jbUdIbu8hrSNIRkc/WR2Q2QOzCX3Ip2p2KsnnX8Clq+9maWaO1y9DRojKXSQOVe+soPKNP9NWu5ee+gO45iYS2zpI7giQ3tFHZocjuxNSgpBH6HZUIAnaMqEj02gpSKK+NJW+nAxSy+Zw8afuZonOaBkXVO4iHtu/dxtbfv8AR7ZtIr32MEWHghS2QTGh21EdaXAkAzozE6ifkkxtVhr9edkk5heRMbmEgrL5TJ+/lMklp+iDQaJyFxlNvYEeXnjs/1H/0gZS9h+isL6Xic1/+zj+4VxomJTM/iWFpJRMJ6t4JhNnLWTGgveSpy1uGQKVu8gIq63awSsPfQu35U2mVfdQ3BHaIm/KhoZJSRxYWEDm/MWcftn1nD+v3Ou44hMqd5Fham9tonL7y9Tv3cqRA1UEGg7iWppJPNJJZmM3JQf6md8f+oDQ/rJk9i2Yy+lXf5pzz7zY6+jiYyp3kWPoDfSwb/cmDry9mZb9b9NVX0t/cyPW2k5yRw+pHUEyOkNnomR1h75Jb+qAdRxJh9Zs2P6ePHLPvZhlH/sq5To7RUaJyl3Gtb5gkO2v/p6qV/5A196dJNc1kdMYYEKTI7UXigjdjupJgiPhM1Fa85NoKEmhPzsTy8snZUIxOVNnMmnWQsrmLSUrt8CrlyWichd/6+poo3rHaxx8+w3aavfQUx/aZZLUfITsxh4mNDrSA3BKeHxLJjQVJvDWwkz6iwpIKppE5uQSCsvmUXrqUiZMmaEzUWRM0L9SGXP6gkHq9r9F7duv01i9k44D7xBsaoDWNpLbu0ht7yX96C6TTkjg708rbMuAxoIE9sxPp3/KZHJPXcxpF36YeXOXePSqRGJL5S5xob21iXd2VVBftY0jB6vpbjhAf0szdqSdpI4eUjp7SetyZHQ6sjohpQ+yCd2OCiaEd5lkGB3ZiTRPTiaYnQF5eaQUTSZrygwmzlrIzAVnMy9/okevVGR0qNzFE10dbfzhvq9gz/+FaTVBMrtDW9iTw7ejehPDH9zJCF0Ls60whWBmKi4ni4TcfNImTiW/9BSmzDmD2XPP1GXWRMJU7jKqXnry5+x/5MdM397GqR2h3SPVc9II5mZhubkkFUwka1IJ+aVzmDpniT5tKXKS9K6RUbFr0zNUf/lmph9w5BjsnZHIgfOWctnnvsfS7Fyv44n4jspdRlxzQy1v/Oh2Fh1wvHlWLou/8C1WnLHM61givqZylxHT0niQP33mSmbu7GJRABpzoPzL32PWwnO8jibieyp3GRF9wSB/uvdfWLCli7dnJJJwxWVcetM3SU3P8DqayLigcpeYeuHx+6n93S+YurOFBa2hT3Tm/9OnOf/qz3odTWRcUbnLsG16+te89cgPmbSjnuLDkG9QXZrAgYvmct6n7mbxjPleRxQZd1TuctIeu/NjZD+3mdI6x2LgnSnGluXTOfOTX+cDi871Op7IuKZyl5M29YnX6TfYclExp370Fpafv8LrSCISpnKXIesLBnn24e+SH4DKuemsvP8ZryOJyAAqd4lKT1cnTz3wTTqe/xNT93Qw9Qj0GfRNH/gt5iISD1TuclxtzfU8+7Nv0PvyS5RUdjOzEwJJUF2aSO0lc3nvDV9jpb5FUSQuqdzlmH59+ypm/fYNTglAVwpUz0im5szFnH/jHSyaOmvwFYiIp6IqdzNbDvxfIBH4iXPuWwOWlwIPAnnhMbc659bHOKuMsL5gkOcfu5dDTz3OohcPA7D7pou4+MY7WaKvyBUZUwYtdzNLBO4DLgVqgI1mts45tyNi2NeBR51z95vZfGA9UDYCeSWGegM97Kx4ij1/fpz+1zcxtaqbye0wEdhXbLQsPZXrvvQjr2OKyEmIZsv9LGCPc64SwMzWAiuAyHJ3wNEr/+YCB2IZUoanLxjktT88yL5nH4e6etKaO8lp7aOgJXTRi3mEdr3sm57E/gWncMbKL3KZzlMXGdOiKfepwP6I6Rpg6YAxdwJ/NLPPAZnAJTFJJ8PSG+jht9efw7S9neS1h/aZ9SRBUx605SVRPzMDN2kiObMXcsGqL7FEF3QW8Y1YHVBdBTzgnLvHzM4GHjKzBc65/shBZrYaWA1QWloao6eWSH3BIBVP/Yqqp35N5rZKFlT305YBb35gDjPfv4rFy67W1YpExoFoyr0WKImYnhaeF+lGYDmAc+5lM0sDioD6yEHOuTXAGoDy8nJ3kpnlGH773c/Q/8KLFNf0ktcBi4DWTNg1N5lZX/1XrjvnSq8jisgoiqbcNwJzzGwGoVJfCXx0wJh9wPuAB8xsHpAGNMQyqJxY0aPPktYD+8qSeWfOdMredw3vufRjukSdyDg16DvfORc0s5uBDYROc/yZc267md0FVDjn1gH/Avy7mX2B0MHVG5xz2jIfBX3BIFtffpKUXqienco1v3nD60giEgei2qwLn7O+fsC82yPu7wB0esUoW/u591P6yn7yj0AqEMzJ9DqSiMQJ/c0+hhVsrcEZbFk+nclnL+fDH/q015FEJE6o3MeY9tYmXnjkHlpef4lZrY5DkxJY+YM/eB1LROKMyn2M6DjSysb1Pyfh+/9GWUtoXn0+dJ1xqrfBRCQuqdzjUG+gh01Pr2Xfi09CZSW5dZ1MbnBMCoaW1xXC9H9/kAvnn+VtUBGJWyr3OFLx9Frqvv1Niuv6yQ3AQqAnGeomGrsWZZEwazZl513FBRdfq1McReSE1BBxpPKPj7BwXz875qfSN2cGxUsvofyy61mcmTP4g0VEIqjcPXb4YBVP/Y+Pk3WghbL60Lc1zL/tu8x7j76eR0ROnsrdI72BHra88DhvP/IjFr/cRF0B7JsZ2mK/5oxlXscTkTFO5e6BvVtf4vAnbiSnExYT+qbGvH/931x04Ye8jiYiPqFy90Dt7teZ0Albz8ik4IprWPL+j1EwqWTwB4qIREnlPoo6jrSy+ZlHOPDc75gAJC5YwCXX3+p1LBHxIZX7KGlpPMiuSy+msBMKgUAi5M9Y4HUsEfEplfsI27v1JbZu+CXdu7exqBO2L0ij6NpPsPiS61hUWOx1PBHxKZX7CNj4x4ep/NNaOFjH6RVtzA3Pb82ArMs+wLLrPu9pPhHxP5X7COi48y5ObwrteqkrhLrTJnL2F+5h3rxyr6OJyDihco+x2qodpAZCl7e7Yu0rpKZneB1JRMYhlXuMrL3pfGZuOkx2F+QBNWnJKnYR8YzKPUby9zbSmwxb3ltM8rRSzvu4TnEUEe+o3GOgN9CD9UNzXgIr73/G6zgiIir34Xj0tg8z8c87yG+Fkj54e2aC15FERACV+7CkbH2L7A7YtSQHN6GIuStu8jqSiAigch+y2qodvPTA3QQPHWBKY5C2LLjuoVe9jiUi8i4q9yF68Y5PcvprbQC0p0HladkeJxIR+Xsq9yGy3j46U6Dk908wb+os3uN1IBGRY9ARwJPgEmDi1FlexxAROS5tuUehtmoHL9z3VWhsZNK+Dq/jiIgMSuUehRfuuYVFT9XQZ9CaBVWnpKNviRGReKZyP4Gerk6qd71GQlMLAJOfWc+C4hkepxIRGZzK/Tg2/PROJn//EVKCsBAIJEF6VoHXsUREoqJyP47WvdsoDcKW84pImTWX0rMuITM71+tYIiJRUbkPYs6q/86Z77vW6xgiIkMS1amQZrbczHab2R4zO+bXHZrZR8xsh5ltN7NfxTbm6Nn87G944r4vQ2WV11FERE7aoFvuZpYI3AdcCtQAG81snXNuR8SYOcBtwLnOuWYzmzhSgUfSMw/fQ/E3fsLRM9h7kmFC6SmeZhIRORnR7JY5C9jjnKsEMLO1wApgR8SYfwLuc841Azjn6mMddDR0NNQCsGX5dEovvY7Ziy/Qh5VEZEyKptynAvsjpmuApQPGnAJgZn8BEoE7nXN/GLgiM1sNrAYoLS09mbwjoi8YpPHQO3TXh8o977T3cM6Vn/Q4lYjIyYvVAdUkYA6wDJgGPG9mC51zLZGDnHNrgDUA5eXlLkbPPSzVOyuo+9j15HbCgvC8lKw8TzOJiAxXNOVeC5RETE8Lz4tUA7zqnOsFqszsLUJlvzEmKUfQgbc3k98JO+al0HfqbDJLZrP82lu8jiUiMizRlPtGYI6ZzSBU6iuBjw4Y81tgFfBzMysitJumMpZBR5pbtJCP3PlLr2OIiMTEoOXunAua2c3ABkL703/mnNtuZncBFc65deFl7zezHUAf8GXnXONIBh+uF3+3hkNv/oXedyrJ9zqMiEiMRbXP3Tm3Hlg/YN7tEfcd8MXwLe4dPlhF7m3fp7A/NB1MgJyyud6GEhGJoXH5CdXO9jaS+uHNs3I57TN3UDJnMQsLi72OJSISM+Oy3I9yuTkseO/lXscQEYm5cVXu7a1NVO98ldrtrxI/Z9mLiMTeuCr3isvPZVITfy12S8/wNI+IyEgZV+We3wZ7yhLoOedM0gon8YF//LrXkURERsS4KneAzolZXHf7L7yOISIyoqL6yl8RERlbVO4iIj7k+90ytVU72PniOrqa6ynr9zqNiMjo8H2577jhGqYd+tsXUPZn6AwZEfE/35d7WrejsiSBhGv/gcyCYq6+8r95HUlEZMT5vtwBerKSuHr1//I6hojIqNEBVRERH1K5i4j4kMpdRMSHfLnPfe3nl1OweR/JvY4JbVA/xetEIiKjy5flnrd1H3ltjtppyTQVJ5B1+QqvI4mIjCpfljtAQ1ECH/qvN72OISLiCe1zFxHxIZW7iIgPqdxFRHxI5S4i4kO+OaDa1dHG5qcfobWumrRuR2eGeR1JRMQzvin3/7rxYha+0UF+eHpXQaKneUREvOSbck/uDNCcBY3XX0bWpFIuunSV15FERDzjm3IHCKTAB2/5gdcxREQ8pwOqIiI+pHIXEfEhlbuIiA+p3EVEfCiqcjez5Wa228z2mNmtJxj3YTNzZlYeu4giIjJUg5a7mSUC9wGXA/OBVWY2/xjjsoFbgFdjHVJERIYmmi33s4A9zrlK51wAWAsc6wvSvwl8G+iOYT4RETkJ0ZznPhXYHzFdAyyNHGBmS4AS59yTZvblGOY7oeaGWl58+B4CLYfJbguO1tOKiMS9YX+IycwSgO8BN0QxdjWwGqC0tHS4T82Gr3yERS83/XW6slTHh0VEILpyrwVKIqanhecdlQ0sAJ4zM4DJwDozu8o5VxG5IufcGmANQHl5uRtGbgASAgF6kqHtjs+SM6mEC08/f7irFBHxhWjKfSMwx8xmECr1lcBHjy50zrUCRUenzew54EsDi32k9BlccM3No/FUIiJjxqD7MZxzQeBmYAOwE3jUObfdzO4ys6tGOqCIiAxdVPvcnXPrgfUD5t1+nLHLhh9LRESGQ0cgRUR8SOUuIuJDKncRER9SuYuI+JDKXUTEh1TuIiI+pHIXEfEhlbuIiA+p3EVEfEjlLiLiQyp3EREfUrmLiPiQyl1ExIeGfSWm0bZ783Nsvu9/ktDZTdG+dq/jiIjEpTFX7q//9G4Wv3iYrhToToV3ZqZwptehRETizJgrd+vvB6B0w3qKimd4nEZEJD5pn7uIiA+p3EVEfEjlLiLiQyp3EREfUrmLiPiQyl1ExIdU7iIiPqRyFxHxIZW7iIgPqdxFRHxI5S4i4kMqdxERH1K5i4j4kMpdRMSHVO4iIj4UVbmb2XIz221me8zs1mMs/6KZ7TCzN83saTObHvuoIiISrUHL3cwSgfuAy4H5wCozmz9g2Gag3Dl3OvAY8H9iHVRERKIXzZb7WcAe51ylcy4ArAVWRA5wzj3rnOsMT74CTIttTBERGYpoyn0qsD9iuiY873huBH5/rAVmttrMKsysoqGhIfqUIiIyJDE9oGpmHwfKge8ca7lzbo1zrtw5Vz5hwoRYPrWIiESI5gLZtUBJxPS08Lx3MbNLgK8BFzrnemITT0RETkY0W+4bgTlmNsPMUoCVwLrIAWZ2BvBvwFXOufrYxxQRkaEYtNydc0HgZmADsBN41Dm33czuMrOrwsO+A2QBvzazN8xs3XFWJyIioyCa3TI459YD6wfMuz3i/iUxziUiIsOgT6iKiPiQyl1ExIdU7iIiPqRyFxHxIZW7iIgPqdxFRHxI5S4i4kMqdxERH1K5i4j4kMpdRMSHVO4iIj6kchcR8SGVu4iID6ncRUR8SOUuIuJDKncRER9SuYuI+JDKXUTEh1TuIiI+pHIXEfEhlbuIiA+p3EVEfEjlLiLiQyp3EREfUrmLiPiQyl1ExIdU7iIiPqRyFxHxIZW7iIgPqdxFRHwoqnI3s+VmttvM9pjZrcdYnmpmj4SXv2pmZbEOKiIi0Ru03M0sEbgPuByYD6wys/kDht0INDvnZgPfB74d66AiIhK9aLbczwL2OOcqnXMBYC2wYsCYFcCD4fuPAe8zM4tdTBERGYpoyn0qsD9iuiY875hjnHNBoBUojEVAEREZulE9oGpmq82swswqGhoaTmodKSUz2T0niaSUtBinExHxj6QoxtQCJRHT08LzjjWmxsySgFygceCKnHNrgDUA5eXl7mQCX33bT07mYSIi40o0W+4bgTlmNsPMUoCVwLoBY9YBnwjfvwZ4xjl3UuUtIiLDN+iWu3MuaGY3AxuAROBnzrntZnYXUOGcWwf8FHjIzPYATYT+AxAREY9Es1sG59x6YP2AebdH3O8Gro1tNBEROVn6hKqIiA+p3EVEfEjlLiLiQyp3EREfUrmLiPiQeXU6upk1AO8M4SFFwOERihNLyhl7YyWrcsaWch7bdOfchMEGeVbuQ2VmFc65cq9zDEY5Y2+sZFXO2FLO4dFuGRERH1K5i4j40Fgq9zVeB4iScsbeWMmqnLGlnMMwZva5i4hI9MbSlruIiETJs3IfzkW3zey28PzdZnZZtOuMh5xmVmJmz5rZDjPbbma3xGPOiGWJZrbZzJ6I15xmlmdmj5nZLjPbaWZnx2nOL4R/59vM7GEzG/YVZ042p5kVhv8dtpvZDwc85kwz2xp+zL2xuGRmrHOaWYaZPRn+nW83s28NN+NI5Bzw2HVmti0WOaPinBv1G6GvDt4LzARSgC3A/AFjPgP8OHx/JfBI+P788PhUYEZ4PYnRrDNOchYDS8JjsoG34jFnxOO+CPwKeCIef+/hZQ8CN4XvpwB58ZaT0KUoq4D08LhHgRs8zJkJnAf8M/DDAY95DXgvYMDvgcvjLSeQAVwU8Tt/IR5zRjzu6vD7aNtw30fR3rzach/ORbdXAGudcz3OuSpgT3h90azT85zOuYPOudcBnHNHgJ38/TVpPc8JYGbTgCuBWF3+KuY5zSwXuIDQNQVwzgWccy3xljM8LglIt9DVyjKAA17ldM51OOdeBLojB5tZMZDjnHvFhVrpF8A/xFtO51ync+7Z8P0A8Dqhq8TFVU4AM8sitJF09zDzDYlX5T6ci24f77HRrDMecv5V+E+6M4BX4zTnD4CvAP3DzDeSOWcADcDPw7uPfmJmmfGW0zlXC3wX2AccBFqdc3/0MOeJ1lkzyDrjIedfmVke8EHg6TjN+U3gHqBzmPmGRAdUPRL+3/w3wOedc21e5xnIzD4A1DvnNnmdZRBJwBLgfufcGUAHEJPjLbFkZvmEtvpmAFOATDP7uLepxr7wX0EPA/c65yq9zjOQmS0GZjnnHh/t5/aq3Idy0e2jv8CjF90+3mOjWWc85MTMkgkV+3845/5zmBlHKue5wFVmVk3oz9OLzeyXcZizBqhxzh396+cxQmUfbzkvAaqccw3OuV7gP4FzPMx5onVG7t7w+n00mDXA2865Hwwz40jlPBsoD7+PXgROMbPnYpB1cKO1c3/AwYUkoJLQVszRAxenDRjzWd594OLR8P3TePcBq0pCB0IGXWec5DRC+zF/EM8/zwGPXUZsDqiOSE5CB9Pmhu/fCXwn3nICS4HthPa1G6H9tp/zKmfE8hsY/IDqFXGa825CG0kJXr+PTpQzYlkZo3hAdVSe5Dgv9ApCZ4rsBb4WnncXcFX4fhrwa0IHpF4DZkY89mvhx+0m4gj5sdYZbzkJHVF3wJvAG+HbsN48I/XzjFi+jBiU+wj+3hcDFeGf6W+B/DjN+Q1gF7ANeAhI9ThnNaEL2rcT+gtofnh+eTjjXuCHhD/sGE85CW1VO0InJBx9H90UbzkHrLuMUSx3fUJVRMSHdEBVRMSHVO4iIj6kchcR8SGVu4iID6ncRUR8SOUuIuJDKncRER9SuYuI+ND/B5Hj+niO69/sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in vals_dict.keys():\n",
    "    for i in range(91,92):\n",
    "        sortedd = word_freq_percentage['tfs-sampling-type_0.99prompt_'+str(i)].sort_values('freq', ascending=True)\n",
    "        sortedd_freq = sortedd.freq.cumsum()\n",
    "        plt.plot(sortedd.freq, sortedd_freq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 16),\n",
       " (8, 8),\n",
       " (20, 20),\n",
       " (6, 6),\n",
       " (17, 18),\n",
       " (8, 8),\n",
       " (9, 12),\n",
       " (44, 50),\n",
       " (39, 39),\n",
       " (13, 13),\n",
       " (23, 24),\n",
       " (15, 15),\n",
       " (23, 24),\n",
       " (1, 2),\n",
       " (11, 13),\n",
       " (17, 17),\n",
       " (2, 3),\n",
       " (23, 23),\n",
       " (36, 37),\n",
       " (1, 1),\n",
       " (9, 10),\n",
       " (13, 14),\n",
       " (21, 23),\n",
       " (13, 13),\n",
       " (21, 22),\n",
       " (22, 23),\n",
       " (2, 2),\n",
       " (6, 9),\n",
       " (19, 20),\n",
       " (17, 17),\n",
       " (21, 21),\n",
       " (26, 30),\n",
       " (9, 10),\n",
       " (2, 3),\n",
       " (6, 7),\n",
       " (20, 22),\n",
       " (7, 7),\n",
       " (26, 31),\n",
       " (18, 23),\n",
       " (15, 15),\n",
       " (19, 20),\n",
       " (10, 10),\n",
       " (9, 9),\n",
       " (9, 9),\n",
       " (24, 26),\n",
       " (15, 15),\n",
       " (8, 9),\n",
       " (5, 5),\n",
       " (13, 15),\n",
       " (10, 10),\n",
       " (22, 22),\n",
       " (27, 29),\n",
       " (14, 16),\n",
       " (6, 6),\n",
       " (13, 14),\n",
       " (47, 48),\n",
       " (23, 26),\n",
       " (13, 13),\n",
       " (38, 39),\n",
       " (2, 2),\n",
       " (18, 18),\n",
       " (17, 19),\n",
       " (21, 23),\n",
       " (2, 2),\n",
       " (2, 2),\n",
       " (26, 28),\n",
       " (16, 16),\n",
       " (11, 15),\n",
       " (15, 17),\n",
       " (8, 9),\n",
       " (4, 4),\n",
       " (24, 27),\n",
       " (13, 14),\n",
       " (11, 11),\n",
       " (1, 1),\n",
       " (14, 14),\n",
       " (14, 15),\n",
       " (1, 2),\n",
       " (43, 45),\n",
       " (19, 19),\n",
       " (13, 16),\n",
       " (5, 5),\n",
       " (13, 16),\n",
       " (23, 24),\n",
       " (32, 33),\n",
       " (13, 13),\n",
       " (17, 17),\n",
       " (21, 23),\n",
       " (24, 25),\n",
       " (15, 16),\n",
       " (26, 28),\n",
       " (30, 30)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_word_occ['tfs-sampling-type_0.25'] # unique words and then total words. \n",
    "# turned the words into frequencies too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-db7fc399d0c7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-db7fc399d0c7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    key+'-sampling-type_'+str(par)+'prompt_'+str(p_ind)]\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "key+'-sampling-type_'+str(par)+'prompt_'+str(p_ind)]\n",
    "\n",
    "for key, prompt_dicts in word_frequency_for_all.items():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
