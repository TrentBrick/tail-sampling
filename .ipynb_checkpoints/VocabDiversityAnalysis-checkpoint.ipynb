{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Gram Analysis\n",
    "get every word generated by a method and its frequency. \n",
    "Get the 4grams of each of the words and their frequencies. Can then make these plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pandas as pd    \n",
    "import torch\n",
    "\n",
    "n_gram = 4\n",
    "prompt_length = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to decode:\n",
    "from decodeLogits import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of samples: 92\n"
     ]
    }
   ],
   "source": [
    "tot_num = 0\n",
    "for i in range(num_batches):\n",
    "    tot_num+= all_logits[i].shape[0]\n",
    "print('total number of samples:', tot_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# works for all but the generated text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key is: tfs\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.25-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 8\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.75-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 16\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.9-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 24\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.95-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 32\n",
      "opening file: gpt-2_output/all_logits_tfs-sampling-type_0.99-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 40\n",
      "Key is: flat\n",
      "opening file: gpt-2_output/all_logits_flat-sampling-type_0.01-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 48\n",
      "opening file: gpt-2_output/all_logits_flat-sampling-type_0.02-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 56\n",
      "opening file: gpt-2_output/all_logits_flat-sampling-type_0.05-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 64\n",
      "Key is: n\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.1-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 72\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.25-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 80\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.5-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 88\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.75-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 96\n",
      "opening file: gpt-2_output/all_logits_n-sampling-type_0.9-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 104\n",
      "Key is: k\n",
      "opening file: gpt-2_output/all_logits_k-sampling-type_1-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 112\n",
      "opening file: gpt-2_output/all_logits_k-sampling-type_10-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 120\n",
      "opening file: gpt-2_output/all_logits_k-sampling-type_40-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 128\n",
      "opening file: gpt-2_output/all_logits_k-sampling-type_200-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz\n",
      "index 0\n",
      "index 25\n",
      "index 50\n",
      "index 75\n",
      "number of prompts where the target is too short for this param 136\n"
     ]
    }
   ],
   "source": [
    "del all_logits\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pandas as pd    \n",
    "import torch\n",
    "\n",
    "num_samples = tot_num\n",
    "num_batches = num_samples//batch_size\n",
    "\n",
    "word_frequency_for_all = dict()\n",
    "\n",
    "num_target_too_short = 0\n",
    "\n",
    "for key, params in vals_dict.items():\n",
    "    print('Key is:', key)\n",
    "    for par in params:\n",
    "        if par ==None:\n",
    "            par = \"None\"\n",
    "        print('opening file:', 'gpt-2_output/all_logits_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz')\n",
    "        #all_logits = pickle.load( gzip.open('gpt-2_output/all_logits_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        text = pickle.load( gzip.open('gpt-2_output/all_text_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        #rand_selects = pickle.load( gzip.open('gpt-2_output/prompt_rand_selections_'+key+'-sampling-type_'+str(par)+'-sampling-param_100-word-prompts_150-gen-length_100-number-of-prompts.pickle.gz', 'rb'))\n",
    "        #temp_tail_cdfs = np.zeros([num_samples, all_logits[0].shape[2]])\n",
    "        #temp_tail_ids = np.zeros([num_samples, all_logits[0].shape[2]])\n",
    "        p_ind = 0\n",
    "        word_freq_temp = dict()\n",
    "        for batch in range(num_batches):\n",
    "            #for p_ind in range(batch*batch_size, (batch*batch_size)+batch_size ):\n",
    "            for ind in range(0,len(text[0][0])):\n",
    "                \n",
    "                if p_ind%25 == 0:\n",
    "                    print('index', str(p_ind))\n",
    "                    \n",
    "                # this is the ground truth calculations =====\n",
    "\n",
    "                decoded_text_generated = decoder_text(text[batch][ind, prompt_length:])\n",
    "                \n",
    "                word_set = list(set(decoded_text_generated.split(' '))) # may be some fuction that does this\n",
    "                for w in word_set:\n",
    "                    # count the number of occurences.\n",
    "                \n",
    "                    word_freq_temp[]\n",
    "                \n",
    "                word_frequency_for_all[key+'-sampling-type_'+str(par)+'prompt_'+str(p_ind)] = ground_token_in_cut_temp\n",
    "                \n",
    "                p_ind+=1\n",
    "                \n",
    "                break\n",
    "            break\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key+'-sampling-type_'+str(par)+'prompt_'+str(p_ind)]\n",
    "\n",
    "for key, prompt_dicts in word_frequency_for_all.items():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
